
---
title: Problem Set Mindestlohn
always_allow_html: true
output: 
  html_document: 
    keep_md: yes
    toc: yes
---

```{r setup, include=FALSE, echo=FALSE}
# Load libraries and source extra code
library(ggplot2)
library(haven)
library(stargazer)
library(sandwich)
library(ggdag)
library(lfe)
library(broom)
library(RTutor)


# Options for rendering data frames
# If you knit to a Word docx file, try
# 
# data.frame.theme="word" 
# 
# (needs RStudio > 1.2.1)
# 
# You can also set the options like
# table.max.cols as chunk options
# Makes sense if there are too many, too wide
# columns in some chunks

RTutor::set.knit.print.opts(data.frame.theme="code", table.max.rows=25, table.max.cols=NULL, round.digits=5, signif.digits=8)


# continue knitting even if there is an error
knitr::opts_chunk$set(error = TRUE) 
```

## Mindestlohn und Firmenprofitabilität: Eine interaktive Analyse



## Exercise Inhaltsübersicht

Herzlich Willkommen zu diesem interaktiven RTutor Problem Set.
Im Rahmen meiner Bachelorarbeit gehen wir den Zusammenhängen von Mindestlöhnen und der Unternehmensprofitabilität auf den Grund.
Die Basis bildet der Artikel [Minimum Wages and Firm Profitability](https://www.aeaweb.org/articles?id=10.1257/app.3.1.129) von Mirko Draca, Stephen Machin und John Van Reenen, erschienen im Januar 2011 im American Economic Journal: Applied Economics. 

Durch die Verknüpfung von inhaltlichen Hintergründen, fachlicher Analyse von Ergebnissen, persönlichen Einschätzungen und technischer Arbeit mit der Statistiksoftware R sollen Sie durch dieses Problem Set von einem fundierten Wissenszuwachs profitieren. 
Es ist das Ziel, dass Sie sich nach der geführten Erarbeitung des Themas kritisch und differenziert mit politischen Mindestlohnforderungen auseinandersetzen können und dazu in der Lage sind, Ihre Meinungsbildung ökonomisch zu begründen.   

### Inhalt

1. Einführung in den Mindestlohn

2. Datenüberblick

3. Difference in Differences

  3.1 Wahl der Gruppen

  3.2 Händische DiD Berechnung

  3.3 DiD-Schätzung mittels Regression

  3.4 Imaginäre Mindestlohneinführung

4. Einordnung des Artikels



## Exercise 1 -- Einführung in den Mindestlohn

- Relevanz der Forschungsfrage
- Hintergrund der Mindestlohneinführung
- sic
- Vergleich zu anderen Staaten
- Wie werden Unternehmensgewinne definiert?
- Theoretisch mathematischer Hintergrund / Ausgangspunkt
  - Messung Unternehmensgewinne
  - Messung Mindestlohn

### **"Jetzt 12€ Mindestlohn wählen."**

Ein zentrales Wahlkampfthema der SPD zur Bundestagswahl 2021. Es war nicht das erste Mal und wird auch nicht das letzte Mal gewesen sein, dass die Versprechung zur Verbesserung des Lohns ein zentrales Instrument der Arbeitsmarktpolitik ist, um eine große Wählerschaft zu mobilisieren.
Hinter diesem leicht verständlichen Versprechen steckt allerdings die komplexe Frage, wie die Lohnerhöhungen getragen werden.

Häufig wird in der Forschung die Frage der Auswirkungen auf die Beschäftigung betrachtet. Dabei treten Kontroversen auf und es herrscht keine Einigkeit in den Schlussfolgerungen.

Daher wählen wir mit unserer Analyse nach Draca et. al (2011) einen anderen Ansatz. Anstatt die Beschäftigung in den Vordergrund zu rücken, widmen wir uns der vorgelagerteten Frage, wie die Lohnsteigerungen innerhalb von Unternehmen kompensiert werden. Eine solche Betrachtungsweise ist nach den Autoren in der Forschung bisher weitestgehend unbeachtet geblieben.

Die Basis der Analyse bilden Unternehmensdaten aus dem Vereinigten Königreich (UK).


Quiz: Wie können Unternehmen die Lohnsteigerung kompensieren?

- Verkleinerung der Gewinnmarge [x]

- Weitergabe der Kostensteigerung an Verbraucher [ ]

- Effizienzsteigerung [ ]



**Hintergrund der Einführung**
Quellen: FES 09/2007
Wie in Deutschland, wurden und werden Löhne im Vereinigten Königreich teilweise durch Tarifverhandlungen festgelegt. Die Notwendigkeit der Einführung eines nationalen Mindestlohns wurde in Großbritannien durch den sinkenden Einfluss von Gewerkschaften gesehen. Haben im Jahr 1970 noch 80% der Arbeitnehmer von Tarifverträgen profitiert, so sank dieser Anteil bis 2000 um 50 Prozentpunkte.
Mit einem Machtwechsel im britischen Unterhaus, hin zur sozialdemokratischen Labour-Partei, kommt es zur Veränderung in der Arbeitsmarktpolitik. Zum 1. April 1999 wird der nationale Mindestlohn eingeführt.


Quiz: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien zur Einführung 1999 (in Pfund)?

- 3.60£ [x]

- 5.70£ [ ]

- 7.80£ [ ]



Weiter gilt zu erwähnen, dass der nationale Mindestlohn (NMW) nicht die erste Art des Mindestlohns im Vereinigten Königreich war. Von 1909 bis zum Jahr 1993 an wurden gesetzliche Mindestlöhne durch *Wage Councils* innerhalb von Branchen bestimmt. 
Das Novum des NMW liegt in der Reichweite über alle Branchen hinweg. Ähnlich wie die *Wage Councils*, gibt die unabhängige Niedriglohnkommission (LPC) eine Empfehlung zur Mindestlohnhöhe. Von 1999 an wird die Lohnhöhe fortlaufend von der Niedriglohnkomission angepasst.


Quiz: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn im UK im Jahr 2024 (in Pfund)?

- 9.11 [ ]

- 11.22 [x]

- 14.44 [ ]

https://www.gov.uk/national-minimum-wage-rates



**Unternehmensgewinne**


## Exercise 2 -- Datenüberblick

- Herkunft der Daten
- Wieso Großbritannien?
- Ausgewogenheit der Daten
- Datensatz WERS
- Datensatz main (FAME (Financial Analysis Made Easy(135)))
  - Gesetzliche Verpflichtung
  - Auch Analyse kleinerer Unternehmen möglich (135)
  - Betrachtung von Firmen mit Geschäftsjahr April-März (Filter-Sample) (135)
- Labor Force Survey (136f.)
  - Arbeitsumfeld
  
**Relevante Variablen**


Quiz: Um in den Datensatz einzutauchen eine kleine Frage zum Einstieg. Was glauben Sie, wieso wir Unternehmensdaten aus dem Vereinigten Königreich beziehen?

- Keine Kosten der Datenbeschaffung im Vereinigten Königreich [ ]

- Strengere Transparenzregeln in der Bilanzierung und eine zentrale Datenspeicherung [x]

- Die Daten sind anonymisiert und lassen eine unternehmensunabhängige Analyse zu [ ]



**Aufgabe**: Lesen Sie den Datensatz 'main_fame.dta' mit der Funktion 'read_dta' ein und speichern Sie den Datensatz unter 'dat_main'. Führen Sie den Code aus, indem Sie "check" drücken.
```{r "3_1"}
#Datensatz einlesen
dat = read_dta('main_fame.dta')
```
Um einen ersten Überblick über den Datensatz zu bekommen, geben sie die ersten Zeilen des Datensatzes mittels der Funktion head aus.
```{r "3_2"}
head(dat)
```
Wir erhalten eine Vielzahl an Variablen, die mehr oder minder relevant für unsere Analysen sind.

Widmen wir uns den wesentlichsten Variablen für unsere Analyse:

**regno**: Hier handelt es sich um eine bestimmte Nummer, mit der die Daten jedem bestimmten Unternehmen zugeordnet werden können.

**year**: Gibt das Jahr an, aus dem die Daten stammen. Dabei wird das zurückliegende Geschäftsjahr betrachtet.

**ln_avwage**: Benennt den logarithmierten Durchschnittslohn im Unternehmen.

**net_pcm**: Die Gewinnmarge eines Unternehmens wir durch die Division vom Nettogewinn durch den Gesamtumsatz im Geschäftsjahr angegeben.

**sic2**: Die Unternehmen werden in Großbritannien nach Branchen in unterschiedliche Branchen unterteilt. Der bis zu vierstellige UKsic (UK Standard Industrial Classification of Economic Activities) beschreibt dabei die Branchen.
Das oben ausgegebene Unternehmen besitzt den UKsic 7020. Die sic2-Zahl ist somit 70 und beschreibt Immobilienaktivitäten.   
(https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/guide-method/classifications/archived-standard-classifications/uk-standard-industrial-classification-1992--sic92-/uk-sic-2003.pdf)

**unionmem**: Beschreibt den Anteil an Gewerkschaftsmitgliedern innerhalb des Unternehmens.

**ptwk**: Anteil an Teilzeitarbeitern innerhalb der vierstelligen UKsic-Branche (sic4).

**female**: Frauenanteil bei Arbeitnehmern innerhalb des sic4.

**gorwk**: Gibt den Regierungsbezirk des jeweiligen Unternehmens an. 
((1) Tyne & Wear                    (12) East of England
(2) Rest of North East              (13) Central London
(3) Greater Manchester              (14) Inner London
(4) Merseyside                      (15) Outer London
(5) Rest of North West              (16) South East
(6) South Yorkshire                 (17) South West
(7) West Yorkshire                  (18) Wales
(8) Rest of Yorkshire & Humberside  (19) Strathclyde
(9) East Midlands                   (20) Rest of Scotland
(10) West Midlands (met county))


Werfen wir einen Blick auf die Variable *month*. Wir wollen sehen, wann die Unternehmen ihren Jahresbericht abgeben und damit ihr Geschäftsjahr beenden.
Gruppieren Sie hierfür den Datensatz *dat* nach dem Berichtsmonat *month*. Geben Sie anschließend die Anzahl der Einträge mittels der Funktion *length* an.
```{r "3_3"}
# dat %>% 
#   group_by(___) %>%
#   summarize(___(month))

dat %>% 
  group_by(month) %>%
  summarize(length(month))
```


Quiz: Alle unsere Daten weisen auf ein Ende des Geschäftsjahres im März hin. Können Sie sich erklären, warum?

- Anders als in Deutschland, endet das Geschäftsjahr im UK bei allen Unternehmen im März. [ ]

- Im Frühjahr gibt es im UK wenig Bewegung auf dem Arbeitsmarkt. Dadurch vermeiden wir unbekannte externe Effekte. [ ]

- Die Mindestlohneinführung findet nicht mitten im Geschäftsjahr statt [x]


## Exercise 2.1 -- Schaubild / Wahl der Gruppen

Es soll überprüft werden, wie sich die Einführung des Mindestlohns auf die unterschiedlichen Einkommen ausgewirkt hat. 
Um die Veränderung des Lohns zum Vorjahr zu messen, muss der Datensatz zunächst für jedes einzelne Jahr aufgeteilt werden.

Zu Beginn wird erneut der Datensatz aus Aufgabe 2 eingelesen.

**Aufgabe**: Führen Sie den Code aus, indem Sie "check" drücken.
```{r "4_4"}
dat_main = read_dta('main_fame.dta')

```

Um die Veränderung der Löhne von Geschäftsjahr zu Geschäftsjahr herauszufinden, muss der Datensatz nach Jahren aufgeteilt werden. Das gelingt, indem für jedes Jahr ein eigener Datensatz erstellt wird. Dafür muss der bereits eingelesene Datensatz dat_main zunächst gefiltert werden.

**Aufgabe**: Wählen Sie die passende Variable für das leere Feld und überprüfen Sie Ihre Eingabe durch "check".
```{r "4_5"}
# pcw95 = dat_main %>%
#   filter(___ == 1995) %>%
#   filter(avwage >= 3)

#
pcw95 = dat_main %>%
  filter(year == 1995)%>%
  filter(avwage >= 3)
```

-#Wieso werden nur Werte für avwage >= 3 gewählt? Verfälschung der Ergebnisse? Was für Unternehmen sind betroffen(sic überprüfen)?

```{r "4_6"}
dat_probe = dat_main %>% 
  filter(avwage < 3)
```


Nun befinden sich in pcw95 alle Daten aus dat_main, die aus dem Jahr 1995 stammen. 
Neben der Unterscheidung in den Jahren sollen zudem die Unterschiede der Ausgangslöhne herauskristallisiert werden.
Dazu werden die Löhne in Perzentile aufgeteilt.

**Aufgabe**: Erstellen Sie einen Vektor "percent95", der die logarithmierten Durchschnittslöhne in 100 Perzentile aufteilt. Nutzen Sie dafür die Funktion `quantile(dat,seq())`. Setzen Sie den fehlenden Wert in "seq()" ein, um einen Vektor der Länge 100 zu erhalten.

```{r "4_7"}
# percent95 = quantile(pcw95$ln_avwage, seq(0, 1, ___))

percent95 = quantile(pcw95$ln_avwage, seq(0, 1, 0.01))
```

Diese Aufteilung muss nun für jedes Jahr des Datensatzes wiederholt werden.

**Aufgabe**: Führen sie den Chunk durch *check* aus.

```{r "4_8"}

pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))

pcw97 = dat_main %>%
  filter(year == 1997)%>%
  filter(avwage >= 3)
percent97 = quantile(pcw97$ln_avwage, seq(0, 1, 0.01))

pcw98 = dat_main %>%
  filter(year == 1998)%>%
  filter(avwage >= 3)
percent98 = quantile(pcw98$ln_avwage, seq(0, 1, 0.01))

pcw99 = dat_main %>%
  filter(year == 1999)%>%
  filter(avwage >= 3)
percent99 = quantile(pcw99$ln_avwage, seq(0, 1, 0.01))

pcw00 = dat_main %>%
  filter(year == 2000)%>%
  filter(avwage >= 3)
percent00 = quantile(pcw00$ln_avwage, seq(0, 1, 0.01))

pcw01 = dat_main %>%
  filter(year == 2001)%>%
  filter(avwage >= 3)
percent01 = quantile(pcw01$ln_avwage, seq(0, 1, 0.01))

pcw02 = dat_main %>%
  filter(year == 2002)%>%
  filter(avwage >= 3)
percent02 = quantile(pcw02$ln_avwage, seq(0, 1, 0.01))


```


Nun können die Unterschiede in jedem einzelnen Perzentil von Jahr zu Jahr ermittelt werden. Die Differenzen sollen in einem Datensatz gespeichert werden. 

Dafür wird zunächst ein Datensatz erstellt, der sich an den Werten der Perzentile aus dem ersten Beobachtungsjahr 1995 richtet.

**Aufgabe**: Erstellen Sie einen Datensatz `diffperc` mittels der Funktion `data.frame`. Dieser soll zunächst die Werte aus `percent95` enthalten, welche durch `sort()` geordnet sind.

```{r "4_9"}

diffperc = data.frame(sort(percent95))
```


Der Datensatz diffperc kann jetzt um die Differenzen innerhalb der Perzentile erweitert werden.

**Aufgabe**: Führen Sie den Code mit "check" aus.

```{r "4_10"}
diffperc = diffperc %>%
  mutate("percentile" = c(0:100),
         "diff96" = percent96-percent95,
         "diff97" = percent97-percent96,
         "diff98" = percent98-percent97,
         "diff99" = percent99-percent98,
         "diff00" = percent00-percent99,
         "diff01" = percent01-percent00,
         "diff02" = percent02-percent01)

```


Für die Betrachtungsweise der Auswirkungen durch die Einführung des Mindestlohns sind zwei Differenzen von besonderer Bedeutung. Daher sollen die Änderung des Lohns im Jahr vor der Einführung (diff99) mit der Änderung im Jahr nach der Einführung (diff00) in einem Liniendiagramm gegenübergestellt werden.

```{r "4_11"}

#Graphik
library(ggplot2)

diffperc = filter(diffperc, percentile < 76 & percentile > 0)
ggplot(diffperc)+
  geom_line(aes(x = percentile, y = diff99), colour = "blue", linetype = 2, linewidth = 0.8)+
  geom_line(aes(x = percentile, y = diff00), colour = "red", linewidth = 0.8)+
  geom_vline(xintercept = 13)+
  geom_vline(xintercept = 50)+
  xlab("Perzentile der Ausgangsdurchschnittslöhne")+
  ylab("Änderung des logarithmierten Durchschnittslohns")

```

#-Mögliche Fragen zum Schaubild

-Wieso logarithmierte Werte?
-Woher kommt der Piek nach unten?




## Exercise 3 DiD -- Difference in Differences

**Möglicher Inhalt**
- Wieso braucht man DiD
- Voraussetzungen gegeben? (parallel-Trend)
- Was sagt er aus
- Vorteil ggü. anderer Methoden
- Wie werden die jeweiligen Gruppen gewählt? (136f.)
  - Treatment Group Indikatoren = FAME + LFS + WERS (136)
  - T = 1 für avwage < 12.000 im Geschäftsjahr vor NMW Einführung 
  - Durchschnitt in T = 1 = 8400 => 3,90 pro Stunde (nah bei NMW = 3,60)  
  - Plausible Treatment-Wahl? (137D.), Fig. 1
- Was gibt es für andere Schätzmethoden?
- Diagramm Variablenbeeinflussung
- Placebo-Effekt (142f.)
  - Imaginäre Einführung NMW im April 1996

**Vorgehen**
- Kernergebnisse erkennen
- Ausgangspunkt: Mindestlohn + Unternehmensgewinne
- Regression aufbauen

**Stichwörter**
- Quasi-experimenteller Rahmen NMW (133)
- Händische DiD-Schätzungsformel (133)
- Parallel-Trend: Unterschiede wären gleich geblieben, wenn es kein Treatment gegeben hätte

**Mögliche Aufgaben**
- Treatmentgruppenwahl entwickeln: 3,60 pro Stunde -> Schnitt 8400 im Jahr bei Vollzeit (Arbeitszeiten GB aufdröseln)


Die Auswirkungen des Mindestlohns auf die Unternehmensgewinne können mit Hilfe der Difference-in-Differences-Methode - kurz **DiD** - beobachtet werden.

**DiD-Methode**
Die DiD-Schätzung ist häufig geeignet, um kausale Effekte politischer Maßnahmen empirisch zu beurteilen.
Dabei werden die Daten in zwei zeitliche Perioden und zwei Gruppen eingeteilt. 
(Callaway, B., & Sant’Anna, P. H. (2021). Difference-in-differences with multiple time periods. Journal of econometrics, 225(2), 200-230., SEITE 2)
Gerade mit Hinblick auf Lohnentwicklungen stellte die Methode bereits in der Vergangenheit eine wichtige Grundlage. So können beispielsweise die Einflüsse von Schocks und fixer Effekte abgefedert werden und so die Auswirkungen einzelner Maßnahmen besser beurteilbar machen. (Quelle???) (Angrist, J. D., & Pischke, J. S. (2009). Mostly harmless econometrics: An empiricist's companion. Princeton university press.)

**Sind die Voraussetzungen gegeben? (Quiz)**
- Parallele Trends


**Parallele Trends**
Eine relevante Voraussetzung für das Anwenden der DiD-Methode wird die Parallel-Trends-Assumption (PTA) gehandelt. Diese besagt, dass ohne die Einführung eines Treatments, in unserem Fall der Mindestlohn, die Linien der Kontroll- und Treatmentgruppe weitestgehend parallel liefen. 
Annähernd kann das überprüft werden, indem man sich die Trendlinien der beiden Gruppen vor Einführung des Treatments ansieht. (Quelle???)

**Code**
```{r "5_12"}
  dat = read_dta('main_fame.dta')
```

```{r "5_13"}
dat_trend_treat = dat %>% 
  filter(ctreat1 == 1) %>%
  group_by(year)%>%
  summarise("Treatment"=mean(ln_avwage, na.rm = TRUE)) 
```
```{r "5_14"}
dat_trend_control = dat %>%
  filter(ctreat1 == 0) %>%
  group_by(year) %>%
  summarise("Control"=mean(ln_avwage, na.rm = TRUE))
```
```{r "5_15"}
dat_trend = left_join(dat_trend_treat, dat_trend_control)
```
```{r "5_16"}
ggplot(dat_trend)+
   geom_line(aes(x = year, y = Treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = Control), colour = "red", linetype = 1, linewidth = 0.8)+
   geom_vline(xintercept = 1999)
```

Quiz: Erkennen Sie einen parallelen Trend?

- Ja [ ]

- Nein [x]


In unserer Betrachtungsweise ist kein eindeutig paralleler Trend zu erkennen. Ist deshalb die DiD-Schätzung eine falsche Methode, um die Effekte der Mindestlohneinführung zu betrachten?
(Rambachan, A., & Roth, J. (2023). A more credible approach to parallel trends. Review of Economic Studies, 90(5), 2555-2591.)

Aufgrund des kurzen Betrachtungszeitraums des Trends sollte diese Einschätzung aber auch mit Vorsicht genossen werden: Es wird sich auf Trends bezogen, die sich auf sechs Datenpunkte (1994-1999) stützen. Die Betrachtung eines größeren Zeitraums könnte hier eine genauere Betrachtung zulassen.
Bezüglich der PTA gibt es seitens der Autoren keine weiterführenden Analysen, eine Erwähnung wird innerhalb des Artikels vergeblich gesucht.




## Exercise 3.1 -- Wahl der Gruppen


Bei der Difference in Difference (DiD) Methode werden die Daten anhand von zwei Kriterien unterteilt.
Zum einen wird entschieden widmen wir uns der Frage, ob es sich um eine Pre-Treatment oder eine Post-Treatment Gruppe handelt.

Zur Erinnerung: Der gesetzliche Mindestlohn wurde am 01. April 1999 eingeführt.


Quiz: Ab welchem Zeitpunkt werden Daten der Post-Treatment Gruppe zugewiesen?

- 1999 [ ]

- 2000 [x]

------------

**Treatment-Wahl**

Für eine DiD-Schätzung muss weiter eine Kontroll- und eine Treatmentgruppe definiert werden. In der Treatmentgruppe werden jene Unternehmen zusammengefasst, bei denen der Durchschnittslohn (avwage) im Jahr unter 12000 Pfund lag.
Die Kontrollgruppe umfasst Unternehmensdaten mit einem Durchschnittslohn zwischen 12000 und 20000 Pfund.

Im Mittelpunkt der Mindestlohneinführung steht der Wert von 3,60 Pfund pro Stunde. Da unser Datensatz allerdings keine Daten zu jedem Arbeitnehmer enthält, müssen wir uns an die Wahl der Treatmentgruppe nähern.



```{r "6_17"}
  dat = read_dta('main_fame.dta')

```
Die Variable, die den Lohn innerhalb eines Unternehmens am Besten widerspiegelt ist hierbei "avwage". Hierüber wird sich auch im Artikel genähert. Dabei werden alle Unternehmen mit einem avwage =< 12000 in die Treatmentgruppe einsortiert. 
Um zu verstehen, warum sich für diesen Wert als Obergrenze entschieden wird ist es hilfreich, den Wert in Zusammenhang mit dem Stundenlohn zu bringen.
Dazu soll zunächst der durchschnittliche Lohn aller Unternehmen aus der Treatmentgruppe in der Pre-Policy Periode ermittelt werden.

**Aufgabe**: Setzen Sie die passenden Werte in die Lücken ein. (Hinweis: Avwage wird im Datensatz in 1000 Pfund angegeben)
```{r "6_18"}
# mean_treat = dat %>%
#   filter(avwage <= ___) %>%
#   filter(year == ___) %>%
#   summarise(round(mean(avwage)*1000,2))
# mean_treat

mean_treat = dat %>%
  filter(avwage <= 12) %>%
  filter(year == 1999) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
```
```{r "6_19"}
mean_treat / 2000
```
Mit dieser Näherung kommt man in die Nähe des Mindestlohns. Dennoch ist dies auch mit Vorsicht zu genießen. Da die Wahl der Treatmentgruppe auf Durchschnittslöhne eines gesamten Unternehmens beruht, können große Ausreißer das Ergebnis beeinflussen. Es wird eine Vollzeitbeschäftigung vorausgesetzt, wobei der Anteil an Teilzeitarbeit im betrachteten Beispiel bei über 16% lag: (Quelle???)

```{r "6_20"}
mean(dat$ptwk, na.rm = TRUE)
```


Die Wahl der Treatmentgruppe kann allerdings weiter durch die Verwendung des WERS-Datensatzes untermauert werden. 
So kann die Lohnverteilung innerhalb eines Unternehmens mit dem Durchschnittslohn in Zusammenhang gebracht werden. Die Autoren kommen zu dem Schluss, dass 87% aller vom Mindestlohn profitierenden Arbeiter in Unternehmen arbeiten, in denen der jährliche Durchschnittslohn bei 12000 Pfund oder niedriger liegt. 
Wir wollen überprüfen, inwiwefern der Anteil an Lohnzahlungen unter 3,60 mit dem Durchschnittslohn zusammmenhängt.

**Figure 1**
```{r "6_21"}
dat_seq = read_dta('seq98.dta')
```
Nun haben wir im ersten Schritt die Gruppen und Perioden definiert. Als nächstes werden wir die Daten aktiv den jeweiligen Gruppen zuordnen und zusammenfassen.

## Exercise 3.2 -- händische DiD-Berechnung

Mit einem Blick auf den Datensatz erkennt man, dass für die unterschiedlichen Gruppen bereits Dummy-Variablen erstellt worden sind.

**Aufgabe**: Laden Sie erneut den bereits bekannten Datensatz und geben Sie die ersten Zeilen aus, indem Sie lediglich "check" drücken.
```{r "7_22"}
dat = read_dta('main_fame.dta')

```
Führen Sie nun den folgenden Code aus, indem Sie den Datensatz nach den für die DiD-Schätzung relevanten Variablen gruppieren. Dadurch erhalten Sie eine Tabelle, die alle relevanten Daten für eine händische Berechnung enthält.
```{r "7_23"}
# dat_table_DiD = dat %>%
#   ___(ctreat1, NMW)%>%
#   filter(pp == 1) %>%
#   summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))

dat_table_DiD = dat %>%
  group_by(ctreat1, NMW)%>%
  filter(pp == 1) %>%
  summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))
```


Quiz: Wieso wird der Mittelwert verwendet und nicht nur die beiden Jahre vor und nach der Mindestlohneinführung?

- Durch die Betrachtung können kurzfristige Schwankungen und zufällige Effekte abgefedert werden. [x]

- Um einen deutlicheren Unterschied zwischen den beiden Perioden zu erhalten. [ ]

- ??? [ ]


**Wieso wird der Dummy "pp" angewandt?**

Im obigen Code wird der Datensatz anhand der Variablen "pp" gefiltert.


Quiz: Wieso und nach welchem Kriterium könnte hier gefiltert werden?

- Es gibt starke Unterschiede in der Berichterstattung zwischen den Ländern im UK. Daher fokussieren wir uns auf England. [ ]

- Aufgrund einer höheren Teilzeitquote bei Frauen, filtern wir hier nach Geschlecht und legen den Fokus auf die Männer. [ ]

- Da kleinere Firmen von manchen Teilen der Berichterstattung befreit sind, sind ihre Daten unvollständig. Daher werden sie nicht weiter berücksichtigt. [x]


Werfen wir einen Blick auf die aussortierten Daten und überprüfen anhand der Beschäftigungszahlen, ob es Aufffälligkeiten gibt:


Quiz: Anhand welcher kennzahlen können wir die oben erwähnten kleinen Unternehmen erkennen?

- a [ ]

- b [x]

- c [ ]


```{r "7_24"}
dat_no_pp = dat %>%
  filter(pp == 0)

dat_pp = dat %>%
  filter(pp == 1)

boxplot(log(dat_no_pp$emp),log(dat_pp$emp))
boxplot(log(dat_no_pp$net_pcm),log(dat_pp$net_pcm))
boxplot(log(dat_no_pp$avwage),log(dat_pp$avwage))
boxplot((dat_no_pp$manuf),(dat_pp$manuf))
boxplot(log(dat_no_pp$turnemp),log(dat_pp$turnemp))

```



Im Gesamten ist zu erkennen, dass die Daten, die sich nicht in der Auswahl befinden, breiter gestreut sind.
Wir erkennen einen Unterschied in den Beschäftigungszahlen der beiden Gruppen.
Im Vereinigten Königreich sind **kleinere Unternehmen** von der Veröffentlichung bestimmter Daten befreit. Um eine vollumfängliche Analyse zu gewährleisten entscheiden sich die Autoren daher ein Unterbeispiel zu erstellen, in denen Daten vollumfänglich erfasst werden (S. 135).
Das schränkt allerdings auch die Bewertung ein, lenkt den Blick weg von kleineren Unternehmen und muss bei der Betrachtung der Ergebnisse bedacht werden.
Wie die Autoren die Auswahl des Unterbeispiels treffen wird nicht leider vollumfänglich bekannt und auch unsere Überlegungen lassen nur Mutmaßungen zu.



Nachdem die relevanten Daten des DiD zusammengefasst in der Tabelle "dat_table_DiD" vorhanden sind, können die Differenzen nun händisch berechnet werden.

Die Formel hierfür lautet 
***(y.post.treat - y.pre.treat) - (y.post.control - y.pre.control)***
(S. 133)

Der erste Teil beschreibt die Veränderung in der Treatmentgruppe durch das Treatment. Um andere Einflussfaktoren wie saisonale Effekte herauszurechnen, wird im zweiten Teil die Veränderung in der Kontrollgruppe berechnet, welche im Idealfall nicht vom Treatment betroffen ist.

**Aufgabe**: Werfen Sie zunächst einen Blick auf die erzeugte Tabelle und überlegen Sie, welcher Gruppe die jeweiligen Werte angehören. Lassen Sie sich dafür die oben erstellte Tabelle anzeigen und überprüfen Sie Ihre Eingabe mittels "check".

```{r "7_25"}

dat_table_DiD
```


Quiz: Welche Spalte beschreibt die Kontroll- bzw. Treatmentgruppe?

- ctreat1 [x]

- NMW [ ]



Quiz: Von welcher Gruppe ist die Rede, wenn NMW = 1 ?

- Pre-Treatment [ ]

- Post-Treatment [x]


**Aufgabe**: Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
```{r "7_26"}
# # Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
# y1.post.treat = dat_table_DiD$mean_ln_avwage[___]
# y1.post.control = dat_table_DiD$mean_ln_avwage[___]
# y1.pre.treat = dat_table_DiD$mean_ln_avwage[___]
# y1.pre.control = dat_table_DiD$mean_ln_avwage[___]
# 

y1.post.treat = dat_table_DiD$mean_ln_avwage[4]
y1.post.control = dat_table_DiD$mean_ln_avwage[2]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[3]
y1.pre.control = dat_table_DiD$mean_ln_avwage[1]

```


Quiz: Wieso werden für den Durchschnittslohn logarithmierte Werte verwendet?

- a [x]

- b [ ]

- c [ ]



Quiz: Wieso gibt es in der Kontrollgruppe eine Obergrenze (20000 = Median)?

- a [ ]

- b [x]

- c [ ]

Neben des logarithmierten Durchschnittslohns wird auch der DiD-Schätzer der Nettorendite eines Unternehmens je Geschäftsjahr (net_pcm) berechnet.
Das geschieht analog zur obigen Schätzung.

**Aufgabe**: Werfen Sie erneut einen Blick auf die erstellte Tabelle und geben Sie nun die Zeilen ein, in denen der passende Wert steht.
```{r "7_27"}
# y2.post.treat = dat_table_DiD$mean_net_pcm[___]
# y2.post.control = dat_table_DiD$mean_net_pcm[___]
# y2.pre.treat = dat_table_DiD$mean_net_pcm[___]
# y2.pre.control = dat_table_DiD$mean_net_pcm[___]

y2.post.treat = dat_table_DiD$mean_net_pcm[4]
y2.post.control = dat_table_DiD$mean_net_pcm[2]
y2.pre.treat = dat_table_DiD$mean_net_pcm[3]
y2.pre.control = dat_table_DiD$mean_net_pcm[1]
```

Die Werte sind nun gespeichert und die DiDs können berechnet werden.

**Aufgabe**: Fügen Sie dem Code das Anzeigen der Ergebnisse hinzu und führen Sie den Code mittels "Check" aus.
```{r "7_28"}
# DiD_ln_avwage = (y1.post.treat - y1.pre.treat) - (y1.post.control - y1.pre.control)
# DiD_net_pcm = (y2.post.treat - y2.pre.treat) - (y2.post.control - y2.pre.control)
#   
# #Ergebnisse anzeigen
# 

DiD_ln_avwage = (y1.post.treat - y1.post.control) - (y1.pre.treat - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.post.control) - (y2.pre.treat - y2.pre.control)
  
#Ergebnisse anzeigen
DiD_ln_avwage
DiD_net_pcm
```

Durch die Einführung des Mindestlohns können wir sagen, dass dadurch in den beobachteten Unternehmen der Durchschnittslohn gestiegen ist. Zugleich ist zu erkennen, dass in jenen Unternehmen der Nettogewinn zurück gegangen ist.

Um diese Veränderung genauer bewerten zu können und tiefergehende Analysen zu ermöglichen, machen wir uns die Methode der Regression zu eigen.


## Exercise 3.3 -- DiD-Schätzung mittels Regression

**Theorie**
- Cluster-Robuste Standardfehler
  - Geclustert nach Regno (unternehmen)
- Genestete Daten

**DAG**

Zu Beginn widmen wir uns der Veränderung im Durchschnittslohn durch die Einführung des Mindestlohns.
Um uns einen ersten Überblick über die Zusammenhänge der Variablen in unserer DiD-Schätzung zu verschaffen, sind die Directed Acyclic Graphs (DAGs) von Vorteil.
Führen Sie hierfür den Code mittels check aus und sehen Sie sich den Graphen an.
(https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html)
(https://r-causal.github.io/ggdag/)

```{r "8_29"}
dag <- dagify(
  ln_avwage ~ ctreat1 + treat1_NMW + NMW, 
  treat1_NMW ~ ctreat1 + NMW,
  labels = c(ctreat1 = "ctreat1", treat1_NMW = "treat1_NMW", NMW = "NMW", ln_avwage = "ln_avwage")
)

ggdag(dag, node_size = 18, text = FALSE, edge_type = "link", use_labels = "label")+
  theme_dag_blank()
```
Hier sieht man, warum der Effekt von treat1_NMW in Regression III so stark von dem in Regression IV abweicht. , nicht nur eine Regression mit der Interaktionsvariablen durchzuführen, sondern auch mit den beiden einzelnen Dummy-Variablen.

**Aufgabe**: Lesen Sie einen Auszug des bekannten Datensatzes dat_main ein, indem Sie den Code mit "check" ausführen.
```{r "8_30"}
dat_raw = read_dta('main_fame.dta')
dat = filter(dat_raw, pp == 1) 
```
Zu Beginn unserer Analyse wollen wir mehrere Regressionen mit den oben dargestellten Variablen laufen lassen. 
Dazu sollen die einzelnen Variablen, die "ln_avwage" beeinflussen, beobachtet werden.


***

### Info: stargazer
Die Stargazer Funktion ermöglicht uns einen schön formatierten Output mit der Möglichkeit, mehrere Regressionen parallel darzustellen.
(https://www.rdocumentation.org/packages/stargazer/versions/5.2.3/topics/stargazer)

***


Führen Sie die Regression aus und stellen Sie das Ergebnis mittels der stargazer-Funktion dar.
```{r "8_31"}
# regi = lm(ln_avwage ~ treat1_NMW, data = dat)
# 
# stargazer(___, type = "text")

regi = lm(ln_avwage ~ treat1_NMW, data = dat)

stargazer(regi, type = "text")
```


Quiz: Wieso ist der Einfluss der Treatmentvariablen im Gegensatz zur händischen Berechnung negativ?

- Die Regression ist genauer als die händische Berechnung. [ ]

- Die Regression ist fehlerhaft. [x]



Wir müssen in unserer Regression also sowohl die Interaktionsvariable als auch die die abhängige Variable beeinflussenden Dummys berücksichtigen.


$ln(avwage) = \beta_0 + \beta_1 ctreat + \beta_2 treat1*NMW + \beta_3 NMW + \epsilon$

Berechnen Sie auf Basis dieser Formel die Einflüsse der Variablen und das damit zusammenhängende DiD-Ergebnis. Stellen Sie das Ergebnis wieder in "stargazer" dar.

```{r "8_32"}
# reg1 = lm(ln_avwage ~ ___ + ___ + ___, data = dat)
# stargazer(reg1, type = "text")


reg1 = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW, data = dat)
stargazer(reg1, type = "text")
```
Der Wert der Interaktionsvariablen hat sich im Vergleich zur unvollständigen Regression stark verändert und erinnert an die händische Berechnung.

Um diese starke Veränderung besser zu verstehen, können wir die gemeinsame Betrachtung der erklärenden Variablen mit der einzelnen Betrachtung vergleichen.

Führen Sie dazu den Code aus und sehen sich die Ausgabe an.
```{r "8_33"}
regii = lm(ln_avwage ~ ctreat1, data = dat)

regiii = lm(ln_avwage ~ NMW, data = dat)

stargazer(regi, regii, regiii, reg1, type = "text")

```
Im Gegensatz zur händischen Berechnung können wir durch die Regression die Signifikanz unserer Schätzung beurteilen.


Quiz: Wie beurteilen Sie die Signifikanz unseres DiD-Schätzers in der dargestellten Regression?

- hoch [x]

- niedrig [ ]



**Genestete Daten**
(Bryk, Raudenbush: Hierarchical Linear Models: Applications and Data Analysis Methods)
Die Werte der Variablen sind im obigen Fall also hoch signifikant gekennzeichnet. 
Allerdings können die p-Werte fehlerhaft sein, da es sich bei den Daten teilweise um genestete Daten handelt. 
Genestete Daten liegen vor, wenn mehrere Daten zu einer übergeordneten Einheit zählen.
In unserem Fall haben wir Daten zum logarithmierten Durchschnittslohn (ln_avwage) über mehrere Jahre. Diese haben ein Unternehmen (regno) als übergeordnete Einheit.
Um Fehler bezüglich genesteter Daten zu verhindern, führen wir Clusterrobuste Standardfehler ein.


Quiz: Nach welcher Variablen soll geclustert werden?

- ln_avwage [ ]

- regno [x]


Nun fügen wir die **Clusterrobusten Standardfehler** ein und schauen, was sich dadurch verändert.

Führen Sie hierzu die Regression durch und vergleichen die Regression ohne Clustering (reg1) mit der Regression mit Clustering.
```{r "8_34"}
# reg2 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW|0|0|regno, data=dat)
# stargazer(___, ___, type ="text")

reg2 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW|0|0|regno, data=dat)
stargazer(reg1, reg2, type ="text")
```


An den Werten der Variablen ist keine Veränderung zu erkennen. Allerdings haben sich die Werte der Standardfehler verändert.
Während man für ctreat1 und die Interaktionsvariable eine Erhöhung des p-Wertes vorfindet, ist eine Verringerung bei der Variablen NMW zu verzeichnen.

Um diese Veränderungen zu verstehen sehen wir uns an, was es generell mit **clusterrobusten Standardfehlern** auf sich hat:
(Angrist, 231ff) / 
(Abadie, A., Athey, S., Imbens, G. W., & Wooldridge, J. M. (2023). When should you adjust standard errors for clustering?. The Quarterly Journal of Economics, 138(1), 1-35.)
Variiert der Regressor nur innerhalb einer Clustergruppe, so kann der Standardfehler steigen (231)


---------------

**Ergebnisanalyse**

Die Variablen beschreiben die Veränderungen im Vergleich zum Pre-Policy Jahr, welche mit Constant beschrieben wird.
- Wie wirken die unterschiedlichen Variablen?
- Werte zuordnen


Quiz: In welcher Einheit wird der DiD-Wert beschrieben?

- Pfund [ ]

- Prozent [ ]

- Prozentpunkte [x]



----------------
**NET_PCM**

Wir haben in Erfahrung gebracht, dass es einen Effekt durch die Einführung des gesetzlichen Mindestlohns gibt. 
Um herauszufinden, wie die Unternehmen auf diese Veränderung reagieren, sehen wir uns spiegelbildlich zur obigen Schätzung die Veränderung auf die Gewinnmarge *net_pcm* an.


```{r "8_35"}
reg2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data = dat)

stargazer(reg2, type = "text")
```
-------------

Sehen wir uns weiter an ob es zu Veränderungen kommt, wenn wir auf bestimmte Effekte der Unternehmenswelt kontrollieren.
Dafür können wir uns die Funktion der Faktorvariablen zunutze machen.

## **Faktorvariablen**
Da wir bei nominalskalierten Daten keine Möglichkeit zur messbaren Unterscheidung finden, müssen wir Faktorvariablen nutzen, um diskrete Daten in die Regression miteinzubeziehen. 
Technisch umsetzbar wird diese Faktorisierung, indem eine Gruppe die Referenz bildet. Statistisch gesehen geht diese Wahl willkürlich vonstatten, inhaltlich gibt es nach Hardy (1993) drei Grundüberlegungen zur Wahl der Referenzgruppe:

So soll die Referenzgruppe 

1. Einen sinnvollen Vergleich bieten

2. Klar definiert sein

3. Eine ausreichend große Stichprobengröße im Vergleich zu anderen Gruppen besitzen


(https://learning.oreilly.com/library/view/applied-multiple-regression-correlation/9780805822236/xhtml/15_Chapter_08.xhtml#h8_2 
=> Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). "Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences.", Kapitel 8.2)



***

### Info: factor
In R können wir entweder die Variablen innerhalb der Regression faktorisieren, oder bereits im Datensatz.

***


Die Variable *year* möchten wir in unserem Datensatz faktorisieren und erstellen hierfür eine neue Variable *factor_year*. Vergleichen Sie weiter die Werte der neuen mit der bereits existierenden Variablen, indem Sie sich mittels *head()* die ersten Einträge anzeigen lassen.
```{r "8_36"}
dat = dat %>%
  mutate("factor_year" = factor(year))

head(dat$year)
head(dat$factor_year)
```
Die Einträge scheinen zunächst identisch, dennoch ist bei unserer faktorisierten Variablen der Eintrag *Levels* zu finden.

Levels gibt die unterschiedlichen Kategorien innerhalb der Variablen an. Dabei stellt die erste Kategorie die Referenzkategorie dar.


Quiz: Wie bewerten Sie die gewählte Referenzkategorie? (Denken Sie dabei an die oben beschriebenen Grundüberlegungen)

- Das Jahr 1997 ist sinnvoll gewählt, da es den Startpunkt unserer Analyse markiert. [ ]

- Es gibt andere Jahre, die auf Basis unserer Analyse einen wichtigeren Punkt markieren [x]

- Alle Jahre sind gleich relevant und die Grundüberlegungen treffen auf jedes Jahr zu. Daher kann das Jahr beliebig gewählt werden. [ ]


Eine besser geeignete Referenzkategorie können wir selbst festlegen:
```{r "8_37"}
dat$factor_year = relevel(dat$factor_year, ref = "2000")
```



Sehen wir uns nun an, was diese Faktorisierung für die Regression bedeutet, indem wir die Regression einmal mit *year* und einmal mit *factor_year* ergänzen.
```{r "8_38"}
reg2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data = dat)
reg2.1 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + year| 0 | 0 | regno, data = dat)
reg2.2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + factor_year| 0 | 0 | regno, data = dat)
reg2.3 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + factor(year)| 0 | 0 | regno, data = dat)


stargazer(reg2, reg2.1, reg2.2, reg2.3, type= "text")
```
Wir sehen, dass sich die Ergebnisse durch eine Faktorisierung verändern.
Ebenfalls durch die Veränderung der Referenzkategorie entstehen Unterschiede, wenn auch im überschaubaren Rahmen. 

Dabei gilt dennoch zu erwähnen, dass die Autoren des Artikels bei der Wahl der Referenzkategorie wohl einer anderen Idee der Wahl gefolgt sind und das Jahr 1997 als Referenz gewählt haben. 


Da durch die Darstellung der Faktorvariablen eine längere Ausgabe entsteht, kann es beim Hinzufügen mehrerer Faktorvariablen aus Gründen der Übersichtlichkeit und Vergleichbarkeit sinnvoll sein, unsere Ausgabe auf das Relevanteste reduzieren.

Hierbei lernen Sie eine alternative Darstellung der Regressionsergebnisse zu *stargazer* kennen.

Laden Sie hierfür zunächst das Paket *broom*
```{r "8_39"}
# library(___)

library(broom)
```
Führen Sie den Code aus, um aus der Liste - die uns durch die *felm*-Funktion erstellt wird - eine Tabelle der Regression zu kreieren.
Geben Sie anschließend die Tabelle aus.
```{r "8_40"}
# table_reg2.3 = tidy(reg2.3)
# 
# #Tabelle ausgeben
# 

table_reg2.3 = tidy(reg2.3)

#Tabelle ausgeben
table_reg2.3
```
Nun haben wir die relevanten Werte der Regression in der Tabelle gespeichert und können darauf wie auf jeden anderen Data Frame zurückgreifen.

(https://cran.r-project.org/web/packages/broom/vignettes/broom.html)



-----------

**Table 2, Panel A**
```{r "8_41"}
reg3 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg3, type = "text")
```

```{r "8_42"}
reg4 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg4, type = "text")
```

**Table 2, Panel B**

**Kontinuierliche Messung**

Bisher haben wir uns auf die Unterscheidung zwischen Treatment und keinem Treeatment konzentriert. Dabei wurde deutlich, dass sowohl einen signifikante positive Änderung des Lohns, als auch eine negative signifikante Veränderung der Gewinnmarge vorhanden sind. Da diese sich diese Unterscheidung allerdings auf die vorangegangene eigene Definition der beiden Gruppen stützt, kann die Betrachtung durch eine weitere Methode hilfreich sein. Zudem wollen wir einen genaueren Effekt je nach Einkommen erhalten.

Im Vergleich zur diskreten Messung wird bei der kontinuierlichen Messung kein Dummy für die Treatments verwendet, sondern ein bestimmter Wert.


Um diese kontinuierliche Analyse zu ermöglichen, wird anstatt der Treatmentvariablen *ctreat1* eine andere Variable gewählt.
In unserem Fall ist das *c_avwage99* und beschreibt den logarithmierten Durchschnittslohn zum Jahr 1999 nach Unternehmen gruppiert.

**Diskrete Daten vs. Kontinuierliche Daten**

| Merkmal             |     Diskrete Daten      |     Kontinuierliche Daten     |
|---------------------|-----------------------  |-------------------------------|
| Generell            |                         |                               |
| Vorteil             |                         |                               |   
| DiD-Schätzung       | Verwendung von Dummys   | Verwendung konkreter Werte    |
| Treatmentvariable   | ctreat                  | c_avwage99                    |
| Werte               | 0 oder 1                | logarithmierter Durchschnittslohn im Jahr 1999 |


```{r "8_43"}
reg5 = felm(ln_avwage ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg6 = felm(net_pcm ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg5, reg6, type = "text")
```
WAS HAT SICH GEÄNDERT?
WIE KANN DAS ERGEBNIS INTERPRETIERT WERDEN?
WIESO BRAUCHT MAN DAS?
  - Vergleich zur imaginären Einführung



## Exercise 3.4 -- Imaginäre Mindestlohneinführung

- Sind die Veränderungen auf das Treatment zurückzuführen?
  - Vergleich zu Parallel-Trend
- Imaginäre Einführung am 1. April 1996
- Vergleich Datensätze: ff=0 vs. ff=1
- Table 3
- Figure 3

Um zu überprüfen, ob die Mindestlohneinführung der Grund für die Ergebnisse der DiD-Schätzung ist, kann ein **Placebo Experiment** eingeführt werden.(142ff.)
Hierfür wird die Mindestlohneinführung imaginär um drei Jahre vorverlegt, auf den 01. April 1996.
Dabei können wir auf Vorarbeit im Datensatz zurückgreifen. Ähnlich wie bei der vorangegangenen Schätzung zur realen Mindestlohneinführung wird der Datensatz anhand eines Dummys gefiltert.

Lesen Sie den Datensatz ein und teilen ihn nach den Dummywerten von ff auf.
```{r "9_44"}
dat = read_dta('main_fame.dta')
dat_ff1 = filter(dat, ff == 1)
dat_ff0 = filter(dat, ff == 0)
```
Um zu verstehen, warum manche Einträge von Firmen ausgelassen werden, hilft ein Vergleich der oben erstellten Variablen.

Gruppieren Sie dazu die Datensätze nach den Jahren und geben sie die Anzahl der Einträge pro Jahr aus. Hinweis: Die Funktion length(*Variable*) gibt die Anzahl der Einträge wieder.
```{r "9_45"}
dat_ff1 %>%
  group_by(year)%>%
  summarise(length(year))

dat_ff0 %>%
  group_by(year)%>%
  summarise(length(year))
```
Es fällt auf, dass sich im untersuchten Datensatz nur Einträge befinden, die sich auf den Zeitraum **vor** der reellen Mindestlohneinführung beziehen.

Allerdings werden auch Daten aus den Jahren 1994 - 1999 herausgefiltert. Sehen wir uns an, wie das mit dem von den Autoren gefundene Unterbeispiel (pp) zusammenhängt.

```{r "9_46"}
dat_ff0 %>%
  group_by(pp)%>%
  summarise(length(pp))

dat_ff1 %>%
  group_by(pp)%>%
  summarise(length(pp))
```
Der Anteil an pp==0 ist im unberücksichtigten Datensatz deutlich höher als im am Ende betrachteten Datensatz dat_ff1. Allerdings werden nun auch Unternehmen berücksichtigt, die bei den Analysen zur reellen Mindestlohneinführung nicht berücksichtigt wurden.
Der Grund dafür könnte sein, dass sich die Zahlen in den Unternehmen verändert haben.???

```{r "9_47"}
dat_ff0 = filter(dat_ff0, year==1996)
dat_ff1 = filter(dat_ff1, year==1996)
boxplot(dat_ff0$ln_avwage,dat_ff1$ln_avwage)
mean(dat_ff0$avwage, na.rm = TRUE)
mean(dat_ff1$avwage)
max(dat_ff1$avwage)
```

Wie in den vorherigen Analysen sind nicht alle Ursachen für die Aussortierung einiger Daten erkennbar. 
Weiter werden wir die Analysen mit dem von den Autoren gegebenen Unterbeispiel durchführen.

Dafür können wir dieselbe Regression wie im Kapitel 3.3 verwenden mit dem Unterschied, dass der Datensatz nun nach ff gefiltert wird.
```{r "9_48"}
dat = filter(dat, ff == 1)
```
**Diskret**
```{r "9_49"}
reg7 = felm(ln_avwage ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg8 = felm(net_pcm ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg7, reg8, type = "text")
```


**Kontinuierlich**
```{r "9_50"}
reg9 = felm(ln_avwage ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg10 = felm(net_pcm ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg9, reg10, type = "text")
```
----------------

**Vergleich Fig 3**
- Treatmenteffekt net_pcm

Intervalle erstellen
```{r "9_51"}
pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))
```
```{r "9_52"}
dat_fig3 = dat %>%
  mutate("threshold" = round(exp(c_avwage99)*1000,-2)) %>%
  filter(threshold <= 16000) %>%
  filter(threshold >= 10000) %>%
  
  group_by(threshold) %>%
  summarise(length(threshold), mean(avwage99_NMW))
```

Regression in 100er Schritten durchführen und wiederholen. Die grenze wird nach oben verschioben und es werden immer mehr Einträge berücksichtigt.
Ergebnisse je 100 in Liste speichern

```{r "9_53"}
#Neuen Datensatz erstellen
dati = read_dta('main_fame.dta')
dati = filter(dati, pp==1)

```




```{r "9_54"}
library(ggplot2)
ggplot(dat_fig3, aes(x = threshold))+
  geom_line(aes(y = avwage99_NMW))

```




## Exercise 4 -- Einordnung des Artikels (weiterführende Überlegungen)

- EU-weiter Mindestlohn (Möglichkeiten, Chancen, Probleme)
- Unterschiede zu 1999 (Andere Rahmenbedingungen?, Brexit?)
- unberücksichtigte Variablen
- Auswirkung auf Beschäftigung
- weitere Artikel (andere Auswirkungen untersucht)
- Strukturen in Unternehmen
- Ist der Mindestlohn zu befürworten? (sozial, ökonomisch)



## Exercise Anregungen

- "Aber was sind die Produktionskosten - des Arbeiters, d.h. die Kosten, um den Arbeiter selbst zu produzieren?" / "Wert der Arbeit" (Kapital, 497)


## Exercise Probleme beim Code

- i. Dummyvariablen in Stata
- Intervallregression


## Exercise Aufgabentypen 

a) We often want to compute some summary statistic of a vector. For example:

```{r "13_a_55"}
x = 10:23
# Computing the sum of x
sum(x)
```

Now compute the mean of x.
```{r "13_a_56",optional=TRUE}
# Note the chunk option optional = TRUE means
# the user can continue with the next exercise
# without having solved this one

mean(x)
```



***

### Info: useful functions for numeric vectors
Here are examples for useful R functions
```{r "13_a_57"}
max(c(1,5,2)) # returns maximum
min(c(1,5,2)) # returns minimum

sum(c(1,5,2,NA), na.rm=TRUE) # returns sum of all numbers, ignore NA
cumsum(c(1,5,2)) # returns cummulated sum
diff(c(1,5,2)) # returns the vector of differences
```

***




***

### Award: mean means mean
Well, in some occasions one can just guess the name of an R function. The function to compute the mean of a vector, or matrix is called 'mean'. Usually, it is much quicker to goggle than to guess function names, however.

***


b) Let `y` be a vector that contains the squared elements of `x`, i.e. for each element $i$ we want $$y_i = x_i^2.$$ Then show `y`.
```{r "13_b_58"}
# We should not set this chunk optional
# since we need y in the next chunk
y = x^2
y
```

c) Now use the function `qplot` from the package `ggplot2` to create a scatter plot of `x` against `y`. You can google `r qplot` to get the help for the function `qplot`.

```{r "13_c_59",optional=TRUE, dev='svg', fig.width=4}
library(ggplot2) # load ggplot2 package

# Enter your call to qplot here...
qplot(x,y)
# The block above allows the user to add extra arguments to the call to qplot, i.e. qplot(x,y,xlab="The variable x"), would also pass the test.
```



Quiz: What is the 'oddest' prime?

- 2 [x]

- 3 [ ]

- 5 [ ]

- 7 [ ]


Note: A quiz as specified below only works in the shiny environment. If you want to design a quiz in an RMarkdown based RTutor problem set, you should use a chunk. E.g. as follows:

Which of the following numbers is the oddest prime? 2,3,5 or 7? Enter you solution in the code below and press "check".

```{r "13_c_60"}
2
```

***

### Award: The oddest prime
Wouldn't you agree that the only even prime is the odd man out?

***


## Exercise Submitting your solution

To submit your solution please proceed as follows:

1. Scroll to the top and click on the icon with the bars <i class="fa fa-tasks fa-fw"></i> to see how many points you got so far. If you want to have more points you can try to solve the missing tasks.

2. If you want to submit click on the download button <i class="fa  fa-download fa-fw"></i> at the very right.

3. In the opened tab click the button "Download Submission File". Your browser should then download a file with the extension `.sub`.

4. Upload that downloaded file to your course management system like Moodle, as specified by your instructor.




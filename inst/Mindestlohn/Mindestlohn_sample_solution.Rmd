
```{r 'check_ps', include=FALSE}

user.name = 'Jane Doe'
```

## Mindestlohn und Firmenprofitabilität: Eine interaktive Analyse

- Einführung .



## Exercise Inhaltsübersicht

1. Einführung in den Mindestlohn

2. Datenüberblick

3. Difference in Differences

4. Einordnung des Artikels

**Ideen**
Diagramm Variablenbeeinflussung


## Exercise 1 -- Einführung in den Mindestlohn

- Relevanz der Forschungsfrage
- Hintergrund der Mindestlohneinführung
- sic
- Vergleich zu anderen Staaten
- Wie werden Unternehmensgewinne definiert?
- Theoretisch mathematischer Hintergrund / Ausgangspunkt
  - Messung Unternehmensgewinne
  - Messung Mindestlohn

**"Jetzt 12€ Mindestlohn wählen."**
Ein zentrales Wahlkampfthema der SPD zur Bundestagswahl 2021. Es war nicht das erste und wird auch nicht das letzte Mal sein, dass die Versprechung zur Verbesserung des Lohns ein zentrales Instrument der Arbeitsmarktpolitik ist, um die Gunst der Wähler zu gewinnen.
Hinter diesem leicht verständlichen Versprechen steckt die komplexe Frage, wie die Lohnerhöhungen getragen werden.
Besonders die Frage der Auswirkungen auf die Beschäftigung wirft in der Forschung Kontroversen auf.

Daher wählen wir mit unserer Analyse nach Draca et. al (2008) einen anderen Ansatz. Anstatt die Beschäftigung in den Vordergrund zu rücken sehen wir uns an, wie die Lohnsteigerungen innerhalb von Unternehmen kompensiert werden. 



Quiz: Wie können Unternehmen die Lohnsteigerung kompensieren?

- Verkleinerung der Gewinnmarge [x]

- Weitergabe der Kostensteigerung an Verbraucher [ ]

- Effizienzsteigerung [ ]



**Hintergrund der Einführung**
Quellen: FES 09/2007
Wie in Deutschland, wurden und werden Löhne teilweise durch Tarifverhandlungen festgelegt. Die Notwendigkeit der Einführung eines nationalen Mindestlohns wurde in Großbritannien durch den sinkenden Einfluss von Gewerkschaften gesehen. Haben im Jahr 1970 noch 80% der Arbeitnehmer von Tarifverträgen profitiert, sank dieser Anteil bis 2000 um 50 Prozentpunkte.
Mit einem Machtwechsel im britischen Unterhaus, hin zur sozialdemokratischen Labour-Partei, kommt es zur Veränderung in der Arbeitspolitik. Zum 1. April 1999 wird der nationale Mindestlohn eingeführt.

Quiz: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien zur Einführung 1999 (in Pfund)?

- 3.6 [x]

- 5.7 [ ]

- 7.8 [ ]



Weiter gilt zu erwähnen, dass der nationale Mindestlohn (NMW) nicht die erste Art des Mindestlohns in Großbritannien war. Von 1909 bis zum Jahr 1993 an wurden gesetzliche Mindestlöhne durch *Wage Councils* innerhalb von Branchen bestimmt. 
Das Novum des NMW liegt in der Reichweite über alle Branchen hinweg. Ähnlich wie die *Wage Councils*, gibt die unabhängige Niedriglohnkommission (LPC) eine Empfehlung zur Mindestlohnhöhe. Von 1999 an wird die Lohnhöhe fortlaufend von der Niedriglohnkomission angepasst.


Quiz: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien im Jahr 2024 (in Pfund)?

- 9.11 [ ]

- 11.22 [x]

- 14.44 [ ]

https://www.gov.uk/national-minimum-wage-rates



**Unternehmensgewinne**


## Exercise 2 -- Datenüberblick

- Herkunft der Daten
- Wieso Großbritannien?
- Ausgewogenheit der Daten
- Datensatz WERS
- Datensatz main (FAME (Financial Analysis Made Easy(135)))
  - Gesetzliche Verpflichtung
  - Auch Analyse kleinerer Unternehmen möglich (135)
  - Betrachtung von Firmen mit Geschäftsjahr April-März (Filter-Sample) (135)
- Labor Force Survey (136f.)
  - Arbeitsumfeld
  
- Relevante Variablen

**Aufgabe**: Lesen Sie den Datensatz 'main_fame.dta' mit der Funktion 'read_dta' ein und speichern Sie den Datensatz unter 'dat_main'. Führen Sie den Code aus, indem Sie "check" drücken.
```{r "3_1"}
#Datensatz einlesen
dat = read_dta('main_fame.dta')
```
Um einen ersten Überblick über den Datensatz zu bekommen, geben sie die ersten Zeilen des Datensatzes mittels der Funktion head aus.
```{r "3_2"}
head(dat)
```
Wir erhalten eine Vielzahl an Variablen, die mehr oder minder relevant für unsere Analysen sind.

Widmen wir uns den wesentlichsten Variablen für unsere Analyse:

**regno**: Hier handelt es sich um eine bestimmte Nummer, mit der die Daten jedem bestimmten Unternehmen zugeordnet werden können.

**year**: Gibt das Jahr an, aus dem die Daten stammen. Dabei wird das zurückliegende Geschäftsjahr betrachtet.

**ln_avwage**: Benennt den logarithmierten Durchschnittslohn im Unternehmen.

**net_pcm**: Die Gewinnmarge eines Unternehmens wir durch die Division vom Nettogewinn durch den Gesamtumsatz im Geschäftsjahr angegeben.

**sic2**: Die Unternehmen werden in Großbritannien nach Branchen in unterschiedliche Branchen unterteilt. Der bis zu vierstellige UKsic (UK Standard Industrial Classification of Economic Activities) beschreibt dabei die Branchen.
Das oben ausgegebene Unternehmen besitzt den UKsic 7020. Die sic2-Zahl ist somit 70 und beschreibt Immobilienaktivitäten.   
(https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/guide-method/classifications/archived-standard-classifications/uk-standard-industrial-classification-1992--sic92-/uk-sic-2003.pdf)

**unionmem**: Beschreibt den Anteil an Gewerkschaftsmitgliedern innerhalb des Unternehmens.

**ptwk**: Anteil an Teilzeitarbeitern innerhalb der vierstelligen UKsic-Branche (sic4).

**female**: Frauenanteil bei Arbeitnehmern innerhalb des sic4.

**gorwk**: Gibt den Regierungsbezirk des jeweiligen Unternehmens an.


## Exercise 2.1 -- Schaubild / Wahl der Gruppen

Es soll überprüft werden, wie sich die Einführung des Mindestlohns auf die unterschiedlichen Einkommen ausgewirkt hat. 
Um die Veränderung des Lohns zum Vorjahr zu messen, muss der Datensatz zunächst für jedes einzelne Jahr aufgeteilt werden.

Zu Beginn wird erneut der Datensatz aus Aufgabe 2 eingelesen.

**Aufgabe**: Führen Sie den Code aus, indem Sie "check" drücken.
```{r "4_1"}
dat_main = read_dta('main_fame.dta')

```

Um die Veränderung der Löhne von Geschäftsjahr zu Geschäftsjahr herauszufinden, muss der Datensatz nach Jahren aufgeteilt werden. Das gelingt, indem für jedes Jahr ein eigener Datensatz erstellt wird. Dafür muss der bereits eingelesene Datensatz dat_main zunächst gefiltert werden.

**Aufgabe**: Wählen Sie die passende Variable für das leere Feld und überprüfen Sie Ihre Eingabe durch "check".
```{r "4_2"}
#
pcw95 = dat_main %>%
  filter(year == 1995)%>%
  filter(avwage >= 3)
```

-#Wieso werden nur Werte für avwage >= 3 gewählt? Verfälschung der Ergebnisse? Was für Unternehmen sind betroffen(sic überprüfen)?

```{r "4_3"}
dat_probe = dat_main %>% 
  filter(avwage < 3)
```


Nun befinden sich in pcw95 alle Daten aus dat_main, die aus dem Jahr 1995 stammen. 
Neben der Unterscheidung in den Jahren sollen zudem die Unterschiede der Ausgangslöhne herauskristallisiert werden.
Dazu werden die Löhne in Perzentile aufgeteilt.

**Aufgabe**: Erstellen Sie einen Vektor "percent95", der die logarithmierten Durchschnittslöhne in 100 Perzentile aufteilt. Nutzen Sie dafür die Funktion `quantile(dat,seq())`. Setzen Sie den fehlenden Wert in "seq()" ein, um einen Vektor der Länge 100 zu erhalten.

```{r "4_4"}
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, 0.01))
```

Diese Aufteilung muss nun für jedes Jahr des Datensatzes wiederholt werden.

**Aufgabe**: Führen sie den Chunk durch *check* aus.

```{r "4_5"}

pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))

pcw97 = dat_main %>%
  filter(year == 1997)%>%
  filter(avwage >= 3)
percent97 = quantile(pcw97$ln_avwage, seq(0, 1, 0.01))

pcw98 = dat_main %>%
  filter(year == 1998)%>%
  filter(avwage >= 3)
percent98 = quantile(pcw98$ln_avwage, seq(0, 1, 0.01))

pcw99 = dat_main %>%
  filter(year == 1999)%>%
  filter(avwage >= 3)
percent99 = quantile(pcw99$ln_avwage, seq(0, 1, 0.01))

pcw00 = dat_main %>%
  filter(year == 2000)%>%
  filter(avwage >= 3)
percent00 = quantile(pcw00$ln_avwage, seq(0, 1, 0.01))

pcw01 = dat_main %>%
  filter(year == 2001)%>%
  filter(avwage >= 3)
percent01 = quantile(pcw01$ln_avwage, seq(0, 1, 0.01))

pcw02 = dat_main %>%
  filter(year == 2002)%>%
  filter(avwage >= 3)
percent02 = quantile(pcw02$ln_avwage, seq(0, 1, 0.01))


```


Nun können die Unterschiede in jedem einzelnen Perzentil von Jahr zu Jahr ermittelt werden. Die Differenzen sollen in einem Datensatz gespeichert werden. 

Dafür wird zunächst ein Datensatz erstellt, der sich an den Werten der Perzentile aus dem ersten Beobachtungsjahr 1995 richtet.

**Aufgabe**: Erstellen Sie einen Datensatz `diffperc` mittels der Funktion `data.frame`. Dieser soll zunächst die Werte aus `percent95` enthalten, welche durch `sort()` geordnet sind.

```{r "4_6"}

diffperc = data.frame(sort(percent95))
```


Der Datensatz diffperc kann jetzt um die Differenzen innerhalb der Perzentile erweitert werden.

**Aufgabe**: Führen Sie den Code mit "check" aus.

```{r "4_7"}
diffperc = diffperc %>%
  mutate("percentile" = c(0:100),
         "diff96" = percent96-percent95,
         "diff97" = percent97-percent96,
         "diff98" = percent98-percent97,
         "diff99" = percent99-percent98,
         "diff00" = percent00-percent99,
         "diff01" = percent01-percent00,
         "diff02" = percent02-percent01)

```


Für die Betrachtungsweise der Auswirkungen durch die Einführung des Mindestlohns sind zwei Differenzen von besonderer Bedeutung. Daher sollen die Änderung des Lohns im Jahr vor der Einführung (diff99) mit der Änderung im Jahr nach der Einführung (diff00) in einem Liniendiagramm gegenübergestellt werden.

```{r "4_8"}

#Graphik
library(ggplot2)

diffperc = filter(diffperc, percentile < 76 & percentile > 0)
ggplot(diffperc)+
  geom_line(aes(x = percentile, y = diff99), colour = "blue", linetype = 2, linewidth = 0.8)+
  geom_line(aes(x = percentile, y = diff00), colour = "red", linewidth = 0.8)+
  geom_vline(xintercept = 13)+
  geom_vline(xintercept = 50)+
  xlab("Perzentile der Ausgangsdurchschnittslöhne")+
  ylab("Änderung des logarithmierten Durchschnittslohns")

```

#-Mögliche Fragen zum Schaubild

-Wieso logarithmierte Werte?
-Woher kommt der Piek nach unten?




## Exercise 3 DiD -- Difference in Differences

**Möglicher Inhalt**
- Wieso braucht man DiD
- Voraussetzungen gegeben? (parallel-Trend)
- Was sagt er aus
- Vorteil ggü. anderer Methoden
- Wie werden die jeweiligen Gruppen gewählt? (136f.)
  - Treatment Group Indikatoren = FAME + LFS + WERS (136)
  - T = 1 für avwage < 12.000 im Geschäftsjahr vor NMW Einführung 
  - Durchschnitt in T = 1 = 8400 => 3,90 pro Stunde (nah bei NMW = 3,60)  
  - Plausible Treatment-Wahl? (137D.), Fig. 1
- Was gibt es für andere Schätzmethoden?
- Diagramm Variablenbeeinflussung
- Placebo-Effekt (142f.)
  - Imaginäre Einführung NMW im April 1996

**Vorgehen**
- Kernergebnisse erkennen
- Ausgangspunkt: Mindestlohn + Unternehmensgewinne
- Regression aufbauen

**Stichwörter**
- Quasi-experimenteller Rahmen NMW (133)
- Händische DiD-Schätzungsformel (133)
- Parallel-Trend: Unterschiede wären gleich geblieben, wenn es kein Treatment gegeben hätte

**Mögliche Aufgaben**
- Treatmentgruppenwahl entwickeln: 3,60 pro Stunde -> Schnitt 8400 im Jahr bei Vollzeit (Arbeitszeiten GB aufdröseln)


Die Auswirkungen des Mindestlohns auf die Unternehmensgewinne können mit Hilfe der Difference-in-Differences-Methode - kurz **DiD** - beobachtet werden.

**DiD-Methode**
Die DiD-Schätzung ist häufig geeignet, um politische Maßnahmen empirisch zu beurteilen. Gerade mit Hinblick auf Lohnentwicklungen stellte die Methode bereits in der Vergangenheit eine wichtige Grundlage. So können beispielsweise die Einflüsse von Schocks und fixer Effekte abgefedert werden und so die Auswirkungen einzelner Maßnahmen besser beurteilbar machen. (Quelle???) (Angrist, J. D., & Pischke, J. S. (2009). Mostly harmless econometrics: An empiricist's companion. Princeton university press.)

**Sind die Voraussetzungen gegeben? (Quiz)**
- Parallele Trends


**Parallele Trends**
Eine relevante Voraussetzung für das Anwenden der DiD-Methode ist die Parallel-Trends-Assumption (PTA). Diese besagt, dass ohne die Einführung eines Treatments, in unserem Fall der Mindestlohn, die Linien der Kontroll- und Treatmentgruppe weitestgehend parallel liefen. 
Annähernd kann das überprüft werden, indem man sich die Trendlinien der beiden Gruppen vor Einführung des Treatments ansieht. (Quelle???)

**Code**
```{r "5_1"}
  dat = read_dta('main_fame.dta')
```

```{r "5_2"}
dat_trend_treat = dat %>% 
  filter(ctreat1 == 1) %>%
  group_by(year)%>%
  summarise("Treatment"=mean(ln_avwage, na.rm = TRUE))
```
```{r "5_3"}
dat_trend_control = dat %>%
  filter(ctreat1 == 0) %>%
  group_by(year) %>%
  summarise("Control"=mean(ln_avwage, na.rm = TRUE))
```
```{r "5_4"}
dat_trend = left_join(dat_trend_treat, dat_trend_control)
```
```{r "5_5"}
ggplot(dat_trend)+
   geom_line(aes(x = year, y = Treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = Control), colour = "red", linetype = 1, linewidth = 0.8)+
   geom_vline(xintercept = 1999)
```

Quiz: Erkennen Sie einen parallelen Trend?

- Ja [ ]

- Nein [x]


In unserer Betrachtungsweise ist kein eindeutig paralleler Trend zu erkennen. Aufgrund des kurzen Betrachtungszeitraums des Trends sollte diese Einschätzung aber auch mit Vorsicht genossen werden: Es wird sich auf Trends bezogen, die sich auf sechs Datenpunkte (1994-1999) stützen. Die Betrachtung eines größeren Zeitraums könnte hier eine genauere Betrachtung zulassen.
Bezüglich der PTA gibt es seitens der Autoren keine weiterführenden Analysen, eine Erwähnung wird innerhalb des Artikels vergeblich gesucht.




## Exercise 3.1 -- Wahl der Gruppen
Bei der Difference in Difference (DiD) Methode werden die Daten anhand von zwei Kriterien unterteilt.
Zum einen wird entschieden, ob es sich um eine Pre-Treatment oder eine Post-Treatment Gruppe handelt.


Quiz: Ab welchem Zeitpunkt werden Daten der Post-Treatment Gruppe zugewiesen?

- 1999 [ ]

- 2000 [x]


Für eine DiD-Schätzung muss weiter eine Kontroll- und eine Treatmentgruppe definiert werden. In der Treatmentgruppe werden jene Unternehmen zusammengefasst, bei denen der Durchschnittslohn (avwage) im Jahr unter 12000 Pfund lag.
Die Kontrollgruppe umfasst Unternehmensdaten mit einem Durchschnittslohn zwischen 12000 und 20000 Pfund.

Im Mittelpunkt der Mindestlohneinführung steht der Wert von 3,60 Pfund pro Stunde. Da unser Datensatz allerdings keine Daten zu jedem Arbeitnehmer enthält, müssen wir uns an die Wahl der Treatmentgruppe nähern.

```{r "6_1"}
  dat = read_dta('main_fame.dta')

```
Die Variable, die den Lohn innerhalb eines Unternehmens am Besten widerspiegelt ist hierbei "avwage". Hierüber wird sich auch im Artikel genähert. Dabei werden alle Unternehmen mit einem avwage =< 12000 in die Treatmentgruppe einsortiert. 
Um zu verstehen, warum sich für diesen Wert als Obergrenze entschieden wird ist es hilfreich, den Wert in Zusammenhang mit dem Stundenlohn zu bringen.
Dazu soll zunächst der durchschnittliche Lohn aller Unternehmen aus der Treatmentgruppe in der Pre-Policy Periode ermittelt werden.

**Aufgabe**: Setzen Sie die passenden Werte in die Lücken ein. (Hinweis: Avwage wird im Datensatz in 1000 Pfund angegeben)
```{r "6_2"}
mean_treat = dat %>%
  filter(avwage <= 12) %>%
  filter(year == 1999) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
```
```{r "6_3"}
mean_treat / 2000
```
Mit dieser Näherung kommt man in die Nähe des Mindestlohns. Dennoch ist dies auch mit Vorsicht zu genießen. Da die Wahl der Treatmentgruppe auf Durchschnittslöhne eines gesamten Unternehmens beruht, können große Ausreißer das Ergebnis beeinflussen. Es wird eine Vollzeitbeschäftigung vorausgesetzt, wobei der Anteil an Teilzeitarbeit im betrachteten Beispiel bei über 16% lag: (Quelle???)

```{r "6_4"}
mean(dat$ptwk, na.rm = TRUE)
```


Die Wahl der Treatmentgruppe kann allerdings weiter durch die Verwendung des WERS-Datensatzes untermauert werden. 
So kann die Lohnverteilung innerhalb eines Unternehmens mit dem Durchschnittslohn in Zusammenhang gebracht werden. Die Autoren kommen zu dem Schluss, dass 87% aller vom Mindestlohn profitierenden Arbeiter in Unternehmen arbeiten, in denen der jährliche Durchschnittslohn bei 12000 Pfund oder niedriger liegt. 
Wir wollen überprüfen, inwiwefern der Anteil an Lohnzahlungen unter 3,60 mit dem Durchschnittslohn zusammmenhängt.

**Figure 1**
```{r "6_5"}
dat_seq = read_dta('seq98.dta')
```

## Exercise 3.2 -- händische DiD-Berechnung

Mit einem Blick auf den Datensatz erkennt man, dass hierfür bereits Dummy-Variablen ertellt worden sind.

**Aufgabe**: Laden Sie erneut den bereits bekannten Datensatz, indem Sie lediglich "check" drücken.
```{r "7_1"}
dat = read_dta('main_fame.dta')

```

```{r "7_2"}
dat_table_DiD = dat %>%
  group_by(ctreat1, NMW)%>%
  filter(pp == 1) %>%
  summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))
```

**Wieso wird der Dummy "pp" angewandt?**
In diesem Code fällt auf, dass der Datensatz um mehrere Einträge mit Hilfe des Dummys pp verkleinert wird.
Diese Vorauswahl wird von Seiten der Autoren getroffen (S. 135, (Verw. 14)): Dabei wird sich auf Unternehmen bezogen, deren Geschäftsjahr im Zeitraum April bis März läuft. Untersuchungen wurden ebenfalls für den gesamten Datensatz durchgeführt, die grundlegenden Ergebnisse ähneln sich dabei. Aufgrund diverser Regelungen in der britischen Berichterstattung sind kleinere Unternehmen von der Angabe bestimmter Daten befreit. Daher gibt es ein subsample. 

Werfen wir einen Blick auf die aussortierten Daten und überprüfen anhand der Beschäftigungszahlen, ob es Aufffälligkeiten gibt:

```{r "7_3"}
dat_no_pp = dat %>%
  filter(pp == 0)

dat_pp = dat %>%
  filter(pp == 1)

boxplot(log(dat_no_pp$emp),log(dat_pp$emp))
boxplot(log(dat_no_pp$net_pcm),log(dat_pp$net_pcm))
boxplot(log(dat_no_pp$avwage),log(dat_pp$avwage))

```
Im Gesamten ist zu erkennen, dass die Daten, die sich nicht in der Auswahl befinden, breiter gestreut sind.
Wir erkennen einen Unterschied in den Beschäftigungszahlen der beiden Gruppen.
In Großbritannien sind **kleinere Unternehmen** von der Veröffentlichung bestimmter Daten befreit. Um eine vollumfängliche Analyse zu gewährleisten entscheiden sich die Autoren daher ein Unterbeispiel zu erstellen, in denen Daten vollumfänglich erfasst werden (S. 135).
Das schränkt allerdings auch die Bewertung ein, lenkt den Blick weg von kleineren Unternehmen und muss bei der Betrachtung der Ergebnisse bedacht werden.
Wie die Autoren die Auswahl des Unterbeispiels treffen wird nicht vollumfänglich bekannt.



Nachdem die relevanten Daten des DiD zusammengefasst in der Tabelle "dat_table_DiD" vorhanden sind, können die Differenzen nun händisch berechnet werden.

Die Formel hierfür lautet 
***(y.post.treat - y.post.control) - (y.pre.treat - y.pre.control)***

**Aufgabe**: Werfen Sie zunächst einen Blick auf die erzeugte Tabelle und überlegen Sie, welcher Gruppe die jeweiligen Werte angehören. Lassen Sie sich dafür die oben erstellte Tabelle anzeigen und überprüfen Sie Ihre Eingabe mittels "check".
```{r "7_4"}

dat_table_DiD
```


Quiz: Welche Spalte beschreibt die Kontroll- bzw. Treatmentgruppe?

- ctreat1 [x]

- NMW [ ]



Quiz: Von welcher Gruppe ist die Rede, wenn NMW = 1 ?

- Pre-Treatment [ ]

- Post-Treatment [x]


**Aufgabe**: Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
```{r "7_5"}
y1.post.treat = dat_table_DiD$mean_ln_avwage[4]
y1.post.control = dat_table_DiD$mean_ln_avwage[2]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[3]
y1.pre.control = dat_table_DiD$mean_ln_avwage[1]

```


Quiz: Wieso werden für den Durchschnittslohn logarithmierte Werte verwendet?

- a [x]

- b [ ]

- c [ ]



Quiz: Wieso gibt es in der Kontrollgruppe eine Obergrenze (20000 = Median)?

- a [ ]

- b [x]

- c [ ]

Neben des logarithmierten Durchschnittslohns wird auch der DiD-Schätzer der Nettorendite eines Unternehmens je Geschäftsjahr (net_pcm) berechnet.
Das geschieht analog zur obigen Schätzung.

**Aufgabe**: Werfen Sie erneut einen Blick auf die erstellte Tabelle und geben Sie nun die Zeilen ein, in denen der passende Wert steht.
```{r "7_6"}
y2.post.treat = dat_table_DiD$mean_net_pcm[4]
y2.post.control = dat_table_DiD$mean_net_pcm[2]
y2.pre.treat = dat_table_DiD$mean_net_pcm[3]
y2.pre.control = dat_table_DiD$mean_net_pcm[1]
```

Die Werte sind nun gespeichert und die DiDs können berechnet werden.

**Aufgabe**: Fügen Sie dem Code das Anzeigen der Ergebnisse hinzu und führen Sie den Code mittels "Check" aus.
```{r "7_7"}
DiD_ln_avwage = (y1.post.treat - y1.post.control) - (y1.pre.treat - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.post.control) - (y2.pre.treat - y2.pre.control)
  
#Ergebnisse anzeigen
DiD_ln_avwage
DiD_net_pcm
```

Durch die Einführung des Mindestlohns können wir sagen, dass dadurch in den beobachteten Unternehmen der Durchschnittslohn gestiegen ist. Zugleich ist zu erkennen, dass in jenen Unternehmen der Nettogewinn zurück gegangen ist.

Um diese Veränderung genauer bewerten zu können und tiefergehende Analysen zu ermöglichen, machen wir uns die Methode der Regression zu eigen.


## Exercise 3.3 -- DiD-Schätzung mittels Regression

**Theorie**
- Cluster-Robuste Standardfehler
  - Geclustert nach Regno (unternehmen)
- Genestete Daten

**DAG**

Um uns einen ersten Überblick über die Zusammenhänge der Variablen in unserer DiD-Schätzung zu verschaffen, sind die Directed Acyclic Graphs (DAGs) von Vorteil.
Führen Sie hierfür den Code mittels check aus und sehen Sie sich den Graphen an.
(https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html)
(https://r-causal.github.io/ggdag/)

```{r "8_1"}

dag <- dagify(
  ln_avwage ~ ctreat1 + treat1_NMW + NMW, 
  treat1_NMW ~ ctreat1 + NMW,
  labels = c(ctreat1 = "ctreat1", treat1_NMW = "treat1_NMW", NMW = "NMW", ln_avwage = "ln_avwage")
)

ggdag(dag, node_size = 18, text = FALSE, edge_type = "link", use_labels = "label")+
  theme_dag_blank()
```
Hier sieht man warum der Effekt von treat1_NMW in Regression III so stark von dem in Regression IV abweicht. , nicht nur eine Regression mit der Interaktionsvariablen durchzuführen, sondern auch mit den beiden einzelnen Dummy-Variablen.

**Aufgabe**: Lesen Sie einen Auszug des bekannten Datensatzes dat_main ein, indem Sie den Code mit "check" ausführen.
```{r "8_2"}
dat_raw = read_dta('main_fame.dta')
dat = filter(dat_raw, pp == 1) 
```

```{r "8_3"}
regi = lm(ln_avwage ~ ctreat1, data = dat)
```

```{r "8_4"}
regii = lm(ln_avwage ~ NMW, data = dat)
```

```{r "8_5"}
regiii = lm(ln_avwage ~ treat1_NMW, data = dat)
```

```{r "8_6"}
regiv = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW, data = dat)
```

```{r "8_7"}
stargazer(regi, regii, regiii, regiv, type = "text")
```




**Genestete Daten**
(Bryk, Raudenbush: Hierarchical Linear Models: Applications and Data Analysis Methods)
Die Werte der Variablen sind im obigen Fall als hoch signifikant gekennzeichnet. Allerdings sind die p-Werte fehlerhaft, da es sich bei den Daten teilweise um genestete Daten handelt. Genestete Daten liegen vor, wenn mehrere Daten zu einer übergeordneten Einheit zählen.
In unserem Fall haben wir Daten zum logarithmierten Durchschnittslohn (ln_avwage) über mehrere Jahre. Diese haben ein Unternehmen (regno) als übergeordnete Einheit.
Um Fehler bezüglich genesteter Daten zu verhindern, fügen wir Clusterrobuste Standardfehler ein.


Quiz: Nach welcher Variable soll geclustert werden?

- ln_avwage [ ]

- regno [x]


Nun fügen wir die Clusterrobusten Standardfehler ein und schauen, was sich dadurch verändert.

```{r "8_8"}
reg1 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW|0|0|regno, data=dat)
stargazer(reg1, type ="text")
```



**Clusterrobuste Standardfehler**


An den Werten der ist Variablen ist keine Veränderung zu erkennen. Allerdings haben sich die Werte der Standardfehler verändert.
Während man für ctreat1 und die Interaktionsvariable eine Erhöhung des P-Wertes vorfindet, ist eine Verringerung bei der Variablen NMW zu verzeichnen.

Um diese Veränderungen zu verstehen sehen wir uns an, was es generell mit clusterrobusten Standardfehlern auf sich hat:
(Angrist, 231ff)...
Variiert der Regressor nur innerhalb einer Clustergruppe, so kann der Standardfehler steigen (231)

---------------

**Ergebnisanalyse**

Die Variablen beschreiben die Veränderungen im Vergleich zum Pre-Policy Jahr, welche mit Constant beschrieben wird.
- Wie wirken die unterschiedlichen Variablen?
- Werte zuordnen

Quiz: Wenn Sie an die Werte aus der händischen Berechnung zurückdenken, sollte Ihnen der Wert einer Variablen bekannt vorkommen. Von welcher Variablen ist die Rede?

- ctreat1 [ ]

- treat1_NMW [x]

- NMW [ ]


Bei treat1_NMW handelt es sich um den Interaktionsterm der beiden Dummyvariablen. Dieser beschreibt die einfache DiD-Schätzung unter der Berücksichtigung Cluster-Robuster Standardfehler je Unternehmen. Der Wert ist hoch signifikant.


Quiz: In welcher Einheit wird der DiD-Wert beschrieben?

- Pfund [ ]

- Prozent [ ]

- Prozentpunkte [x]



----------------



**NET_PCM**

Zur Betrachtung der Veränderung der Unternehmensgewinne gehen wir nach demselben Schema vor.

```{r "8_10"}
reg2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data = dat)

stargazer(reg2, type = "text")
```
-------------

Sehen wir uns weiter an ob es zu Veränderungen kommt, wenn wir auf bestimmte Effekte der Unternehmenswelt kontrollieren.
Dafür können wir uns die Funktion der Faktorvariablen zunutze machen.

**Faktorvariablen**



**Table 2, Panel A**
```{r "8_11"}
reg3 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg3, type = "text")
```

```{r "8_12"}
reg4 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg4, type = "text")
```

**Table 2, Panel B**

**Kontinuierliche Messung**

Bisher haben wir uns auf die Unterscheidung zwischen Treatment und keinem Treeatment konzentriert. Dabei wurde deutlich, dass sowohl einen signifikante positive Änderung des Lohns, als auch eine negative signifikante Veränderung der Gewinnmarge vorhanden sind. Da diese sich diese Unterscheidung allerdings auf die vorangegangene eigene Definiton der beiden Gruppen stützt, kann die Betrachtung durch eine weitere Methode hilfreich sein. Zudem wollen wir einen genaueren Effekt je nach Einkommen erhalten.

Im Vergleich zur diskreten Messung wird bei der kontinuierlichen Messung kein Dummy für die Treatments verwendet, sondern ein bestimmter Wert.


Um diese kontinuierliche Analyse zu ermöglichen, wird anstatt der Treatmentvariablen *ctreat1* eine andere Variable gewählt.
In unserem Fall ist das *c_avwage99* beschreibt den logarithmierten Durchschnittslohn zum Jahr 1999 nach Unternehmen gruppiert.



```{r "8_13"}
reg5 = felm(ln_avwage ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg6 = felm(net_pcm ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg5, reg6, type = "text")
```
WAS HAT SICH GEÄNDERT?
WIE KANN DAS ERGEBNIS INTERPRETIERT WERDEN?
WIESO BRAUCHT MAN DAS?
  - Vergleich zur imaginären Einführung



## Exercise 3.4 -- Imaginäre Mindestlohneinführung

- Sind die Veränderungen auf das Treatment zurückzuführen?
  - Vergleich zu Parallel-Trend
- Imaginäre Einführung am 1. April 1996
- Vergleich Datensätze: ff=0 vs. ff=1
- Table 3
- Figure 3

Um zu überprüfen, ob die Mindestlohneinführung der Grund für die Ergebnisse der DiD-Schätzung ist, kann ein **Placebo Experiment** eingeführt werden.(142ff.)
Hierfür wird die Mindestlohneinführung imaginär um drei Jahre vorverlegt, auf den 01. April 1996.
Dabei können wir auf Vorarbeit im Datensatz zurückgreifen. Ähnlich wie bei der vorangegangenen Schätzung zur realen Mindestlohneinführung wird der Datensatz anhand eines Dummys gefiltert.

Lesen Sie den Datensatz ein und teilen ihn nach den Dummywerten von ff auf.
```{r "9_1"}
dat = read_dta('main_fame.dta')
dat_ff1 = filter(dat, ff == 1)
dat_ff0 = filter(dat, ff == 0)
```
Um zu verstehen, warum manche Einträge von Firmen ausgelassen werden, hilft ein Vergleich der oben erstellten Variablen.

Gruppieren Sie dazu die Datensätze nach den Jahren und geben sie die Anzahl der Einträge pro Jahr aus. Hinweis: Die Funktion length(*Variable*) gibt die Anzahl der Einträge wieder.
```{r "9_2"}
dat_ff1 %>%
  group_by(year)%>%
  summarise(length(year))

dat_ff0 %>%
  group_by(year)%>%
  summarise(length(year))
```
Es fällt auf, dass sich im untersuchten Datensatz nur Einträge befinden, die sich auf den Zeitraum **vor** der reellen Mindestlohneinführung beziehen.

Allerdings werden auch Daten aus den Jahren 1994 - 1999 herausgefiltert. Sehen wir uns an, wie das mit dem von den Autoren gefundene Unterbeispiel (pp) zusammenhängt.

```{r "9_3"}
dat_ff0 %>%
  group_by(pp)%>%
  summarise(length(pp))

dat_ff1 %>%
  group_by(pp)%>%
  summarise(length(pp))
```
Der Anteil an pp==0 ist im unberücksichtigten Datensatz deutlich höher als im am Ende betrachteten Datensatz dat_ff1. Allerdings werden nun auch Unternehmen berücksichtigt, die bei den Analysen zur reellen Mindestlohneinführung nicht berücksichtigt wurden.
Der Grund dafür könnte sein, dass sich die Zahlen in den Unternehmen verändert haben.???

```{r "9_4"}
dat_ff0 = filter(dat_ff0, year==1996)
dat_ff1 = filter(dat_ff1, year==1996)
boxplot(dat_ff0$ln_avwage,dat_ff1$ln_avwage)
mean(dat_ff0$avwage, na.rm = TRUE)
mean(dat_ff1$avwage)
max(dat_ff1$avwage)
```

Wie in den vorherigen Analysen sind nicht alle Ursachen für die Aussortierung einiger Daten erkennbar. 
Weiter werden wir die Analysen mit dem von den Autoren gegebenen Unterbeispiel durchführen.

Dafür können wir dieselbe Regression wie im Kapitel 3.3 verwenden mit dem Unterschied, dass der Datensatz nun nach ff gefiltert wird.
```{r "9_5"}
dat = filter(dat, ff == 1)
```
**Diskret**
```{r "9_6"}
reg7 = felm(ln_avwage ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg8 = felm(net_pcm ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg7, reg8, type = "text")
```


**Kontinuierlich**
```{r "9_7"}
reg9 = felm(ln_avwage ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg10 = felm(net_pcm ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg9, reg10, type = "text")
```
----------------

**Vergleich Fig 3**
- Treatmenteffekt net_pcm

Intervalle erstellen
```{r "9_8"}
pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))
```
```{r "9_9"}
dat_fig3 = dat %>%
  mutate("threshold" = round(exp(c_avwage99)*1000,-2)) %>%
  filter(threshold <= 16000) %>%
  filter(threshold >= 10000) %>%
  
  group_by(threshold) %>%
  summarise(length(threshold), mean(avwage99_NMW))
```

Regression in 100er Schritten durchführen und wiederholen. Die grenze wird nach oben verschioben und es werden immer mehr Einträge berücksichtigt.
Ergebnisse je 100 in Liste speichern

```{r "9_10"}
#Neuen Datensatz erstellen
dati = read_dta('main_fame.dta')
dati = filter(dati, pp==1)

```

```{r "9_11"}

# Schleife initiieren
i = 10000
while(i<=16000){
dati = mutate(dati, "treat1" = NULL)
dati$ctreat1 = NULL
dati$avwage = dati$avwage * 1000

dati$treat1 = ifelse(dati$year == 1999 | dati$avwage <= i, 1, 0)
dati$ctreat1 = ifelse(dati$treat1 == 1, 1, 0)
dati = mutate(dati, treat1)


dati$paste("treat1", i, "_NMW") = dati$ctreat1*dati$NMW
  
# Regression innerhalb der Schleife
reg = felm(net_pcm ~ ctreat1 + paste("treat1", i, "_NMW") + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dati)

i + 100
}
```



```{r "9_12"}
library(ggplot2)
ggplot(dat_fig3, aes(x = threshold))+
  geom_line(aes(y = avwage99_NMW))

```




## Exercise 4 -- Einordnung des Artikels (weiterführende Überlegungen)

- EU-weiter Mindestlohn (Möglichkeiten, Chancen, Probleme)
- Unterschiede zu 1999 (Andere Rahmenbedingungen?, Brexit?)
- unberücksichtigte Variablen
- Auswirkung auf Beschäftigung
- weitere Artikel (andere Auswirkungen untersucht)
- Strukturen in Unternehmen

## Exercise Anregungen

- "Aber was sind die Produktionskosten - des Arbeiters, d.h. die Kosten, um den Arbeiter selbst zu produzieren?" / "Wert der Arbeit" (Kapital, 497)


## Exercise Probleme beim Code

- i. Dummyvariablen in Stata
- Intervallregression


## Exercise Aufgabentypen 

a) We often want to compute some summary statistic of a vector. For example:

```{r "13_a"}
x = 10:23
# Computing the sum of x
sum(x)
```

Now compute the mean of x.
```{r "13_a_2",optional=TRUE}
# Note the chunk option optional = TRUE means
# the user can continue with the next exercise
# without having solved this one

mean(x)
```


info("useful functions for numeric vectors")



b) Let `y` be a vector that contains the squared elements of `x`, i.e. for each element $i$ we want $$y_i = x_i^2.$$ Then show `y`.
```{r "13_b"}
# We should not set this chunk optional
# since we need y in the next chunk
y = x^2
y
```

c) Now use the function `qplot` from the package `ggplot2` to create a scatter plot of `x` against `y`. You can google `r qplot` to get the help for the function `qplot`.

```{r "13_c",optional=TRUE, dev='svg', fig.width=4}
library(ggplot2) # load ggplot2 package

# Enter your call to qplot here...
qplot(x,y)
# The block above allows the user to add extra arguments to the call to qplot, i.e. qplot(x,y,xlab="The variable x"), would also pass the test.
```



Quiz: What is the 'oddest' prime?

- 2 [x]

- 3 [ ]

- 5 [ ]

- 7 [ ]


Note: A quiz as specified below only works in the shiny environment. If you want to design a quiz in an RMarkdown based RTutor problem set, you should use a chunk. E.g. as follows:

Which of the following numbers is the oddest prime? 2,3,5 or 7? Enter you solution in the code below and press "check".

```{r "13_c_2"}
2
```

## Exercise Submitting your solution

To submit your solution please proceed as follows:

1. Scroll to the top and click on the icon with the bars <i class="fa fa-tasks fa-fw"></i> to see how many points you got so far. If you want to have more points you can try to solve the missing tasks.

2. If you want to submit click on the download button <i class="fa  fa-download fa-fw"></i> at the very right.

3. In the opened tab click the button "Download Submission File". Your browser should then download a file with the extension `.sub`.

4. Upload that downloaded file to your course management system like Moodle, as specified by your instructor.




## Mindestlohn und Firmenprofitabilität: Eine interaktive Analyse

- Einführung .


#< ignore
```{r "setup"}
library(RTutor)
# Adapt working directory
setwd("C:/Users/lasse/Documents/GitHub/RTutorMindestlohn/inst/Mindestlohn")
ps.name = "Mindestlohn"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all packages you load in the problem set
libs = c("ggplot2","haven") 
create.ps(sol.file=sol.file, ps.name=ps.name,libs=libs, rps.has.sol=TRUE, addons="quiz")
# Show the problem set in the webbrowser
show.ps(ps.name,sample.solution=FALSE,auto.save.code = TRUE)
```
#>

## Exercise Inhaltsübersicht

1. Einführung in den Mindestlohn

2. Datenüberblick

3. Difference in Differences

4. Einordnung des Artikels


## Exercise 1 -- Einführung in den Mindestlohn

- Hintergrund der Mindestlohneinführung
- sic
- Vergleich zu anderen Staaten

#< quiz "1"
question: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbrittanien zur Einführung 1999 (in Pfund)?
sc:
    - 3.6*
    - 5.7 
    - 7.8 

success: Korrekt. Der Artikel befasst sich mit der Einführung des Mindestlohns in Höhe von 3.60 Pfund.
failure: Diese Schätzung ist zu hoch.
#>


#< quiz "2"
question: Wie werden Lohnerhöhungen hauptsächlich gedeckt?
sc:
    - Verkleinerung der Gewinnmarge*
    - Weitergabe an Verbraucher
    - Effizienzsteigerung

success: Auf diese Vermutung beruht der wissenschaftliche Artikel.
failure: Eine mögliche Antwort
#>

## Exercise 2 -- Datenüberblick

- Herkunft der Daten
- Ausgewogenheit der Daten
- Datensatz WERS
- Datensatz main
- Relevante Variablen

**Aufgabe**: Lesen Sie den Datensatz 'main_fame.dta' mit der Funktion 'read_dta' ein und speichern Sie den Datensatz unter 'dat_main'. Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
#Datensatz einlesen
#>
dat_main = read_dta('main_fame.dta')
```


## Exercise 2.1 -- Schaubild

Es soll überprüft werden, wie sich die Einführung des Mindestlohns auf die unterschiedlichen Einkommen ausgewirkt hat. 
Um die Veränderung des Lohns zum Vorjahr zu messen, muss der Datensatz zunächst für jedes einzelne Jahr aufgeteilt werden.

Zu Beginn wird erneut der Datensatz aus Aufgabe 2 eingelesen.

**Aufgabe**: Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
dat_main = read_dta('main_fame.dta')
#>

```

Um die Veränderung der Löhne von Geschäftsjahr zu Geschäftsjahr herauszufinden, muss der Datensatz nach Jahren aufgeteilt werden. Das gelingt, indem für jedes Jahr ein eigener Datensatz erstellt wird. Dafür muss der bereits eingelesene Datensatz dat_main zunächst gefiltert werden.

**Aufgabe**: Wählen Sie die passende Variable für das leere Feld und überprüfen Sie Ihre Eingabe durch "check".
```{r}
#< fill_in
pcw95 = dat_main %>%
  filter(___ == 1995) %>%
  filter(avwage >= 3)
#>
#
pcw95 = dat_main %>%
  filter(year == 1995)%>%
  filter(avwage >= 3)
```

-#Wieso werden nur Werte für avwage >= 3 gewählt? Verfälschung der Ergebnisse? Was für Unternehmen sind betroffen(sic überprüfen)?

```{r}
dat_probe = dat_main %>% 
  filter(avwage < 3)
```


Nun befinden sich in pcw95 alle Daten aus dat_main, die aus dem Jahr 1995 stammen. 
Neben der Unterscheidung in den Jahren sollen zudem die Unterschiede der Ausgangslöhne herauskristallisiert werden.
Dazu werden die Löhne in Perzentile aufgeteilt.

**Aufgabe**: Erstellen Sie einen Vektor "percent95", der die logarithmierten Durchschnittslöhne in 100 Perzentile aufteilt. Nutzen Sie dafür die Funktion `quantile(dat,seq())`. Setzen Sie den fehlenden Wert in "seq()" ein, um einen Vektor der Länge 100 zu erhalten.

```{r}
#< fill_in
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, ___))
#>
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, 0.01))
```

Diese Aufteilung muss nun für jedes Jahr des Datensatzes wiederholt werden.

**Aufgabe**: Führen sie den Chunk durch *check* aus.

```{r}
#< task

pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))

pcw97 = dat_main %>%
  filter(year == 1997)%>%
  filter(avwage >= 3)
percent97 = quantile(pcw97$ln_avwage, seq(0, 1, 0.01))

pcw98 = dat_main %>%
  filter(year == 1998)%>%
  filter(avwage >= 3)
percent98 = quantile(pcw98$ln_avwage, seq(0, 1, 0.01))

pcw99 = dat_main %>%
  filter(year == 1999)%>%
  filter(avwage >= 3)
percent99 = quantile(pcw99$ln_avwage, seq(0, 1, 0.01))

pcw00 = dat_main %>%
  filter(year == 2000)%>%
  filter(avwage >= 3)
percent00 = quantile(pcw00$ln_avwage, seq(0, 1, 0.01))

pcw01 = dat_main %>%
  filter(year == 2001)%>%
  filter(avwage >= 3)
percent01 = quantile(pcw01$ln_avwage, seq(0, 1, 0.01))

pcw02 = dat_main %>%
  filter(year == 2002)%>%
  filter(avwage >= 3)
percent02 = quantile(pcw02$ln_avwage, seq(0, 1, 0.01))

#>

```


Nun können die Unterschiede in jedem einzelnen Perzentil von Jahr zu Jahr ermittelt werden. Die Differenzen sollen in einem Datnsatz gespeichert werden. 

Dafür wird zunächst ein Datensatz erstellt, der sich an den Werten der Perzentile aus dem ersten Beobachtungsjahr 1995 richtet.

**Aufgabe**: Erstellen Sie einen Datensatz `diffperc` mittels der Funktion `data.frame`. Dieser soll zunächst die Werte aus `percent95` enthalten, welche durch `sort()` geordnet sind.

```{r}
#< task

#>
diffperc = data.frame(sort(percent95))
```


Der Datensatz diffperc kann jetzt um die Differenzen innerhalb der Perzentile erweitert werden.

**Aufgabe**: Führen Sie den Code mit "check" aus.

```{r}
#< task
diffperc = diffperc %>%
  mutate("percentile" = c(0:100),
         "diff96" = percent96-percent95,
         "diff97" = percent97-percent96,
         "diff98" = percent98-percent97,
         "diff99" = percent99-percent98,
         "diff00" = percent00-percent99,
         "diff01" = percent01-percent00,
         "diff02" = percent02-percent01)

#>
```


```{r}
#< task

#Graphik
library(ggplot2)

diffperc = filter(diffperc, percentile < 76 & percentile > 0)
ggplot(diffperc)+
  geom_line(aes(x = percentile, y = diff99), colour = "blue", linetype = 2, linewidth = 0.8)+
  geom_line(aes(x = percentile, y = diff00), colour = "red", linewidth = 0.8)+
  geom_vline(xintercept = 13)+
  geom_vline(xintercept = 50)+
  xlab("Perzentile der Ausgangsdurchschnittslöhne")+
  ylab("Änderung des logarithmierten Durchschnittslohns")

#>
```



## Exercise 3 -- Difference in Differences

Bei der Difference in Difference (DiD) Methode werden die Daten anhand von zwei Kriterien unterteilt.
Zum einen wird entschieden, ob es sich um eine Pre-Treatment oder eine Post-Treatment Gruppe handelt.

#< quiz "3"
question: Ab welchem Zeitpunkt werden Daten der Post-Treatment Gruppe zugewiesen?
sc:
    - 1999
    - 2000*

success: Richtige Antwort. Die Einführung war zwar im Jahr 1999, die Daten jedes Jahres beziehen sich allerdings auf das vergangene Geschäftsjahr (April bis März).
failure: Das ist nicht korrekt. 
#>

Für eine DiD-Schätuung muss weiter eine Kontroll- und eine Treatmentgruppe definiert werden. In der Treatmentgruppe werden jene Unternehmen zusammengefasst, bei denen der Durchschnittslohn (avwage) im Jahr unter 12000 Pfund lag.
Die Kontrollgruppe umfasst Unternehmensdaten mit einem Durchschnittslohn zwischen 12000 und 20000 Pfund.

Mit einem Blick auf den Datensatz erkennt man, dass hierfür bereits Dummy-Variablen ertellt worden sind.
ctreat bezieht sich auf die Kontrollkomponente, während "NMW" angibt, ob sich die Daten der Pre- oder Post-Treatment Periode angehören.

```{r}
#< task
dat_table_DiD = dat_main %>%
  group_by(ctreat1, NMW)%>%
  filter(pp == 1) %>%
  summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))
#>
```

Nachdem die relevanten Daten des DiD zusammengefasst in der Tabelle "dat_table_DiD" vorhanden sind, können die Differenzen nun händisch berechnet werden.

Die Formel hierfür lautet 
(y.post.treat - y.post.control) - (y.pre.treat - y.pre.control)

```{r}
#< fill_in
# Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
y1.post.treat = dat_table_DiD$mean_ln_avwage[___]
y1.post.control = dat_table_DiD$mean_ln_avwage[___]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[___]
y1.pre.control = dat_table_DiD$mean_ln_avwage[___]

#>
```

#< quiz "4"
question: Wieso werden für den Durchschnittslohn logarithmierte Werte verwendet?
sc:
    - a*
    - b
    - c

success: Korrekt. 
failure: Das ist nicht die richtige Lösung.
#>

Neben des logarithmierten Durchschnittslohns wird auch der DiD-Schätzer der Nettorendite eines Unternehmens je Geschäftsjahr (net_pcm) berechnet.
Das geschieht analog zur obigen Schätzung.

```{r}
#< fill_in
y2.post.treat = dat_table_DiD$mean_net_pcm[___]
y2.post.control = dat_table_DiD$mean_net_pcm[___]
y2.pre.treat = dat_table_DiD$mean_net_pcm[___]
y2.pre.control = dat_table_DiD$mean_net_pcm[___]
#>
```

Dadurch erhalten wir folgende 


## Exercise 4 -- Einordnung des Artikels (weiterführende Überlegungen)

- EU-weiter Mindestlohn (Möglichkeiten, Chancen, Probleme)
- Unterschiede zu 1999 (Andere Rahmenbedingungen?, Brexit?)
- weitere Artikel


## Exercise Probleme beim Code

- i. Dummyvariablen in Stata
- Intervallregression


## Exercise Aufgabentypen 

a) We often want to compute some summary statistic of a vector. For example:

```{r}
#< task
x = 10:23
# Computing the sum of x
sum(x)
#>
```

Now compute the mean of x.
```{r optional=TRUE}
# Note the chunk option optional = TRUE means
# the user can continue with the next exercise
# without having solved this one

mean(x)
#< hint
cat("There already exist R functions for many things. To find them use Google, e.g. search for 'R compute mean'.")
#>
```


#< info "useful functions for numeric vectors"
Here are examples for useful R functions
```{r}
max(c(1,5,2)) # returns maximum
min(c(1,5,2)) # returns minimum

sum(c(1,5,2,NA), na.rm=TRUE) # returns sum of all numbers, ignore NA
cumsum(c(1,5,2)) # returns cummulated sum
diff(c(1,5,2)) # returns the vector of differences
```
#>


#< award "mean means mean"
Well, in some occasions one can just guess the name of an R function. The function to compute the mean of a vector, or matrix is called 'mean'. Usually, it is much quicker to goggle than to guess function names, however.
#>

b) Let `y` be a vector that contains the squared elements of `x`, i.e. for each element $i$ we want $$y_i = x_i^2.$$ Then show `y`.
```{r}
# We should not set this chunk optional
# since we need y in the next chunk
y = x^2
y
```

c) Now use the function `qplot` from the package `ggplot2` to create a scatter plot of `x` against `y`. You can google `r qplot` to get the help for the function `qplot`.

```{r optional=TRUE, dev="svg", fig.width=4}
#< task
library(ggplot2) # load ggplot2 package

# Enter your call to qplot here...
#>
qplot(x,y)
#< test_arg
allow.extra.arg = TRUE 
#>
# The block above allows the user to add extra arguments to the call to qplot, i.e. qplot(x,y,xlab="The variable x"), would also pass the test.
```


#< quiz "prime"
question: What is the 'oddest' prime?
sc:
    - 2*
    - 3
    - 5
    - 7
success: Well, of course the answer is debatable...
failure: Try again.
#>

Note: A quiz as specified below only works in the shiny environment. If you want to design a quiz in an RMarkdown based RTutor problem set, you should use a chunk. E.g. as follows:

Which of the following numbers is the oddest prime? 2,3,5 or 7? Enter you solution in the code below and press "check".

```{r}
2
```
#< award "The oddest prime"
Wouldn't you agree that the only even prime is the odd man out?
#>

## Exercise Submitting your solution

To submit your solution please proceed as follows:

1. Scroll to the top and click on the icon with the bars <i class="fa fa-tasks fa-fw"></i> to see how many points you got so far. If you want to have more points you can try to solve the missing tasks.

2. If you want to submit click on the download button <i class="fa  fa-download fa-fw"></i> at the very right.

3. In the opened tab click the button "Download Submission File". Your browser should then download a file with the extension `.sub`.

4. Upload that downloaded file to your course management system like Moodle, as specified by your instructor.




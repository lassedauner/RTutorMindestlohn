## Mindestlohn und Firmenprofitabilität: Eine interaktive Analyse


#< ignore
```{r "setup"}
library(RTutor)
# Adapt working directory
setwd("C:/Users/lasse/Documents/GitHub/RTutorMindestlohn/inst/Mindestlohn")
ps.name = "Mindestlohn"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all packages you load in the problem set
libs = c("ggplot2","haven","stargazer","sandwich", "ggdag", "lfe", "broom") 
create.ps(sol.file=sol.file, ps.name=ps.name,libs=libs, rps.has.sol=TRUE, addons="quiz")
# Show the problem set in the webbrowser
show.ps(ps.name,sample.solution=FALSE,auto.save.code = TRUE)
```
#>

## Exercise Inhaltsübersicht

Herzlich Willkommen zu diesem interaktiven RTutor Problem Set.
Im Rahmen meiner Bachelorarbeit gehen wir den Zusammenhängen von Mindestlöhnen und der Unternehmensprofitabilität auf den Grund.
Die Basis bildet der Artikel [Minimum Wages and Firm Profitability](https://www.aeaweb.org/articles?id=10.1257/app.3.1.129) von Mirko Draca, Stephen Machin und John Van Reenen, erschienen im Januar 2011 im American Economic Journal: Applied Economics. 

Durch die Verknüpfung von inhaltlichen Hintergründen, fachlicher Analyse von Ergebnissen, persönlichen Einschätzungen und technischer Arbeit mit der Statistiksoftware R sollen Sie durch dieses Problem Set von einem fundierten Wissenszuwachs profitieren. 
Es ist das Ziel, dass Sie sich nach der geführten Erarbeitung des Themas kritisch und differenziert mit politischen Mindestlohnforderungen auseinandersetzen können und dazu in der Lage sind, Ihre Meinungsbildung ökonomisch zu begründen.  

### Inhalt

1. Einführung in den Mindestlohn

2. Datenüberblick

3. Difference in Differences

  3.1 Wahl der Gruppen

  3.2 Händische DiD Berechnung

  3.3 DiD-Schätzung mittels Regression

  3.4 Imaginäre Mindestlohneinführung

4. Einordnung des Artikels



## Exercise 1 -- Einführung in den Mindestlohn

- Relevanz der Forschungsfrage
- Hintergrund der Mindestlohneinführung
- sic
- Vergleich zu anderen Staaten
- Wie werden Unternehmensgewinne definiert?
- Theoretisch mathematischer Hintergrund / Ausgangspunkt
  - Messung Unternehmensgewinne
  - Messung Mindestlohn

### **"Jetzt 12€ Mindestlohn wählen."**

Ein zentrales Wahlkampfthema der SPD zur Bundestagswahl 2021. Es war nicht das erste Mal und wird auch nicht das letzte Mal gewesen sein, dass die Versprechung zur Verbesserung des Lohns ein zentrales Instrument der Arbeitsmarktpolitik ist, um eine große Wählerschaft zu mobilisieren.
Hinter diesem leicht verständlichen Versprechen steckt allerdings die komplexe Frage, wie die Lohnerhöhungen getragen werden.

Häufig wird in der Forschung die Frage der Auswirkungen auf die Beschäftigung betrachtet. Dabei treten Kontroversen auf und es herrscht keine Einigkeit in den Schlussfolgerungen.

Daher wählen wir mit unserer Analyse nach Draca et. al (2011) einen anderen Ansatz. Anstatt die Beschäftigung in den Vordergrund zu rücken, widmen wir uns der vorgelagerteten Frage, wie die Lohnsteigerungen innerhalb von Unternehmen kompensiert werden. Eine solche Betrachtungsweise ist nach den Autoren in der Forschung bisher weitestgehend unbeachtet geblieben.

Die Basis der Analyse bilden Unternehmensdaten aus dem Vereinigten Königreich (UK).

#< quiz "1"
question: Wie können Unternehmen die Lohnsteigerung kompensieren?
sc:
    - Verkleinerung der Gewinnmarge*
    - Weitergabe der Kostensteigerung an Verbraucher
    - Effizienzsteigerung

success: Auf dieser Vermutung beruht unsere Untersuchung.
failure: Eine plausible Antwort, allerdings werden hierfür keine Belege gefunden (Draca et al, S.130)
#>


**Hintergrund der Einführung**
Quellen: FES 09/2007
Wie in Deutschland, wurden und werden Löhne im Vereinigten Königreich teilweise durch Tarifverhandlungen festgelegt. Die Notwendigkeit der Einführung eines nationalen Mindestlohns wurde in Großbritannien durch den sinkenden Einfluss von Gewerkschaften gesehen. Haben im Jahr 1970 noch 80% der Arbeitnehmer von Tarifverträgen profitiert, so sank dieser Anteil bis 2000 um 50 Prozentpunkte.
Mit einem Machtwechsel im britischen Unterhaus, hin zur sozialdemokratischen Labour-Partei, kommt es zur Veränderung in der Arbeitsmarktpolitik. Zum 1. April 1999 wird der nationale Mindestlohn eingeführt.

#< quiz "1.1"
question: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien zur Einführung 1999?
sc:
    - 3.60£*
    - 5.70£ 
    - 7.80£

success: Korrekt. Der Artikel befasst sich mit der Einführung des Mindestlohns in Höhe von 3.60 Pfund.
failure: Diese Schätzung ist zu hoch.
#>

*Hinweis*: Wir verwenden einheitlich den Punkt als Dezimaltrennzeichen, da sich unsere Daten und die Software ebenfalls auf diese Methode stützen.


Weiter gilt zu erwähnen, dass der nationale Mindestlohn (NMW) nicht die erste Art des Mindestlohns im Vereinigten Königreich war. Von 1909 bis zum Jahr 1993 an wurden gesetzliche Mindestlöhne durch *Wage Councils* innerhalb von Branchen bestimmt. 
Das Novum des NMW liegt in der Reichweite über alle Branchen hinweg. Ähnlich wie die *Wage Councils*, gibt die unabhängige Niedriglohnkommission (LPC) eine Empfehlung zur Mindestlohnhöhe. Von 1999 an wird die Lohnhöhe fortlaufend von der Niedriglohnkomission angepasst.

#< quiz "1.2"
question: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn im UK im Jahr 2024?
sc:
    - 9.11£
    - 11.22£*
    - 14.44£
    

success: Korrekt. Für Personen über 21 gilt dieser Mindestlohn von April 2024 an.
failure: Diese Schätzung ist falsch.
#>
https://www.gov.uk/national-minimum-wage-rates



**Unternehmensgewinne**

Den theoretischen Ausgangspunkt für die Analyse bietet die Idee der Profitmaximierung nach Ashenfelter & Smith (1979).
Dabei wird von einem gewinnmaximierenden Unternehmen ausgegangen dessen Gewinn anhand von Variablen der Arbeitskraft, des Lohns, der Kosten und des Outputpreises gemessen wird.


(Draca et al., S.131f)


## Exercise 2 -- Datenüberblick

- Herkunft der Daten
- Wieso Großbritannien?
- Ausgewogenheit der Daten
- Datensatz WERS
- Datensatz main (FAME (Financial Analysis Made Easy(135)))
  - Gesetzliche Verpflichtung
  - Auch Analyse kleinerer Unternehmen möglich (135)
  - Betrachtung von Firmen mit Geschäftsjahr April-März (Filter-Sample) (135)
- Labor Force Survey (136f.)
  - Arbeitsumfeld
  
**Relevante Variablen**

#< quiz "2.1"
question: Um in den Datensatz einzutauchen eine kleine Frage zum Einstieg. Was glauben Sie, wieso wir Unternehmensdaten aus dem Vereinigten Königreich beziehen?
sc:
    - Keine Kosten der Datenbeschaffung im Vereinigten Königreich
    - Strengere Transparenzregeln in der Bilanzierung und eine zentrale Datenspeicherung*
    - Die Daten sind anonymisiert und lassen eine unternehmensunabhängige Analyse zu

success: Das ist ein wichtiger Grund, warum wir uns mit Daten aus dem UK beschäftigen. Dabei werden die Daten in unserem Fall kommerziell vom "Bureau Van Dijk" bezogen. Eine unternehmensunabhängige Analyse wäre mit Hinblick auf branchenspezifische Einflüsse nicht zielführend.
failure: Die Antwort ist leider falsch.
#>


**Aufgabe**: Lesen Sie den Datensatz *main_fame.dta* mit der Funktion *read_dta* ein und speichern Sie den Datensatz unter *dat*. Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
#Datensatz einlesen
#>
dat = read_dta('main_fame.dta')
```
Um einen ersten Überblick über den Datensatz zu bekommen, geben sie die ersten Zeilen des Datensatzes mittels der Funktion head aus.
```{r}
head(dat)
```
Wir erhalten eine Vielzahl an Variablen, die mehr oder minder relevant für unsere Analysen sind.

Widmen wir uns den wesentlichsten Variablen für unsere Analyse:

**regno**: Hier handelt es sich um eine bestimmte Nummer, mit der die Daten jedem bestimmten Unternehmen zugeordnet werden können.

**year**: Gibt das Jahr an, aus dem die Daten stammen. Dabei wird das zurückliegende Geschäftsjahr betrachtet.

**ln_avwage**: Benennt den logarithmierten Durchschnittslohn im Unternehmen.

**net_pcm**: Die Gewinnmarge eines Unternehmens wir durch die Division vom Nettogewinn durch den Gesamtumsatz im Geschäftsjahr angegeben.

**sic2**: Die Unternehmen werden in Großbritannien nach Branchen in unterschiedliche Branchen unterteilt. Der bis zu vierstellige UKsic (UK Standard Industrial Classification of Economic Activities) beschreibt dabei die Branchen.
Das oben ausgegebene Unternehmen besitzt den UKsic 7020. Die sic2-Zahl ist somit 70 und beschreibt Immobilienaktivitäten.   
(https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/guide-method/classifications/archived-standard-classifications/uk-standard-industrial-classification-1992--sic92-/uk-sic-2003.pdf)

**unionmem**: Beschreibt den Anteil an Gewerkschaftsmitgliedern innerhalb des Unternehmens.

**ptwk**: Anteil an Teilzeitarbeitern innerhalb der vierstelligen UKsic-Branche (sic4).

**female**: Frauenanteil bei Arbeitnehmern innerhalb des sic4.

**gorwk**: Gibt den Regierungsbezirk des jeweiligen Unternehmens an. 
((1) Tyne & Wear                    (12) East of England
(2) Rest of North East              (13) Central London
(3) Greater Manchester              (14) Inner London
(4) Merseyside                      (15) Outer London
(5) Rest of North West              (16) South East
(6) South Yorkshire                 (17) South West
(7) West Yorkshire                  (18) Wales
(8) Rest of Yorkshire & Humberside  (19) Strathclyde
(9) East Midlands                   (20) Rest of Scotland
(10) West Midlands (met county))


Werfen wir einen Blick auf die Variable *month*. Wir wollen sehen, wann die Unternehmen ihren Jahresbericht abgeben und damit ihr Geschäftsjahr beenden.
Gruppieren Sie hierfür den Datensatz *dat* nach dem Berichtsmonat *month*. Geben Sie anschließend die Anzahl der Einträge mittels der Funktion *length* an.
```{r}
#< fill_in
dat %>% 
  group_by(___) %>%
  summarize("Einträge" = ___(month))
#>
dat %>% 
  group_by(month) %>%
  summarize(length(month))
```

#< quiz "2.2"
question: Alle unsere Daten weisen auf ein Ende des Geschäftsjahres im März hin. Können Sie sich erklären, warum?
sc:
    - Anders als in Deutschland, endet das Geschäftsjahr im UK bei allen Unternehmen im März.
    - Im Frühjahr gibt es im UK wenig Bewegung auf dem Arbeitsmarkt. Dadurch vermeiden wir unbekannte externe Effekte.
    - Die Mindestlohneinführung findet bei diesen Unternehmen nicht mitten im Geschäftsjahr statt.*

success: Richtige Antwort. Dadurch können wir zwei klare Perioden vor und nach der Mindestlohneinführung definieren.
failure: Die Antwort ist leider falsch.
#>

## Exercise 2.1 -- Schaubild / Wahl der Gruppen

Es soll überprüft werden, wie sich die Einführung des Mindestlohns auf die unterschiedlichen Einkommen ausgewirkt hat. 
Um die Veränderung des Lohns zum Vorjahr zu messen, muss der Datensatz zunächst für jedes einzelne Jahr aufgeteilt werden.

Zu Beginn wird erneut der Datensatz aus Aufgabe 2 eingelesen.

**Aufgabe**: Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
dat_main = read_dta('main_fame.dta')
#>

```

Um die Veränderung der Löhne von Geschäftsjahr zu Geschäftsjahr herauszufinden, muss der Datensatz nach Jahren aufgeteilt werden. Das gelingt, indem für jedes Jahr ein eigener Datensatz erstellt wird. Dafür muss der bereits eingelesene Datensatz dat_main zunächst gefiltert werden.

**Aufgabe**: Wählen Sie die passende Variable für das leere Feld und überprüfen Sie Ihre Eingabe durch "check".
```{r}
#< fill_in
pcw95 = dat_main %>%
  filter(___ == 1995) %>%
  filter(avwage >= 3)
#>
#
pcw95 = dat_main %>%
  filter(year == 1995)%>%
  filter(avwage >= 3)
```

-#Wieso werden nur Werte für avwage >= 3 gewählt? Verfälschung der Ergebnisse? Was für Unternehmen sind betroffen(sic überprüfen)?

```{r}
dat_probe = dat_main %>% 
  filter(avwage < 3)
```


Nun befinden sich in pcw95 alle Daten aus dat_main, die aus dem Jahr 1995 stammen. 
Neben der Unterscheidung in den Jahren sollen zudem die Unterschiede der Ausgangslöhne herauskristallisiert werden.
Dazu werden die Löhne in Perzentile aufgeteilt.

**Aufgabe**: Erstellen Sie einen Vektor "percent95", der die logarithmierten Durchschnittslöhne in 100 Perzentile aufteilt. Nutzen Sie dafür die Funktion `quantile(dat,seq())`. Setzen Sie den fehlenden Wert in "seq()" ein, um einen Vektor der Länge 100 zu erhalten.

```{r}
#< fill_in
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, ___))
#>
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, 0.01))
```

Diese Aufteilung muss nun für jedes Jahr des Datensatzes wiederholt werden.

**Aufgabe**: Führen sie den Chunk durch *check* aus.

```{r}
#< task

pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))

pcw97 = dat_main %>%
  filter(year == 1997)%>%
  filter(avwage >= 3)
percent97 = quantile(pcw97$ln_avwage, seq(0, 1, 0.01))

pcw98 = dat_main %>%
  filter(year == 1998)%>%
  filter(avwage >= 3)
percent98 = quantile(pcw98$ln_avwage, seq(0, 1, 0.01))

pcw99 = dat_main %>%
  filter(year == 1999)%>%
  filter(avwage >= 3)
percent99 = quantile(pcw99$ln_avwage, seq(0, 1, 0.01))

pcw00 = dat_main %>%
  filter(year == 2000)%>%
  filter(avwage >= 3)
percent00 = quantile(pcw00$ln_avwage, seq(0, 1, 0.01))

pcw01 = dat_main %>%
  filter(year == 2001)%>%
  filter(avwage >= 3)
percent01 = quantile(pcw01$ln_avwage, seq(0, 1, 0.01))

pcw02 = dat_main %>%
  filter(year == 2002)%>%
  filter(avwage >= 3)
percent02 = quantile(pcw02$ln_avwage, seq(0, 1, 0.01))

#>

```


Nun können die Unterschiede in jedem einzelnen Perzentil von Jahr zu Jahr ermittelt werden. Die Differenzen sollen in einem Datensatz gespeichert werden. 

Dafür wird zunächst ein Datensatz erstellt, der sich an den Werten der Perzentile aus dem ersten Beobachtungsjahr 1995 richtet.

**Aufgabe**: Erstellen Sie einen Datensatz `diffperc` mittels der Funktion `data.frame`. Dieser soll zunächst die Werte aus `percent95` enthalten, welche durch `sort()` geordnet sind.

```{r}
#< task

#>
diffperc = data.frame(sort(percent95))
```


Der Datensatz diffperc kann jetzt um die Differenzen innerhalb der Perzentile erweitert werden.

**Aufgabe**: Führen Sie den Code mit "check" aus.

```{r}
#< task
diffperc = diffperc %>%
  mutate("percentile" = c(0:100),
         "diff96" = percent96-percent95,
         "diff97" = percent97-percent96,
         "diff98" = percent98-percent97,
         "diff99" = percent99-percent98,
         "diff00" = percent00-percent99,
         "diff01" = percent01-percent00,
         "diff02" = percent02-percent01)

#>
```


Für die Betrachtungsweise der Auswirkungen durch die Einführung des Mindestlohns sind zwei Differenzen von besonderer Bedeutung. Daher sollen die Änderung des Lohns im Jahr vor der Einführung (diff99) mit der Änderung im Jahr nach der Einführung (diff00) in einem Liniendiagramm gegenübergestellt werden.

```{r}
#< task

#Graphik
library(ggplot2)

diffperc = filter(diffperc, percentile < 76 & percentile > 0)
ggplot(diffperc)+
  geom_line(aes(x = percentile, y = diff99), colour = "blue", linetype = 2, linewidth = 0.8)+
  geom_line(aes(x = percentile, y = diff00), colour = "red", linewidth = 0.8)+
  geom_vline(xintercept = 13)+
  geom_vline(xintercept = 50)+
  xlab("Perzentile der Ausgangsdurchschnittslöhne")+
  ylab("Änderung des logarithmierten Durchschnittslohns")

#>
```

#-Mögliche Fragen zum Schaubild

-Wieso logarithmierte Werte?
-Woher kommt der Piek nach unten?




## Exercise 3 DiD -- Difference in Differences

**Möglicher Inhalt**
- Wieso braucht man DiD
- Voraussetzungen gegeben? (parallel-Trend)
- Was sagt er aus
- Vorteil ggü. anderer Methoden
- Wie werden die jeweiligen Gruppen gewählt? (136f.)
  - Treatment Group Indikatoren = FAME + LFS + WERS (136)
  - T = 1 für avwage < 12.000 im Geschäftsjahr vor NMW Einführung 
  - Durchschnitt in T = 1 = 8400 => 3,90 pro Stunde (nah bei NMW = 3,60)  
  - Plausible Treatment-Wahl? (137D.), Fig. 1
- Was gibt es für andere Schätzmethoden?
- Diagramm Variablenbeeinflussung
- Placebo-Effekt (142f.)
  - Imaginäre Einführung NMW im April 1996

**Vorgehen**
- Kernergebnisse erkennen
- Ausgangspunkt: Mindestlohn + Unternehmensgewinne
- Regression aufbauen

**Stichwörter**
- Quasi-experimenteller Rahmen NMW (133)
- Händische DiD-Schätzungsformel (133)
- Parallel-Trend: Unterschiede wären gleich geblieben, wenn es kein Treatment gegeben hätte

**Mögliche Aufgaben**
- Treatmentgruppenwahl entwickeln: 3,60 pro Stunde -> Schnitt 8400 im Jahr bei Vollzeit (Arbeitszeiten GB aufdröseln)


Die Auswirkungen des Mindestlohns auf die Unternehmensgewinne können mit Hilfe der Difference-in-Differences-Methode - kurz **DiD** - beobachtet werden.

**DiD-Methode**
Die DiD-Schätzung ist häufig geeignet, um kausale Effekte politischer Maßnahmen empirisch zu beurteilen.
Dabei werden die Daten in zwei zeitliche Perioden und zwei Gruppen eingeteilt. 
(Callaway, B., & Sant’Anna, P. H. (2021). Difference-in-differences with multiple time periods. Journal of econometrics, 225(2), 200-230., SEITE 2)
Gerade mit Hinblick auf Lohnentwicklungen stellte die Methode bereits in der Vergangenheit eine wichtige Grundlage. So können beispielsweise die Einflüsse von Schocks und fixer Effekte abgefedert werden und so die Auswirkungen einzelner Maßnahmen besser beurteilbar machen. (Quelle???) (Angrist, J. D., & Pischke, J. S. (2009). Mostly harmless econometrics: An empiricist's companion. Princeton university press.)




## Exercise 3.1 -- Wahl der Gruppen


Bei der Difference in Difference (DiD) Methode werden die Daten anhand von zwei Kriterien unterteilt.
Zum einen wird entschieden, ob es sich um eine Pre-Treatment oder eine Post-Treatment Gruppe handelt.

#< info "Treatmentgruppen"
Bei der DiD-Schätzung ist ein genauer Zeitpunkt ermittelbar, zu dem es ein Treatment gibt.
In unserem Fall ist dieses Treatment die Einführung des nationalen Mindestlohns.
Alle Daten, die aus einer Zeit vor dem Treatment stammen, sind Teil der Pre-Treatment Gruppe.
Jene Daten, die seit dem Treatment erfasst wurden, werden der Post-Treatment Gruppe zugeordnet.
#>

Zur Erinnerung: Der gesetzliche Mindestlohn wurde am 01. April 1999 eingeführt.

#< quiz "4"
question: Ab welchem Zeitpunkt werden Daten der Post-Treatment Gruppe zugewiesen? 
sc:
    - 1999
    - 2000*

success: Richtige Antwort. Die Einführung war zwar im Jahr 1999, die Daten jeden Jahres beziehen sich allerdings auf das vergangene Geschäftsjahr (April bis März).
failure: Das ist nicht korrekt. 
#>
------------

**Treatment-Wahl**

Für eine DiD-Schätzung muss weiter eine Kontroll- und eine Treatmentgruppe definiert werden. In der Treatmentgruppe werden jene Unternehmen zusammengefasst, bei denen der Durchschnittslohn (avwage) im Jahr unter 12000 Pfund lag.
Die Kontrollgruppe umfasst Unternehmensdaten mit einem Durchschnittslohn zwischen 12000 und 20000 Pfund.


-----------
**Parallele Trends**
Als relevante Voraussetzung für das Anwenden der DiD-Methode wird die Parallel-Trends-Assumption (PTA) gehandelt. Diese besagt, dass ohne die Einführung eines Treatments, die Linien der Kontroll- und Treatmentgruppe weitestgehend parallel weiterliefen. 
Annähernd kann das überprüft werden, indem man sich die Trendlinien der beiden Gruppen vor Einführung des Treatments ansieht. (Quelle???)


**Aufgabe**: Lesen Sie hierfür zunächst den Datensatz *main_fame* ein und speichern ihn unter *dat*.
```{r}
#< fill_in
___ = read_dta('main_fame.dta')
#>
dat = read_dta('main_fame.dta')
```

Um die Daten jeden Jahres zusammenzufassen, kann die Funktion *group_by* genutzt werden. 

#< info "group_by"
Die group_by Funktion aus dem dplyr Paket fasst die Daten anhand einer zu bestimmenden Variablen zusammen und ordnet die Ergebnisse aufsteigend an. 
Um die Gruppierung in einem Output sichtbar zu machen, kann die Pipe um den *summarise* Befehl erweitert werden, in dem dann die Werte jeder Einheit zusammengefasst werden können.
(https://dplyr.tidyverse.org/reference/group_by.html)
#>

**Aufgabe**: Fügen Sie die passende Variable in *group_by* ein und geben Sie für jedes Jahr den durchschnittlichen logarithmierten Durchschnittslohn aus.
```{r}
#< fill_in
dat_trend_treat = dat %>% 
  filter(ctreat1 == 1) %>%
  group_by(___)%>%
  summarise("treatment"=___(ln_avwage, na.rm = TRUE)) 
#>
dat_trend_treat = dat %>% 
  filter(ctreat1 == 1) %>%
  group_by(year)%>%
  summarise("treatment"=mean(ln_avwage, na.rm = TRUE)) 
```


Analog dazu erstellen wir auch noch einen Datensatz der Kontrollgruppe. 
**Aufgabe**: Führen Sie dazu den Code mittels *check* aus.
```{r}
#< task
dat_trend_control = dat %>%
  filter(ctreat1 == 0) %>%
  group_by(year) %>%
  summarise("control"=mean(ln_avwage, na.rm = TRUE))
#>

```

Um die beiden erstellten Datensätze miteinander zu verbinden, nutzen wir den *left_join*.

**Aufgabe**: Führen Sie den Code mittels *check* aus und sehen sich den Datensatz an.
```{r}
#< task
dat_trend = left_join(dat_trend_treat, dat_trend_control)

dat_trend
#>
```


Jetzt können wir die Daten **visualisieren**, indem wir uns in einem Liniendiagramm die Trends beider Gruppen ausgeben lassen.

Die Basis dafür bildet der oben erstellte Datensatz *dat_trend*.
**Aufgabe**: Fügen Sie die Trendlinien der beiden Gruppen hinzu, indem Sie den Code um die fehlende Variable auf der Y-Achse ergänzen.  
```{r}
#< fill_in
ggplot(dat_trend)+
  geom_line(aes(x = year, y = treatment))+
  geom_line(aes(x = year, y = ___))
#>
ggplot(dat_trend)+
  geom_line(aes(x = year, y = treatment))+
  geom_line(aes(x = year, y = control))
```

Wir können schon etwas ablesen, die Graphik kann allerdings noch ansehnlicher gestaltet werden um Unterschiede deutlicher zu machen. 
Dafür können wir die Linien kolorieren und sowohl die Lininenstärke, als auch den Linientyp verändern.

**Aufgabe**: Färben Sie die Linie der Treatmentgruppe in blau und die der Kontrollgruppe in rot.
*Hinweis*: Der englische Farbenname muss in Anführungszeichen angegeben werden.
```{r}
#< fill_in
ggplot(dat_trend)+
   geom_line(aes(x = year, y = treatment), colour= ___, linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = control), colour = ___, linetype = 1, linewidth = 0.8)
#>
ggplot(dat_trend)+
   geom_line(aes(x = year, y = treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = control), colour = "red", linetype = 1, linewidth = 0.8)
```

Um klarzumachen, in welcher Periode wir uns befinden, kann der Zeitpunkt der Einführung des nationalen Mindestlohns markiert werden.
**Aufgabe**: Fügen Sie hierfür das letzte Jahr ein, in dem der Mindestlohn nicht galt.
*Erinnerung:* Das Jahr gibt das Ende des letzten Geschäftsjahres an.
```{r}
#< fill_in
ggplot(dat_trend)+
   geom_line(aes(x = year, y = treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = control), colour = "red", linetype = 1, linewidth = 0.8)+
   geom_vline(xintercept = ___)
#>
ggplot(dat_trend)+
   geom_line(aes(x = year, y = treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = control), colour = "red", linetype = 1, linewidth = 0.8)+
   geom_vline(xintercept = 1999)
  
```

Zum Abschluss geben wir dem Graphen einen Titel, sowie eine passende Achsenbeschriftung.
**Aufgabe**: Führen Sie den Code mittels *check* aus.
```{r}
#< task
ggplot(dat_trend)+
   geom_line(aes(x = year, y = treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = control), colour = "red", linetype = 1, linewidth = 0.8)+
   geom_vline(xintercept = 1999)+
  xlab("Jahr")+
  ylab("logarithmierter Durchschnittslohn")+
  ggtitle("Entwicklung des logarithmierten Durchschnittslohns in Kontroll- und Treatmentgruppe")
#>
```

#< award "Graphikkünstler"
Sie haben erfolgreich ein Liniendiagramm mit ggplot2 entwickelt.
#>



#< quiz "3"
question: Erkennen Sie einen parallelen Trend?
sc:
    - Ja
    - Nein*

success: Während die Löhne in der Kontrollgruppe konstant zu steigen scheinen, läuft der Trend der Treatmentgruppe nicht konstant und auf einem gleichbleibenden Niveau.
failure: Auch wenn es hier meist um eine subjektive Einschätzung geht, sollten Sie sich die unterschiedlichen Steigungen der Trends ansehen.
#>

In unserer Betrachtungsweise ist kein eindeutig paralleler Trend zu erkennen. Ist deshalb die DiD-Schätzung eine falsche Methode, um die Effekte der Mindestlohneinführung zu betrachten?
(Rambachan, A., & Roth, J. (2023). A more credible approach to parallel trends. Review of Economic Studies, 90(5), 2555-2591.)

Aufgrund des kurzen Betrachtungszeitraums des Trends sollte diese Einschätzung aber auch mit Vorsicht genossen werden: Es wird sich auf Trends bezogen, die sich auf sechs Datenpunkte (1994-1999) stützen. Die Betrachtung eines größeren Zeitraums könnte hier eine genauere Betrachtung zulassen.
Bezüglich der PTA gibt es seitens der Autoren keine weiterführenden Analysen, eine Erwähnung wird innerhalb des Artikels vergeblich gesucht.

-----------

Nachdem wir um die Komplexität der allgemeinen Voraussetzungen für eine DiD-Schätzung wissen, können wir uns weiter der Relevanz der Gruppenwahl widmen.
In der erstellten Graphik haben wir die Treatment- und Kontrollgruppen zunächst als gegeben angenommen, ohne die Entstehung zu hinterfragen.

Der Frage der Entstehung gehen wir nun nach.

Im Mittelpunkt der Mindestlohneinführung steht der Wert von 3.60 Pfund pro Stunde. Da unser Datensatz allerdings keine Daten zu jedem Arbeitnehmer enthält, müssen wir uns der Wahl der Treatmentgruppe nähern.


Die Variable, die den Lohn innerhalb eines Unternehmens am Besten widerspiegelt ist hierbei *avwage*, worüber sich auch im Artikel genähert wird. Dabei werden alle Unternehmen mit einem durchschnittlichen Lohn kleiner gleich 12,000£ in die Treatmentgruppe einsortiert. 
Um zu verstehen, warum sich für diesen Wert als Obergrenze entschieden wird ist es hilfreich, den Wert in Zusammenhang mit dem Stundenlohn zu bringen.
Dazu soll zunächst der durchschnittliche Lohn aller Unternehmen aus der Treatmentgruppe in der Pre-Policy Periode ermittelt werden.

**Aufgabe**: Setzen Sie die passenden Werte in die Lücken ein. (Hinweis: *Avwage* wird im Datensatz in 1000 Pfund angegeben)
```{r}
#< fill_in
mean_treat = dat %>%
  filter(avwage <= ___) %>%
  filter(year == ___) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
#>
mean_treat = dat %>%
  filter(avwage <= 12) %>%
  filter(year == 1999) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
```
```{r}
#< task
mean_treat / 2000
#>
```

Mit dieser Näherung kommt man in die Nähe des Mindestlohns. Dennoch ist dies auch mit Vorsicht zu genießen. Da die Wahl der Treatmentgruppe auf Durchschnittslöhne eines gesamten Unternehmens beruht, können große Ausreißer das Ergebnis beeinflussen. Es wird eine Vollzeitbeschäftigung vorausgesetzt, wobei der Anteil an Teilzeitarbeit im betrachteten Beispiel bei über 16% lag: (Quelle???)

Berechnen Sie den Anteil an Teilzeitarbeitern (*ptwk*) in unserem Datensatz *dat*. 
Hinweis: Da es immer sein kann, dass Daten nicht vollständig sind, fügen wir *na.rm = TRUE* hinzu, um fehlende Einträge bei der Berechnung zu ignorieren.
```{r}
#< fill_in
mean(___, na.rm = TRUE)
#>
mean(dat$ptwk, na.rm = TRUE)
```


Die Wahl der Treatmentgruppe kann allerdings weiter durch die Verwendung des WERS-Datensatzes untermauert werden. 
So kann die Lohnverteilung innerhalb eines Unternehmens mit dem Durchschnittslohn in Zusammenhang gebracht werden. Die Autoren kommen zu dem Schluss, dass 87% aller vom Mindestlohn profitierenden Arbeiter in Unternehmen arbeiten, in denen der jährliche Durchschnittslohn bei 12,000 Pfund oder niedriger liegt. 

**Figure 1**
```{r}
#< task
dat_seq = read_dta('seq98.dta')
#>
```


Nun haben wir im ersten Schritt die Gruppen und Perioden definiert. Als nächstes werden wir die Daten aktiv den jeweiligen Gruppen zuordnen und zusammenfassen.



## Exercise 3.2 -- händische DiD-Berechnung

Mit einem Blick auf den Datensatz erkennt man, dass für die unterschiedlichen Gruppen bereits Dummy-Variablen erstellt worden sind.

**Aufgabe**: Laden Sie erneut den bereits bekannten Datensatz und geben Sie die ersten Zeilen aus, indem Sie lediglich "check" drücken.
```{r}
#< task
dat = read_dta('main_fame.dta')
#>

```
Führen Sie nun den folgenden Code aus, indem Sie den Datensatz nach den für die DiD-Schätzung relevanten Variablen gruppieren. Dadurch erhalten Sie eine Tabelle, die alle relevanten Daten für eine händische Berechnung enthält.
```{r}
#< fill_in
dat_table_DiD = dat %>%
  ___(ctreat1, NMW)%>%
  filter(pp == 1) %>%
  summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))
#>
dat_table_DiD = dat %>%
  group_by(ctreat1, NMW)%>%
  filter(pp == 1) %>%
  summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))
```

#< quiz "3.2.1"
question: Wieso wird der Mittelwert verwendet und nicht nur die beiden Jahre vor und nach der Mindestlohneinführung? 
sc:
    - Durch die Betrachtung können kurzfristige Schwankungen und zufällige Effekte abgefedert werden.*
    - Um einen deutlicheren Unterschied zwischen den beiden Perioden zu erhalten.
    - ???

success: Richtige Antwort. Bei der Difference in Differences Schätzung ist es hilfreich einen größeren Zeitraum zu betrachten. Die reine Veränderung des Ergebnisses, worauf Antwort B abzielt, sollte kein Grund bei statistischen Analysen sein.
failure: Das ist nicht korrekt. 
#>

**Wieso wird der Dummy "pp" angewandt?**

Im obigen Code wird der Datensatz anhand der Variablen "pp" gefiltert.

#< quiz "3.2.2"
question: Wieso und nach welchem Kriterium könnte hier gefiltert werden? 
sc:
    - Es gibt starke Unterschiede in der Berichterstattung zwischen den Ländern im UK. Daher fokussieren wir uns auf England.
    - Aufgrund einer höheren Teilzeitquote bei Frauen, filtern wir hier nach Geschlecht und legen den Fokus auf die Männer.
    - Da kleinere Firmen von manchen Teilen der Berichterstattung befreit sind, sind ihre Daten unvollständig. Daher werden sie nicht weiter berücksichtigt.* 

success: Richtige Antwort. Diese Vorauswahl wird von Seiten der Autoren getroffen (S. 135, (Verw. 13)). Untersuchungen wurden ebenfalls für den gesamten Datensatz durchgeführt, die grundlegenden Ergebnisse ähneln sich dabei. 
failure: Diese Antwort ist leider falsch. 
#>

Werfen wir einen Blick auf die aussortierten Daten und überprüfen anhand der Beschäftigungszahlen, ob es Aufffälligkeiten gibt:

#< quiz "3.2.3"
question: Anhand welcher kennzahlen können wir die oben erwähnten kleinen Unternehmen erkennen? 
sc:
    - a
    - b*
    - c 

success: Richtig.
failure: Diese Antwort ist leider falsch.
#>

```{r}
dat_no_pp = dat %>%
  filter(pp == 0)

dat_pp = dat %>%
  filter(pp == 1)

boxplot(log(dat_no_pp$emp),log(dat_pp$emp))
boxplot(log(dat_no_pp$net_pcm),log(dat_pp$net_pcm))
boxplot(log(dat_no_pp$avwage),log(dat_pp$avwage))
boxplot((dat_no_pp$manuf),(dat_pp$manuf))
boxplot(log(dat_no_pp$turnemp),log(dat_pp$turnemp))

```



Im Gesamten ist zu erkennen, dass die Daten, die sich nicht in der Auswahl befinden, breiter gestreut sind.
Wir erkennen einen Unterschied in den Beschäftigungszahlen der beiden Gruppen.
Im Vereinigten Königreich sind **kleinere Unternehmen** von der Veröffentlichung bestimmter Daten befreit. Um eine vollumfängliche Analyse zu gewährleisten entscheiden sich die Autoren daher ein Unterbeispiel zu erstellen, in denen Daten vollumfänglich erfasst werden (S. 135).
Das schränkt allerdings auch die Bewertung ein, lenkt den Blick weg von kleineren Unternehmen und muss bei der Betrachtung der Ergebnisse bedacht werden.
Wie die Autoren die Auswahl des Unterbeispiels treffen wird nicht leider vollumfänglich bekannt und auch unsere Überlegungen lassen nur Mutmaßungen zu.



Nachdem die relevanten Daten des DiD zusammengefasst in der Tabelle "dat_table_DiD" vorhanden sind, können die Differenzen nun händisch berechnet werden.

Die Formel hierfür lautet 
***(y.post.treat - y.pre.treat) - (y.post.control - y.pre.control)***
(S. 133)

Der erste Teil beschreibt die Veränderung in der Treatmentgruppe durch das Treatment. Um andere Einflussfaktoren wie saisonale Effekte herauszurechnen, wird im zweiten Teil die Veränderung in der Kontrollgruppe berechnet, welche im Idealfall nicht vom Treatment betroffen ist.

**Aufgabe**: Werfen Sie zunächst einen Blick auf die erzeugte Tabelle und überlegen Sie, welcher Gruppe die jeweiligen Werte angehören. Lassen Sie sich dafür die oben erstellte Tabelle anzeigen und überprüfen Sie Ihre Eingabe mittels "check".

```{r}
#< task

#>
dat_table_DiD
```

#< quiz "5"
question: Welche Spalte beschreibt die Kontroll- bzw. Treatmentgruppe?
sc:
    - ctreat1*
    - NMW

success: Richtige Antwort. Ist ctreat1 = 1, so handelt es sich um die Treatmentgruppe, andernfalls ist es die Kontrollgruppe.
failure: Falsch. NMW bezieht sich auf den Zeitpunkt. 
#>

#< quiz "6"
question: Von welcher Gruppe ist die Rede, wenn NMW = 1 ?
sc:
    - Pre-Treatment
    - Post-Treatment*
    
success: Korrekt. In diesem Fall befinden wir uns im Jahr 2000 oder später.
failure: Das ist nicht richtig. In diesem Fall wäre NMW = 0.

#>

**Aufgabe**: Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
```{r}
#< fill_in
# Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
y1.post.treat = dat_table_DiD$mean_ln_avwage[___]
y1.post.control = dat_table_DiD$mean_ln_avwage[___]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[___]
y1.pre.control = dat_table_DiD$mean_ln_avwage[___]

#>
y1.post.treat = dat_table_DiD$mean_ln_avwage[4]
y1.post.control = dat_table_DiD$mean_ln_avwage[2]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[3]
y1.pre.control = dat_table_DiD$mean_ln_avwage[1]

```

#< quiz "7"
question: Wieso werden für den Durchschnittslohn logarithmierte Werte verwendet?
sc:
    - a*
    - b
    - c

success: Korrekt. 
failure: Das ist nicht die richtige Lösung.
#>

#< quiz "8"
question: Wieso gibt es in der Kontrollgruppe eine Obergrenze (20000 = Median)?
sc:
    - a
    - b*
    - c

success: Korrekt. 
failure: Das ist nicht die richtige Lösung.
#>
Neben des logarithmierten Durchschnittslohns wird auch der DiD-Schätzer der Nettorendite eines Unternehmens je Geschäftsjahr (*net_pcm*) berechnet.
Das geschieht analog zur obigen Schätzung.

**Aufgabe**: Werfen Sie erneut einen Blick auf die erstellte Tabelle und geben Sie nun die Zeilen ein, in denen der passende Wert steht.
```{r}
#< fill_in
y2.post.treat = dat_table_DiD$mean_net_pcm[___]
y2.post.control = dat_table_DiD$mean_net_pcm[___]
y2.pre.treat = dat_table_DiD$mean_net_pcm[___]
y2.pre.control = dat_table_DiD$mean_net_pcm[___]
#>
y2.post.treat = dat_table_DiD$mean_net_pcm[4]
y2.post.control = dat_table_DiD$mean_net_pcm[2]
y2.pre.treat = dat_table_DiD$mean_net_pcm[3]
y2.pre.control = dat_table_DiD$mean_net_pcm[1]
```

Die Werte sind nun gespeichert und die DiDs können berechnet werden.

**Aufgabe**: Fügen Sie dem Code das Anzeigen der Ergebnisse hinzu und führen Sie den Code mittels "Check" aus.
```{r}
#< fill_in
DiD_ln_avwage = (y1.post.treat - y1.pre.treat) - (y1.post.control - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.pre.treat) - (y2.post.control - y2.pre.control)
  
#Ergebnisse anzeigen

#>
DiD_ln_avwage = (y1.post.treat - y1.post.control) - (y1.pre.treat - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.post.control) - (y2.pre.treat - y2.pre.control)
  
#Ergebnisse anzeigen
DiD_ln_avwage
DiD_net_pcm
```

Durch die Einführung des Mindestlohns können wir sagen, dass dadurch in den beobachteten Unternehmen der Durchschnittslohn gestiegen ist. Zugleich ist zu erkennen, dass in jenen Unternehmen der Nettogewinn zurück gegangen ist.

Um diese Veränderung genauer bewerten zu können und tiefergehende Analysen zu ermöglichen, machen wir uns die Methode der Regression zu eigen.


## Exercise 3.3 -- DiD-Schätzung mittels Regression

**DAG**

Zu Beginn widmen wir uns der Veränderung im Durchschnittslohn durch die Einführung des Mindestlohns.
Um uns einen ersten Überblick über die Zusammenhänge der Variablen in unserer DiD-Schätzung zu verschaffen, sind die Directed Acyclic Graphs (DAGs) von Vorteil.
(https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html)
(https://r-causal.github.io/ggdag/)

**Aufgabe**: Führen Sie hierfür den Code mittels *check* aus und sehen Sie sich den Graphen an.
```{r}
#< task
dag <- dagify(
  ln_avwage ~ ctreat1 + treat1_NMW + NMW, 
  treat1_NMW ~ ctreat1 + NMW,
  labels = c(ctreat1 = "ctreat1", treat1_NMW = "treat1_NMW", NMW = "NMW", ln_avwage = "ln_avwage")
)

ggdag(dag, node_size = 18, text = FALSE, edge_type = "link", use_labels = "label")+
  theme_dag_blank()
#>
```

Hier sieht man wie die Variablen, mit denen wir bisher gearbeitet haben, zusammenhängen.

**Aufgabe**: Lesen Sie einen Auszug des bekannten Datensatzes dat_main ein, indem Sie den Code mit "check" ausführen.
```{r}
#< task
dat_raw = read_dta('main_fame.dta')
dat = filter(dat_raw, pp == 1) 
#>
```

Zu Beginn unserer Analyse wollen wir mehrere Regressionen mit den oben dargestellten Variablen laufen lassen. 
Dazu sollen die einzelnen Variablen, die "ln_avwage" beeinflussen, beobachtet werden.

#< info "stargazer"
Die Stargazer Funktion ermöglicht uns einen schön formatierten Output mit der Möglichkeit, mehrere Regressionen parallel darzustellen.
(https://www.rdocumentation.org/packages/stargazer/versions/5.2.3/topics/stargazer)
#>

**Aufgabe**: Führen Sie die Regression aus und stellen Sie das Ergebnis mittels der stargazer-Funktion dar.
```{r}
#< fill_in
regi = lm(ln_avwage ~ treat1_NMW, data = dat)

stargazer(___, type = "text")
#>
regi = lm(ln_avwage ~ treat1_NMW, data = dat)

stargazer(regi, type = "text")
```

#< quiz "3.3.1"
question: Wieso ist der Einfluss der Treatmentvariablen im Gegensatz zur händischen Berechnung negativ?
sc:
    - Die Regression ist genauer als die händische Berechnung.
    - Die Regression ist fehlerhaft.*

success: Korrekt. Mit Blick auf den DAG können Sie erkennen, dass der Effekt von treat1_NMW in der Regression verschätzt wird.
failure: Das ist in diesem Fall nicht der Grund für die Unterschiede. Sehen Sie sich den DAG an.
#>


Wir müssen in unserer Regression also sowohl die Interaktionsvariable als auch die die abhängige Variable beeinflussenden Dummys berücksichtigen.


$ln(avwage) = \beta_0 + \beta_1 ctreat + \beta_2 treat1*NMW + \beta_3 NMW + \epsilon$

*Aufgabe*: Berechnen Sie auf Basis dieser Formel die Einflüsse der Variablen und das damit zusammenhängende DiD-Ergebnis. 
Stellen Sie das Ergebnis wieder in *stargazer* dar.
```{r}
#< fill_in
reg1 = lm(ln_avwage ~ ___ + ___ + ___, data = dat)
stargazer(reg1, type = "text")
#>

reg1 = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW, data = dat)
stargazer(reg1, type = "text")
```

Der Wert der Interaktionsvariablen hat sich im Vergleich zur unvollständigen Regression stark verändert und erinnert an die händische Berechnung.

Um diese starke Veränderung besser zu verstehen, können wir die gemeinsame Betrachtung der erklärenden Variablen mit der einzelnen Betrachtung vergleichen.

**Aufgabe**: Führen Sie dazu den Code aus und sehen sich die Ausgabe an.
```{r}
#< task
regii = lm(ln_avwage ~ ctreat1, data = dat)

regiii = lm(ln_avwage ~ NMW, data = dat)

stargazer(regi, regii, regiii, reg1, type = "text")
#> 
```

Im Gegensatz zur händischen Berechnung können wir durch die Regression die Signifikanz unserer Schätzung beurteilen.

#< quiz "3.3.2"
question: Wie beurteilen Sie die Signifikanz unseres DiD-Schätzers in der dargestellten Regression?
sc:
    - hoch*
    - niedrig

success: Korrekt, *** bestätigt ein hohes Signifikanzniveau. 
failure: Das ist nicht richtig. Achten Sie auf die p-Werte und die dazugehörige Veranschaulichung durch Sterne.
#>


**Genestete Daten**
(Bryk, Raudenbush: Hierarchical Linear Models: Applications and Data Analysis Methods)
Die Werte der Variablen sind im obigen Fall also hoch signifikant gekennzeichnet. 
Allerdings können die p-Werte fehlerhaft sein, da es sich bei den Daten teilweise um genestete Daten handelt. 
Genestete Daten liegen vor, wenn mehrere Daten zu einer übergeordneten Einheit zählen.
In unserem Fall haben wir Daten zum logarithmierten Durchschnittslohn (*ln_avwage*) über mehrere Jahre. Diese haben ein Unternehmen (*regno*) als übergeordnete Einheit.
Um Fehler bezüglich genesteter Daten zu verhindern, führen wir **Clusterrobuste Standardfehler** ein.

#< quiz "3.3.3"
question: Nach welcher Variablen soll geclustert werden?
sc:
    - ln_avwage
    - regno*

success: Korrekt, hierbei handelt es sich um die übergeordnete Einheit, nach der geclustert werden muss.   
failure: Das ist so nicht richtig. Bei genesteten Daten muss nach der übergeordneten Einheit geclustert werden.
#>

Nun fügen wir die Clusterrobusten Standardfehler in unsere Regression ein und schauen, was sich dadurch verändert.

Führen Sie hierzu die Regression mithilfe der *felm* Funktion durch und vergleichen die Regression ohne Clustering (*reg1*) mit der Regression mit Clustering. 

#< info "felm"
Im Vergleich zu einem einfachen Regressionsmodell mit *lm*, kann durch die *felm* Funktion eine spezifiziertere Regression durchgeführt werden.
Der Grundaufbau des formulas sieht wie folgt aus:
felm(y ~ abhängige Variablen | ausgeschlossene Variablen | Spezifikation einer Instrumentalviariablen | Clusterspezifikation)
(https://www.rdocumentation.org/packages/lfe/versions/2.9-0/topics/felm)
#>

**Aufgabe**: Tragen Sie die Clusterspezifikation nach der Variablen *regno* an die passende Stelle ein und setzen die ungenutzten Spezifikationen gleich 0.
```{r}
#< fill_in
reg2 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW | ___ | ___ | ___, data=dat)
stargazer(reg1, reg2, type ="text")
#>
reg2 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data=dat)
stargazer(reg1, reg2, type ="text")
```


An den Werten der Variablen ist keine Veränderung zu erkennen. Allerdings haben sich die Werte der Standardfehler verändert.
Während man für *ctreat1* und die Interaktionsvariable eine Erhöhung des p-Wertes vorfindet, ist eine Verringerung bei der Variablen NMW zu verzeichnen.

Um diese Veränderungen zu verstehen sehen wir uns an, was es generell mit clusterrobusten Standardfehlern auf sich hat:
(Angrist, 231ff) / 
(Abadie, A., Athey, S., Imbens, G. W., & Wooldridge, J. M. (2023). When should you adjust standard errors for clustering?. The Quarterly Journal of Economics, 138(1), 1-35.)
Variiert der Regressor nur innerhalb einer Clustergruppe, so kann der Standardfehler steigen (231)


---------------

**Ergebnisanalyse**

Die Variablen beschreiben die Veränderungen im Vergleich zum Pre-Policy Jahr, welche mit *Constant* beschrieben wird.

#< quiz "3.3.4"
question: In welcher Einheit wird der DiD-Wert beschrieben?
sc:
    - Pfund
    - Prozent
    - Prozentpunkte*

success: Richtige Antwort. Der Anstieg des Gehalts in der Treatmentgruppe ist um ca. 11 Prozentpunkte höher als in der Kontrollgruppe.
failure: Das ist leider falsch. Es werden zwei log-Variablen miteinander verglichen.
#>


----------------
**NET_PCM**

Wir haben in Erfahrung gebracht, dass es einen Effekt durch die Einführung des gesetzlichen Mindestlohns gibt. 
Um herauszufinden, wie die Unternehmen auf diese Veränderung reagieren, sehen wir uns spiegelbildlich zur obigen Schätzung die Veränderung auf die Gewinnmarge *net_pcm* an.

**Aufgabe**: Führen Sie den untenstehenden Code aus und lassen sich das Ergebnis mittels *stargazer* ausgeben
```{r}
#< fill_in
reg2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data = dat)

stargazer(___, type = "text")
#>
reg2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data = dat)

stargazer(reg2, type = "text")
```
-------------

Sehen wir uns weiter an ob es zu Veränderungen kommt, wenn wir auf bestimmte Effekte der Unternehmenswelt kontrollieren.
Dafür können wir uns die Funktion der Faktorvariablen zunutze machen.

## **Faktorvariablen**
Da wir bei nominalskalierten Daten keine Möglichkeit zur messbaren Unterscheidung finden, müssen wir Faktorvariablen nutzen, um diskrete Daten in die Regression miteinzubeziehen. 
Technisch umsetzbar wird diese Faktorisierung, indem eine Gruppe die Referenz bildet. Statistisch gesehen geht diese Wahl willkürlich vonstatten, inhaltlich gibt es nach Hardy (1993) drei Grundüberlegungen zur Wahl der Referenzgruppe:

So soll die Referenzgruppe 

1. Einen sinnvollen Vergleich bieten

2. Klar definiert sein

3. Eine ausreichend große Stichprobengröße im Vergleich zu anderen Gruppen besitzen


(https://learning.oreilly.com/library/view/applied-multiple-regression-correlation/9780805822236/xhtml/15_Chapter_08.xhtml#h8_2 
=> Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). "Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences.", Kapitel 8.2)


#< info "factor"
In R können wir entweder die Variablen innerhalb der Regression faktorisieren, oder bereits im Datensatz.
#>

Die Variable *year* möchten wir in unserem Datensatz faktorisieren und erstellen hierfür eine neue Variable *factor_year*. Vergleichen Sie weiter die Werte der neuen mit der bereits existierenden Variablen, indem Sie sich mittels *head()* die ersten Einträge anzeigen lassen.
```{r}
dat = dat %>%
  mutate("factor_year" = factor(year))

head(dat$year)
head(dat$factor_year)
```
Die Einträge scheinen zunächst identisch, dennoch ist bei unserer faktorisierten Variablen der Eintrag *Levels* zu finden.

Levels gibt die unterschiedlichen Kategorien innerhalb der Variablen an. Dabei stellt die erste Kategorie die Referenzkategorie dar.

#< quiz "3.3.5"
question: Wie bewerten Sie die gewählte Referenzkategorie? (Denken Sie dabei an die oben beschriebenen Grundüberlegungen)
sc:
    - Das Jahr 1997 ist sinnvoll gewählt, da es den Startpunkt unserer Analyse markiert. 
    - Es gibt andere Jahre, die auf Basis unserer Analyse einen wichtigeren Punkt markieren*
    - Alle Jahre sind gleich relevant und die Grundüberlegungen treffen auf jedes Jahr zu. Daher kann das Jahr beliebig gewählt werden.

success: Richtige Antwort. R wählt automatisch den kleinsten Wert bei der Faktorisierung, ohne Berücksichtigung der Relevanz.
failure: Das ist so nicht korrekt, überlegen Sie nochmal auf welche Jahre wir bei unserer DiD-Schätzung einen besonderen Fokus gelegt haben.
#>

Eine besser geeignete Referenzkategorie können wir selbst festlegen.

**Aufgabe**: Wählen Sie das Jahr 2000 als Referenzwert für unsere Faktorisierung.
```{r}
#< fill_in
dat$factor_year = relevel(dat$factor_year, ref = "___")
#>
dat$factor_year = relevel(dat$factor_year, ref = "2000")
```



Sehen wir uns nun an, was diese Faktorisierung für die Regression bedeutet, indem wir die Regression einmal mit *year* und einmal mit *factor_year* ergänzen.

**Aufgabe**: Geben Sie den Vergleich der unterschiedlichen Regressionen aus, indem Sie den Code mittels *check* ausführen.
```{r}
reg2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data = dat)
reg2.1 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + year| 0 | 0 | regno, data = dat)
reg2.2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + factor_year| 0 | 0 | regno, data = dat)
reg2.3 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + factor(year)| 0 | 0 | regno, data = dat)


stargazer(reg2, reg2.1, reg2.2, reg2.3, type= "text")
```

Wir sehen, dass sich die Ergebnisse durch eine Faktorisierung verändern.
Ebenfalls durch die Veränderung der Referenzkategorie entstehen Unterschiede, wenn auch im überschaubaren Rahmen. 

Dabei gilt dennoch zu erwähnen, dass die Autoren des Artikels bei der Wahl der Referenzkategorie wohl einer anderen Idee der Wahl gefolgt sind und das Jahr 1997 als Referenz gewählt haben. 

Da durch die Darstellung der Faktorvariablen eine längere Ausgabe entsteht, kann es beim Hinzufügen mehrerer Faktorvariablen aus Gründen der Übersichtlichkeit und Vergleichbarkeit sinnvoll sein, unsere Ausgabe auf das Relevanteste reduzieren.

Hierbei lernen Sie eine alternative Darstellung der Regressionsergebnisse zu *stargazer* kennen.

**Aufgabe**: Laden Sie hierfür zunächst das Paket *broom*
```{r}
#< fill_in
library(___)
#>
library(broom)
```

**Aufgabe**: Führen Sie den Code aus, um aus der Liste - die uns durch die *felm*-Funktion erstellt wird - eine Tabelle der Regression zu kreieren. Geben Sie anschließend die Tabelle aus.
```{r}
#< fill_in
table_reg2.3 = tidy(reg2.3)

#Tabelle ausgeben

#>
table_reg2.3 = tidy(reg2.3)

#Tabelle ausgeben
table_reg2.3
```

Nun haben wir die relevanten Werte der Regression in der Tabelle gespeichert und können darauf wie auf jeden anderen Data Frame zurückgreifen.

#< award "tidy broomer"
Glückwunsch, Sie haben die Regressionsausgaben erfolgreich in einer Tabelle gespeichert.
Um mehr über das broom Paket zu erfahren, geht es [hier](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) entlang.
#>

**Hinweis:** Wir nutzen das Tool, um einen besseren Überblick über die Veränderung durch Variablen zu erhalten. Es dient als Hilfsmittel und nicht als genereller Mechanismus, um Regressionsergebnisse zu analysieren. 

-----------

In der vorherigen Regression haben wir festgestellt, dass es sowohl eine Veränderung in den Löhnen, als auch in den Unternehmensgewinnen gibt. 

Jetzt geht es darum zu überprüfen, ob die Veränderung der Unternehmensgewinne wirklich auf die Einführung des Mindestlohns zurückgeht und ob weitere Faktoren die Gewinnmarge eines Unternehmens beeinflussen können.
Dabei prüfen wir auf unternehmens- und branchen- und ortsspezifische Größen.

**Aufgabe:** Führen Sie die Regressionen mittels *check* aus.
```{r}
#< task
reg3 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg4 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)
#>
```


```{r}
tidy_reg1 = tidy(reg1)
tidy_reg2 = tidy(reg2)
tidy_reg3 = tidy(reg3)
tidy_reg4 = tidy(reg4)
stargazer(reg4, type = "text")
```

Das waren sehr viele Regressionen, da kann es manchmal kompliziert sein den Überblick zu behalten.
Um die wichtigsten Ergebnisse knapp zusammenfassen zu können, gibt es die Möglichkeit einzelne Werte aus den jeweiligen Regressionen auszuwählen und sie dann in einer Tabelle gegenüberzustellen.
Dabei sehen wir uns die Veränderung des Kernergebnisses an.

**Aufgabe**: Erzeugen Sie die gegenüberstellende Tabelle mittels *check* und lassen sie sie ausgeben.
```{r}
reg_table_net_pcm = data.frame("Variable" = c("Constant", "ctreat1", "treat1_NMW", "NMW"),"reg2" = round(tidy_reg2$estimate[1:4],3),"reg2_p"= round(tidy_reg2$p.value[1:4],3), "reg4" = round(tidy_reg4$estimate[1:4],3), "reg4_p"= round(tidy_reg4$p.value[1:4],3))

reg_table_net_pcm
                              
```


**Table 2, Panel B**

**Kontinuierliche Messung**

Bisher haben wir uns auf die Unterscheidung zwischen Treatment und keinem Treatment konzentriert. Dabei wurde deutlich, dass sowohl einen signifikante positive Änderung des Lohns, als auch eine negative signifikante Veränderung der Gewinnmarge vorhanden sind. Da diese sich diese Unterscheidung allerdings auf die vorangegangene eigene Definition der beiden Gruppen stützt, kann die Betrachtung durch eine weitere Methode hilfreich sein. Zudem wollen wir einen genaueren Effekt je nach Einkommen erhalten.

Im Vergleich zur diskreten Messung wird bei der kontinuierlichen Messung kein Dummy für die Treatments verwendet, sondern ein bestimmter Wert.


Um diese kontinuierliche Analyse zu ermöglichen, wird anstatt der Treatmentvariablen *ctreat1* eine andere Variable gewählt.
In unserem Fall ist das *c_avwage99* und beschreibt den logarithmierten Durchschnittslohn zum Jahr 1999 nach Unternehmen gruppiert.

**Diskrete Daten vs. Kontinuierliche Daten**

| Merkmal             |     Diskrete Daten      |     Kontinuierliche Daten     |
|---------------------|--------------------------|-------------------------------|
| Generell            |                         |                               |
| Vorteil             |                         |                               |   
| DiD-Schätzung       | Verwendung von Dummys   | Verwendung konkreter Werte    |
| Treatmentvariable   | ctreat                  | c_avwage99                    |
| Werte               | 0 oder 1                | logarithmierter Durchschnittslohn im Jahr 1999 |


**Aufgabe:**Ersetzen wir nun aus der vorherigen Regression die Dummyvariable ctreat1 durch die Variable mit kontinuierlichen Werten, *c_avwage99*. Um mit den relevantesten Daten arbeiten zu können, erstellen wir dazu wie gewohnt tidy Datensätze.
```{r}
reg5 = felm(ln_avwage ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg6 = felm(net_pcm ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

tidy_reg5 = tidy(reg5)
tidy_reg6 = tidy(reg6)

stargazer(reg5, reg6, type = "text")
```
WAS HAT SICH GEÄNDERT?
WIE KANN DAS ERGEBNIS INTERPRETIERT WERDEN?
WIESO BRAUCHT MAN DAS?
  - Vergleich zur imaginären Einführung



## Exercise 3.4 -- Imaginäre Mindestlohneinführung

- Sind die Veränderungen auf das Treatment zurückzuführen?
  - Vergleich zu Parallel-Trend
- Imaginäre Einführung am 1. April 1996
- Vergleich Datensätze: ff=0 vs. ff=1
- Table 3
- Figure 3

Um weiter zu überprüfen, ob die Mindestlohneinführung der Grund für die Ergebnisse der DiD-Schätzung ist, kann ein **Placebo Experiment** eingeführt werden.(142ff.)
Hierfür wird die Mindestlohneinführung imaginär um drei Jahre vorverlegt, auf den 01. April 1996.
Dabei können wir auf die Vorarbeit im Datensatz zurückgreifen. Ähnlich wie bei der vorangegangenen Schätzung zur realen Mindestlohneinführung wird der Datensatz anhand eines Dummys gefiltert.

**Aufgabe:** Lesen Sie den Datensatz ein und teilen ihn nach den Dummywerten von ff auf.
```{r}
#< fill_in
dat = read_dta('main_fame.dta')
dat_ff1 = filter(dat, ff == ___)
dat_ff0 = filter(dat, ff == ___)
#>
dat = read_dta('main_fame.dta')
dat_ff1 = filter(dat, ff == 1)
dat_ff0 = filter(dat, ff == 0)
```

Um zu verstehen, warum manche Einträge von Firmen ausgelassen werden, hilft ein Vergleich der oben erstellten Variablen.

**Aufgabe:** Gruppieren Sie dazu die Datensätze nach den Jahren und geben sie die Anzahl der Einträge pro Jahr aus. Hinweis: Die Funktion length(*Variable*) gibt die Anzahl der Einträge wieder.
```{r}
#< task
dat_ff1 %>%
  group_by(year)%>%
  summarise(length(year))

dat_ff0 %>%
  group_by(year)%>%
  summarise(length(year))
#>
```

Es fällt auf, dass sich im untersuchten Datensatz **dat_ff1** nur Einträge befinden, die sich auf den Zeitraum **vor** der reellen Mindestlohneinführung beziehen.

Allerdings werden auch Daten aus den Jahren 1994 - 1999 herausgefiltert. Sehen wir uns an, wie das mit dem von den Autoren gefundene Unterbeispiel (pp) zusammenhängt.

**Aufgabe:** Führen Sie den Code mittels *check* aus.
```{r}
#< task
dat_ff0 %>%
  group_by(pp)%>%
  summarise(length(pp))

dat_ff1 %>%
  group_by(pp)%>%
  summarise(length(pp))
#>
```

Der Anteil an pp==0 ist im unberücksichtigten Datensatz deutlich höher als im am Ende betrachteten Datensatz dat_ff1. Allerdings werden nun auch Unternehmen berücksichtigt, die bei den Analysen zur reellen Mindestlohneinführung nicht berücksichtigt wurden.
Der Grund dafür könnte sein, dass sich die Zahlen in den Unternehmen verändert haben.???

```{r}
dat_ff0 = filter(dat_ff0, year==1996)
dat_ff1 = filter(dat_ff1, year==1996)
boxplot(dat_ff0$ln_avwage,dat_ff1$ln_avwage)
mean(dat_ff0$avwage, na.rm = TRUE)
mean(dat_ff1$avwage)
max(dat_ff1$avwage)
```

Wie in den vorherigen Analysen sind die Ursachen für die Aussortierung einiger Daten leider nicht erkennbar und auch eigene statistische Analysen konnten die Auswahl nicht vollumfänglich erklären. 
Weiter werden wir die Analysen mit dem von den Autoren gegebenen Unterbeispiel durchführen.

Dafür können wir dieselbe Regression wie im Kapitel 3.3 verwenden mit dem Unterschied, dass der Datensatz nun nach *ff* gefiltert wird.
**Aufgabe:** Filtern Sie den Datensatz *dat* nach Daten, die im Unterbeispiel angewandt werden.
```{r}
#< fill_in
dat = filter(dat, ff == ___)
#>
dat = filter(dat, ff == 1)
```

**Diskret**
```{r}
reg7 = felm(ln_avwage ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg8 = felm(net_pcm ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg7, reg8, type = "text")
```


**Kontinuierlich**
```{r}
reg9 = felm(ln_avwage ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg10 = felm(net_pcm ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg9, reg10, type = "text")
```
----------------

Die Regressionen bilden die Grundlage zur Beantwortung der Frage

**Vergleich Fig 3**
- Treatmenteffekt net_pcm

Intervalle erstellen
```{r}
pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))
```
```{r}
dat_fig3 = dat %>%
  mutate("threshold" = round(exp(c_avwage99)*1000,-2)) %>%
  filter(threshold <= 16000) %>%
  filter(threshold >= 10000) %>%
  
  group_by(threshold) %>%
  summarise(length(threshold), mean(avwage99_NMW))
```

Regression in 100er Schritten durchführen und wiederholen. Die grenze wird nach oben verschoben und es werden immer mehr Einträge berücksichtigt.
Ergebnisse je 100 in Liste speichern

```{r}
#Neuen Datensatz erstellen
dati = read_dta('main_fame.dta')
dati = filter(dati, pp==1)

```

```{r}

# Schleife initiieren
i = 10000
while(i<=16000){
dati = mutate(dati, "treat1" = NULL)
dati$ctreat1 = NULL
dati$avwage = dati$avwage * 1000

dati$treat1 = ifelse(dati$year == 1999 | dati$avwage <= i, 1, 0)
dati$ctreat1 = ifelse(dati$treat1 == 1, 1, 0)
dati = mutate(dati, treat1)


dati$paste("treat1", i, "_NMW") = dati$ctreat1*dati$NMW
  
# Regression innerhalb der Schleife
reg = felm(net_pcm ~ ctreat1 + paste("treat1", i, "_NMW") + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dati)

i + 100
}
```



```{r}
library(ggplot2)
ggplot(dat_fig3, aes(x = threshold))+
  geom_line(aes(y = avwage99_NMW))

```




## Exercise 4 -- Einordnung des Artikels (weiterführende Überlegungen)

- EU-weiter Mindestlohn (Möglichkeiten, Chancen, Probleme)
- Unterschiede zu 1999 (Andere Rahmenbedingungen?, Brexit?)
- unberücksichtigte Variablen
- Auswirkung auf Beschäftigung
- weitere Artikel (andere Auswirkungen untersucht)
- Strukturen in Unternehmen
- Ist der Mindestlohn zu befürworten? (sozial, ökonomisch)

Probleme:
  Undurchsichtigkeit bei den Beispielsfirmen (951 von 4112)
  Wahl der Treatmentgruppe ist eine Näherung
  
Komponenten: 
- Bewertung des Artikels
Die wissenschaftliche Arbeit von Draca et al. macht sich die besondere Eigenschaft des quasi-experimentellen Experiments zu eigen und wählt dazu passenderweise die Methodik der Difference-in-Differences Schätzung.
Dabei zeigen die Autoren gut auf, dass die Einführung von Mindeslöhnen zu einer Veränderung der Unternehmensgewinne führt. 
Durch die Wahl von plausiblen Kontrollvariablen aus unterschiedlichen Bereichen der Unternehmenswelt wirkt die Argumentation fundiert.
Der zunächst nicht evidenten Einteilung in Kontroll- und Treatmentgruppe wird sich genähert und anhand von Lohnstrukturen werden die Daten logisch nachvollziehbar eingeteilt.
Kritisch anzumerken ist die Wahl der Beispieldatensätze. Hier wird wenig transparent argumentiert und eine klare Struktur der Idee der Selektion ist nicht erkennbar.
Eine weitere Komponente, die im Rahmen der Analyse vermisst wird, ist eine finanzielle Rahmenbedingung als Kontrollvariable.
- Rückbezug zur Einleitung

## Exercise Anregungen

- "Aber was sind die Produktionskosten - des Arbeiters, d.h. die Kosten, um den Arbeiter selbst zu produzieren?" / "Wert der Arbeit" (Kapital, 497)



## Exercise Submitting your solution

To submit your solution please proceed as follows:

1. Scroll to the top and click on the icon with the bars <i class="fa fa-tasks fa-fw"></i> to see how many points you got so far. If you want to have more points you can try to solve the missing tasks.

2. If you want to submit click on the download button <i class="fa  fa-download fa-fw"></i> at the very right.

3. In the opened tab click the button "Download Submission File". Your browser should then download a file with the extension `.sub`.

4. Upload that downloaded file to your course management system like Moodle, as specified by your instructor.




## Mindestlohn und Firmenprofitabilität: Eine interaktive Analyse

- Einführung .


#< ignore
```{r "setup"}
library(RTutor)
# Adapt working directory
setwd("C:/Users/lasse/Documents/GitHub/RTutorMindestlohn/inst/Mindestlohn")
ps.name = "Mindestlohn"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all packages you load in the problem set
libs = c("ggplot2","haven","stargazer","sandwich", "ggdag", "lfe") 
create.ps(sol.file=sol.file, ps.name=ps.name,libs=libs, rps.has.sol=TRUE, addons="quiz")
# Show the problem set in the webbrowser
show.ps(ps.name,sample.solution=FALSE,auto.save.code = TRUE)
```
#>

## Exercise Inhaltsübersicht

1. Einführung in den Mindestlohn

2. Datenüberblick

3. Difference in Differences

4. Einordnung des Artikels

**Ideen**
Diagramm Variablenbeeinflussung


## Exercise 1 -- Einführung in den Mindestlohn

- Relevanz der Forschungsfrage
- Hintergrund der Mindestlohneinführung
- sic
- Vergleich zu anderen Staaten
- Wie werden Unternehmensgewinne definiert?
- Theoretisch mathematischer Hintergrund / Ausgangspunkt
  - Messung Unternehmensgewinne
  - Messung Mindestlohn

**"Jetzt 12€ Mindestlohn wählen."**
Ein zentrales Wahlkampfthema der SPD zur Bundestagswahl 2021. Es war nicht das erste und wird auch nicht das letzte Mal gewesen sein, dass die Versprechung zur Verbesserung des Lohns ein zentrales Instrument der Arbeitsmarktpolitik ist, um eine große Wählerschaft zu mobilisieren.
Hinter diesem leicht verständlichen Versprechen steckt die komplexe Frage, wie die Lohnerhöhungen getragen werden.
Besonders die Frage der Auswirkungen auf die Beschäftigung wirft in der Forschung Kontroversen auf.

Daher wählen wir mit unserer Analyse nach Draca et. al (2008) einen anderen Ansatz. Anstatt die Beschäftigung in den Vordergrund zu rücken widmen wir uns der vorgelagerteten Frage, wie die Lohnsteigerungen innerhalb von Unternehmen kompensiert werden. Eine solche Betrachtungsweise ist in der Forschung bisher weitestgehend unbeachtet geblieben.
Diese Analyse führen wir für Unternehmensdaten aus dem Vereinigten Königreich (UK) durch, da hier die gesetzlichen Rahmenbedingungen eine große Breite an bereitgestellten Daten ermöglichen.
Zudem wurde in der Analyse kein großer Einfluss auf die Beschäftigung wahrgenommen.


#< quiz "1"
question: Wie können Unternehmen die Lohnsteigerung kompensieren?
sc:
    - Verkleinerung der Gewinnmarge*
    - Weitergabe der Kostensteigerung an Verbraucher
    - Effizienzsteigerung

success: Auf dieser Vermutung beruht unsere Untersuchung.
failure: Eine plausible Antwort, allerdings werden hierfür keine Belege gefunden (Draca et al, S.130)
#>


**Hintergrund der Einführung**
Quellen: FES 09/2007
Wie in Deutschland, wurden und werden Löhne in Großritannien teilweise durch Tarifverhandlungen festgelegt. Die Notwendigkeit der Einführung eines nationalen Mindestlohns wurde in Großbritannien durch den sinkenden Einfluss von Gewerkschaften gesehen. Haben im Jahr 1970 noch 80% der Arbeitnehmer von Tarifverträgen profitiert, sank dieser Anteil bis 2000 um 50 Prozentpunkte.
Mit einem Machtwechsel im britischen Unterhaus, hin zur sozialdemokratischen Labour-Partei, kommt es zur Veränderung in der Arbeitspolitik. Zum 1. April 1999 wird der nationale Mindestlohn eingeführt.

#< quiz "1.1"
question: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien zur Einführung 1999 (in Pfund)?
sc:
    - 3.6*
    - 5.7 
    - 7.8 

success: Korrekt. Der Artikel befasst sich mit der Einführung des Mindestlohns in Höhe von 3.60 Pfund.
failure: Diese Schätzung ist zu hoch.
#>


Weiter gilt zu erwähnen, dass der nationale Mindestlohn (NMW) nicht die erste Art des Mindestlohns in Großbritannien war. Von 1909 bis zum Jahr 1993 an wurden gesetzliche Mindestlöhne durch *Wage Councils* innerhalb von Branchen bestimmt. 
Das Novum des NMW liegt in der Reichweite über alle Branchen hinweg. Ähnlich wie die *Wage Councils*, gibt die unabhängige Niedriglohnkommission (LPC) eine Empfehlung zur Mindestlohnhöhe. Von 1999 an wird die Lohnhöhe fortlaufend von der Niedriglohnkomission angepasst.

#< quiz "1.2"
question: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien im Jahr 2024 (in Pfund)?
sc:
    - 9.11
    - 11.22*
    - 14.44
    

success: Korrekt. Für Personen über 21 gilt dieser Mindestlohn von April 2024 an.
failure: Diese Schätzung ist falsch.
#>
https://www.gov.uk/national-minimum-wage-rates



**Unternehmensgewinne**


## Exercise 2 -- Datenüberblick

- Herkunft der Daten
- Wieso Großbritannien?
- Ausgewogenheit der Daten
- Datensatz WERS
- Datensatz main (FAME (Financial Analysis Made Easy(135)))
  - Gesetzliche Verpflichtung
  - Auch Analyse kleinerer Unternehmen möglich (135)
  - Betrachtung von Firmen mit Geschäftsjahr April-März (Filter-Sample) (135)
- Labor Force Survey (136f.)
  - Arbeitsumfeld
  
**Relevante Variablen**

**Aufgabe**: Lesen Sie den Datensatz 'main_fame.dta' mit der Funktion 'read_dta' ein und speichern Sie den Datensatz unter 'dat_main'. Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
#Datensatz einlesen
#>
dat = read_dta('main_fame.dta')
```
Um einen ersten Überblick über den Datensatz zu bekommen, geben sie die ersten Zeilen des Datensatzes mittels der Funktion head aus.
```{r}
head(dat)
```
Wir erhalten eine Vielzahl an Variablen, die mehr oder minder relevant für unsere Analysen sind.

Widmen wir uns den wesentlichsten Variablen für unsere Analyse:

**regno**: Hier handelt es sich um eine bestimmte Nummer, mit der die Daten jedem bestimmten Unternehmen zugeordnet werden können.

**year**: Gibt das Jahr an, aus dem die Daten stammen. Dabei wird das zurückliegende Geschäftsjahr betrachtet.

**ln_avwage**: Benennt den logarithmierten Durchschnittslohn im Unternehmen.

**net_pcm**: Die Gewinnmarge eines Unternehmens wir durch die Division vom Nettogewinn durch den Gesamtumsatz im Geschäftsjahr angegeben.

**sic2**: Die Unternehmen werden in Großbritannien nach Branchen in unterschiedliche Branchen unterteilt. Der bis zu vierstellige UKsic (UK Standard Industrial Classification of Economic Activities) beschreibt dabei die Branchen.
Das oben ausgegebene Unternehmen besitzt den UKsic 7020. Die sic2-Zahl ist somit 70 und beschreibt Immobilienaktivitäten.   
(https://webarchive.nationalarchives.gov.uk/ukgwa/20160105160709/http://www.ons.gov.uk/ons/guide-method/classifications/archived-standard-classifications/uk-standard-industrial-classification-1992--sic92-/uk-sic-2003.pdf)

**unionmem**: Beschreibt den Anteil an Gewerkschaftsmitgliedern innerhalb des Unternehmens.

**ptwk**: Anteil an Teilzeitarbeitern innerhalb der vierstelligen UKsic-Branche (sic4).

**female**: Frauenanteil bei Arbeitnehmern innerhalb des sic4.

**gorwk**: Gibt den Regierungsbezirk des jeweiligen Unternehmens an.


## Exercise 2.1 -- Schaubild / Wahl der Gruppen

Es soll überprüft werden, wie sich die Einführung des Mindestlohns auf die unterschiedlichen Einkommen ausgewirkt hat. 
Um die Veränderung des Lohns zum Vorjahr zu messen, muss der Datensatz zunächst für jedes einzelne Jahr aufgeteilt werden.

Zu Beginn wird erneut der Datensatz aus Aufgabe 2 eingelesen.

**Aufgabe**: Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
dat_main = read_dta('main_fame.dta')
#>

```

Um die Veränderung der Löhne von Geschäftsjahr zu Geschäftsjahr herauszufinden, muss der Datensatz nach Jahren aufgeteilt werden. Das gelingt, indem für jedes Jahr ein eigener Datensatz erstellt wird. Dafür muss der bereits eingelesene Datensatz dat_main zunächst gefiltert werden.

**Aufgabe**: Wählen Sie die passende Variable für das leere Feld und überprüfen Sie Ihre Eingabe durch "check".
```{r}
#< fill_in
pcw95 = dat_main %>%
  filter(___ == 1995) %>%
  filter(avwage >= 3)
#>
#
pcw95 = dat_main %>%
  filter(year == 1995)%>%
  filter(avwage >= 3)
```

-#Wieso werden nur Werte für avwage >= 3 gewählt? Verfälschung der Ergebnisse? Was für Unternehmen sind betroffen(sic überprüfen)?

```{r}
dat_probe = dat_main %>% 
  filter(avwage < 3)
```


Nun befinden sich in pcw95 alle Daten aus dat_main, die aus dem Jahr 1995 stammen. 
Neben der Unterscheidung in den Jahren sollen zudem die Unterschiede der Ausgangslöhne herauskristallisiert werden.
Dazu werden die Löhne in Perzentile aufgeteilt.

**Aufgabe**: Erstellen Sie einen Vektor "percent95", der die logarithmierten Durchschnittslöhne in 100 Perzentile aufteilt. Nutzen Sie dafür die Funktion `quantile(dat,seq())`. Setzen Sie den fehlenden Wert in "seq()" ein, um einen Vektor der Länge 100 zu erhalten.

```{r}
#< fill_in
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, ___))
#>
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, 0.01))
```

Diese Aufteilung muss nun für jedes Jahr des Datensatzes wiederholt werden.

**Aufgabe**: Führen sie den Chunk durch *check* aus.

```{r}
#< task

pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))

pcw97 = dat_main %>%
  filter(year == 1997)%>%
  filter(avwage >= 3)
percent97 = quantile(pcw97$ln_avwage, seq(0, 1, 0.01))

pcw98 = dat_main %>%
  filter(year == 1998)%>%
  filter(avwage >= 3)
percent98 = quantile(pcw98$ln_avwage, seq(0, 1, 0.01))

pcw99 = dat_main %>%
  filter(year == 1999)%>%
  filter(avwage >= 3)
percent99 = quantile(pcw99$ln_avwage, seq(0, 1, 0.01))

pcw00 = dat_main %>%
  filter(year == 2000)%>%
  filter(avwage >= 3)
percent00 = quantile(pcw00$ln_avwage, seq(0, 1, 0.01))

pcw01 = dat_main %>%
  filter(year == 2001)%>%
  filter(avwage >= 3)
percent01 = quantile(pcw01$ln_avwage, seq(0, 1, 0.01))

pcw02 = dat_main %>%
  filter(year == 2002)%>%
  filter(avwage >= 3)
percent02 = quantile(pcw02$ln_avwage, seq(0, 1, 0.01))

#>

```


Nun können die Unterschiede in jedem einzelnen Perzentil von Jahr zu Jahr ermittelt werden. Die Differenzen sollen in einem Datensatz gespeichert werden. 

Dafür wird zunächst ein Datensatz erstellt, der sich an den Werten der Perzentile aus dem ersten Beobachtungsjahr 1995 richtet.

**Aufgabe**: Erstellen Sie einen Datensatz `diffperc` mittels der Funktion `data.frame`. Dieser soll zunächst die Werte aus `percent95` enthalten, welche durch `sort()` geordnet sind.

```{r}
#< task

#>
diffperc = data.frame(sort(percent95))
```


Der Datensatz diffperc kann jetzt um die Differenzen innerhalb der Perzentile erweitert werden.

**Aufgabe**: Führen Sie den Code mit "check" aus.

```{r}
#< task
diffperc = diffperc %>%
  mutate("percentile" = c(0:100),
         "diff96" = percent96-percent95,
         "diff97" = percent97-percent96,
         "diff98" = percent98-percent97,
         "diff99" = percent99-percent98,
         "diff00" = percent00-percent99,
         "diff01" = percent01-percent00,
         "diff02" = percent02-percent01)

#>
```


Für die Betrachtungsweise der Auswirkungen durch die Einführung des Mindestlohns sind zwei Differenzen von besonderer Bedeutung. Daher sollen die Änderung des Lohns im Jahr vor der Einführung (diff99) mit der Änderung im Jahr nach der Einführung (diff00) in einem Liniendiagramm gegenübergestellt werden.

```{r}
#< task

#Graphik
library(ggplot2)

diffperc = filter(diffperc, percentile < 76 & percentile > 0)
ggplot(diffperc)+
  geom_line(aes(x = percentile, y = diff99), colour = "blue", linetype = 2, linewidth = 0.8)+
  geom_line(aes(x = percentile, y = diff00), colour = "red", linewidth = 0.8)+
  geom_vline(xintercept = 13)+
  geom_vline(xintercept = 50)+
  xlab("Perzentile der Ausgangsdurchschnittslöhne")+
  ylab("Änderung des logarithmierten Durchschnittslohns")

#>
```

#-Mögliche Fragen zum Schaubild

-Wieso logarithmierte Werte?
-Woher kommt der Piek nach unten?




## Exercise 3 DiD -- Difference in Differences

**Möglicher Inhalt**
- Wieso braucht man DiD
- Voraussetzungen gegeben? (parallel-Trend)
- Was sagt er aus
- Vorteil ggü. anderer Methoden
- Wie werden die jeweiligen Gruppen gewählt? (136f.)
  - Treatment Group Indikatoren = FAME + LFS + WERS (136)
  - T = 1 für avwage < 12.000 im Geschäftsjahr vor NMW Einführung 
  - Durchschnitt in T = 1 = 8400 => 3,90 pro Stunde (nah bei NMW = 3,60)  
  - Plausible Treatment-Wahl? (137D.), Fig. 1
- Was gibt es für andere Schätzmethoden?
- Diagramm Variablenbeeinflussung
- Placebo-Effekt (142f.)
  - Imaginäre Einführung NMW im April 1996

**Vorgehen**
- Kernergebnisse erkennen
- Ausgangspunkt: Mindestlohn + Unternehmensgewinne
- Regression aufbauen

**Stichwörter**
- Quasi-experimenteller Rahmen NMW (133)
- Händische DiD-Schätzungsformel (133)
- Parallel-Trend: Unterschiede wären gleich geblieben, wenn es kein Treatment gegeben hätte

**Mögliche Aufgaben**
- Treatmentgruppenwahl entwickeln: 3,60 pro Stunde -> Schnitt 8400 im Jahr bei Vollzeit (Arbeitszeiten GB aufdröseln)


Die Auswirkungen des Mindestlohns auf die Unternehmensgewinne können mit Hilfe der Difference-in-Differences-Methode - kurz **DiD** - beobachtet werden.

**DiD-Methode**
Die DiD-Schätzung ist häufig geeignet, um politische Maßnahmen empirisch zu beurteilen. Gerade mit Hinblick auf Lohnentwicklungen stellte die Methode bereits in der Vergangenheit eine wichtige Grundlage. So können beispielsweise die Einflüsse von Schocks und fixer Effekte abgefedert werden und so die Auswirkungen einzelner Maßnahmen besser beurteilbar machen. (Quelle???) (Angrist, J. D., & Pischke, J. S. (2009). Mostly harmless econometrics: An empiricist's companion. Princeton university press.)

**Sind die Voraussetzungen gegeben? (Quiz)**
- Parallele Trends


**Parallele Trends**
Eine relevante Voraussetzung für das Anwenden der DiD-Methode ist die Parallel-Trends-Assumption (PTA). Diese besagt, dass ohne die Einführung eines Treatments, in unserem Fall der Mindestlohn, die Linien der Kontroll- und Treatmentgruppe weitestgehend parallel liefen. 
Annähernd kann das überprüft werden, indem man sich die Trendlinien der beiden Gruppen vor Einführung des Treatments ansieht. (Quelle???)

**Code**
```{r}
  dat = read_dta('main_fame.dta')
```

```{r}
dat_trend_treat = dat %>% 
  filter(ctreat1 == 1) %>%
  group_by(year)%>%
  summarise("Treatment"=mean(ln_avwage, na.rm = TRUE))
```
```{r}
dat_trend_control = dat %>%
  filter(ctreat1 == 0) %>%
  group_by(year) %>%
  summarise("Control"=mean(ln_avwage, na.rm = TRUE))
```
```{r}
dat_trend = left_join(dat_trend_treat, dat_trend_control)
```
```{r}
ggplot(dat_trend)+
   geom_line(aes(x = year, y = Treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = Control), colour = "red", linetype = 1, linewidth = 0.8)+
   geom_vline(xintercept = 1999)
```
#< quiz "3"
question: Erkennen Sie einen parallelen Trend?
sc:
    - Ja
    - Nein*

success: Während die Löhne in der Kontrollgruppe konstant zu steigen scheinen, läuft der Trend der Treatmentgruppe nicht konstant und auf einem gleichbleibenden Niveau.
failure: Auch wenn es hier meist um eine subjektive Einschätzung geht, sollten Sie sich die unterschiedlichen Steigungen der Trends ansehen.
#>

In unserer Betrachtungsweise ist kein eindeutig paralleler Trend zu erkennen. Aufgrund des kurzen Betrachtungszeitraums des Trends sollte diese Einschätzung aber auch mit Vorsicht genossen werden: Es wird sich auf Trends bezogen, die sich auf sechs Datenpunkte (1994-1999) stützen. Die Betrachtung eines größeren Zeitraums könnte hier eine genauere Betrachtung zulassen.
Bezüglich der PTA gibt es seitens der Autoren keine weiterführenden Analysen, eine Erwähnung wird innerhalb des Artikels vergeblich gesucht.




## Exercise 3.1 -- Wahl der Gruppen
Bei der Difference in Difference (DiD) Methode werden die Daten anhand von zwei Kriterien unterteilt.
Zum einen wird entschieden, ob es sich um eine Pre-Treatment oder eine Post-Treatment Gruppe handelt.

#< quiz "4"
question: Ab welchem Zeitpunkt werden Daten der Post-Treatment Gruppe zugewiesen?
sc:
    - 1999
    - 2000*

success: Richtige Antwort. Die Einführung war zwar im Jahr 1999, die Daten jedes Jahres beziehen sich allerdings auf das vergangene Geschäftsjahr (April bis März).
failure: Das ist nicht korrekt. 
#>

Für eine DiD-Schätzung muss weiter eine Kontroll- und eine Treatmentgruppe definiert werden. In der Treatmentgruppe werden jene Unternehmen zusammengefasst, bei denen der Durchschnittslohn (avwage) im Jahr unter 12000 Pfund lag.
Die Kontrollgruppe umfasst Unternehmensdaten mit einem Durchschnittslohn zwischen 12000 und 20000 Pfund.

Im Mittelpunkt der Mindestlohneinführung steht der Wert von 3,60 Pfund pro Stunde. Da unser Datensatz allerdings keine Daten zu jedem Arbeitnehmer enthält, müssen wir uns an die Wahl der Treatmentgruppe nähern.

```{r}
#< task
  dat = read_dta('main_fame.dta')
#>

```
Die Variable, die den Lohn innerhalb eines Unternehmens am Besten widerspiegelt ist hierbei "avwage". Hierüber wird sich auch im Artikel genähert. Dabei werden alle Unternehmen mit einem avwage =< 12000 in die Treatmentgruppe einsortiert. 
Um zu verstehen, warum sich für diesen Wert als Obergrenze entschieden wird ist es hilfreich, den Wert in Zusammenhang mit dem Stundenlohn zu bringen.
Dazu soll zunächst der durchschnittliche Lohn aller Unternehmen aus der Treatmentgruppe in der Pre-Policy Periode ermittelt werden.

**Aufgabe**: Setzen Sie die passenden Werte in die Lücken ein. (Hinweis: Avwage wird im Datensatz in 1000 Pfund angegeben)
```{r}
#< fill_in
mean_treat = dat %>%
  filter(avwage <= ___) %>%
  filter(year == ___) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
#>
mean_treat = dat %>%
  filter(avwage <= 12) %>%
  filter(year == 1999) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
```
```{r}
#< task
mean_treat / 2000
#>
```
Mit dieser Näherung kommt man in die Nähe des Mindestlohns. Dennoch ist dies auch mit Vorsicht zu genießen. Da die Wahl der Treatmentgruppe auf Durchschnittslöhne eines gesamten Unternehmens beruht, können große Ausreißer das Ergebnis beeinflussen. Es wird eine Vollzeitbeschäftigung vorausgesetzt, wobei der Anteil an Teilzeitarbeit im betrachteten Beispiel bei über 16% lag: (Quelle???)

```{r}
mean(dat$ptwk, na.rm = TRUE)
```


Die Wahl der Treatmentgruppe kann allerdings weiter durch die Verwendung des WERS-Datensatzes untermauert werden. 
So kann die Lohnverteilung innerhalb eines Unternehmens mit dem Durchschnittslohn in Zusammenhang gebracht werden. Die Autoren kommen zu dem Schluss, dass 87% aller vom Mindestlohn profitierenden Arbeiter in Unternehmen arbeiten, in denen der jährliche Durchschnittslohn bei 12000 Pfund oder niedriger liegt. 
Wir wollen überprüfen, inwiwefern der Anteil an Lohnzahlungen unter 3,60 mit dem Durchschnittslohn zusammmenhängt.

**Figure 1**
```{r}
#< task
dat_seq = read_dta('seq98.dta')
#>
```

## Exercise 3.2 -- händische DiD-Berechnung

Mit einem Blick auf den Datensatz erkennt man, dass hierfür bereits Dummy-Variablen ertellt worden sind.

**Aufgabe**: Laden Sie erneut den bereits bekannten Datensatz, indem Sie lediglich "check" drücken.
```{r}
#< task
dat = read_dta('main_fame.dta')
#>

```

```{r}
#< task
dat_table_DiD = dat %>%
  group_by(ctreat1, NMW)%>%
  filter(pp == 1) %>%
  summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))
#>
```

**Wieso wird der Dummy "pp" angewandt?**
In diesem Code fällt auf, dass der Datensatz um mehrere Einträge mit Hilfe des Dummys pp verkleinert wird.
Diese Vorauswahl wird von Seiten der Autoren getroffen (S. 135, (Verw. 14)): Dabei wird sich auf Unternehmen bezogen, deren Geschäftsjahr im Zeitraum April bis März läuft. Untersuchungen wurden ebenfalls für den gesamten Datensatz durchgeführt, die grundlegenden Ergebnisse ähneln sich dabei. Aufgrund diverser Regelungen in der britischen Berichterstattung sind kleinere Unternehmen von der Angabe bestimmter Daten befreit. Daher gibt es ein subsample. 

Werfen wir einen Blick auf die aussortierten Daten und überprüfen anhand der Beschäftigungszahlen, ob es Aufffälligkeiten gibt:

```{r}
dat_no_pp = dat %>%
  filter(pp == 0)

dat_pp = dat %>%
  filter(pp == 1)

boxplot(log(dat_no_pp$emp),log(dat_pp$emp))
boxplot(log(dat_no_pp$net_pcm),log(dat_pp$net_pcm))
boxplot(log(dat_no_pp$avwage),log(dat_pp$avwage))

```
Im Gesamten ist zu erkennen, dass die Daten, die sich nicht in der Auswahl befinden, breiter gestreut sind.
Wir erkennen einen Unterschied in den Beschäftigungszahlen der beiden Gruppen.
In Großbritannien sind **kleinere Unternehmen** von der Veröffentlichung bestimmter Daten befreit. Um eine vollumfängliche Analyse zu gewährleisten entscheiden sich die Autoren daher ein Unterbeispiel zu erstellen, in denen Daten vollumfänglich erfasst werden (S. 135).
Das schränkt allerdings auch die Bewertung ein, lenkt den Blick weg von kleineren Unternehmen und muss bei der Betrachtung der Ergebnisse bedacht werden.
Wie die Autoren die Auswahl des Unterbeispiels treffen wird nicht vollumfänglich bekannt.



Nachdem die relevanten Daten des DiD zusammengefasst in der Tabelle "dat_table_DiD" vorhanden sind, können die Differenzen nun händisch berechnet werden.

Die Formel hierfür lautet 
***(y.post.treat - y.post.control) - (y.pre.treat - y.pre.control)***

**Aufgabe**: Werfen Sie zunächst einen Blick auf die erzeugte Tabelle und überlegen Sie, welcher Gruppe die jeweiligen Werte angehören. Lassen Sie sich dafür die oben erstellte Tabelle anzeigen und überprüfen Sie Ihre Eingabe mittels "check".
```{r}
#< task

#>
dat_table_DiD
```

#< quiz "5"
question: Welche Spalte beschreibt die Kontroll- bzw. Treatmentgruppe?
sc:
    - ctreat1*
    - NMW

success: Richtige Antwort. Ist ctreat1 = 1, so handelt es sich um die Treatmentgruppe, andernfalls ist es die Kontrollgruppe.
failure: Falsch. NMW bezieht sich auf den Zeitpunkt. 
#>

#< quiz "6"
question: Von welcher Gruppe ist die Rede, wenn NMW = 1 ?
sc:
    - Pre-Treatment
    - Post-Treatment*
    
success: Korrekt. In diesem Fall befinden wir uns im Jahr 2000 oder später.
failure: Das ist nicht richtig. In diesem Fall wäre NMW = 0.

#>

**Aufgabe**: Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
```{r}
#< fill_in
# Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
y1.post.treat = dat_table_DiD$mean_ln_avwage[___]
y1.post.control = dat_table_DiD$mean_ln_avwage[___]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[___]
y1.pre.control = dat_table_DiD$mean_ln_avwage[___]

#>
y1.post.treat = dat_table_DiD$mean_ln_avwage[4]
y1.post.control = dat_table_DiD$mean_ln_avwage[2]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[3]
y1.pre.control = dat_table_DiD$mean_ln_avwage[1]

```

#< quiz "7"
question: Wieso werden für den Durchschnittslohn logarithmierte Werte verwendet?
sc:
    - a*
    - b
    - c

success: Korrekt. 
failure: Das ist nicht die richtige Lösung.
#>

#< quiz "8"
question: Wieso gibt es in der Kontrollgruppe eine Obergrenze (20000 = Median)?
sc:
    - a
    - b*
    - c

success: Korrekt. 
failure: Das ist nicht die richtige Lösung.
#>
Neben des logarithmierten Durchschnittslohns wird auch der DiD-Schätzer der Nettorendite eines Unternehmens je Geschäftsjahr (net_pcm) berechnet.
Das geschieht analog zur obigen Schätzung.

**Aufgabe**: Werfen Sie erneut einen Blick auf die erstellte Tabelle und geben Sie nun die Zeilen ein, in denen der passende Wert steht.
```{r}
#< fill_in
y2.post.treat = dat_table_DiD$mean_net_pcm[___]
y2.post.control = dat_table_DiD$mean_net_pcm[___]
y2.pre.treat = dat_table_DiD$mean_net_pcm[___]
y2.pre.control = dat_table_DiD$mean_net_pcm[___]
#>
y2.post.treat = dat_table_DiD$mean_net_pcm[4]
y2.post.control = dat_table_DiD$mean_net_pcm[2]
y2.pre.treat = dat_table_DiD$mean_net_pcm[3]
y2.pre.control = dat_table_DiD$mean_net_pcm[1]
```

Die Werte sind nun gespeichert und die DiDs können berechnet werden.

**Aufgabe**: Fügen Sie dem Code das Anzeigen der Ergebnisse hinzu und führen Sie den Code mittels "Check" aus.
```{r}
#< fill_in
DiD_ln_avwage = (y1.post.treat - y1.post.control) - (y1.pre.treat - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.post.control) - (y2.pre.treat - y2.pre.control)
  
#Ergebnisse anzeigen
#>
DiD_ln_avwage = (y1.post.treat - y1.post.control) - (y1.pre.treat - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.post.control) - (y2.pre.treat - y2.pre.control)
  
#Ergebnisse anzeigen
DiD_ln_avwage
DiD_net_pcm
```

Durch die Einführung des Mindestlohns können wir sagen, dass dadurch in den beobachteten Unternehmen der Durchschnittslohn gestiegen ist. Zugleich ist zu erkennen, dass in jenen Unternehmen der Nettogewinn zurück gegangen ist.

Um diese Veränderung genauer bewerten zu können und tiefergehende Analysen zu ermöglichen, machen wir uns die Methode der Regression zu eigen.


## Exercise 3.3 -- DiD-Schätzung mittels Regression

**Theorie**
- Cluster-Robuste Standardfehler
  - Geclustert nach Regno (unternehmen)
- Genestete Daten

**DAG**

Zu Beginn widmen wir uns der Veränderung im Durchschnittslohn durch die Einführung des Mindestlohns.
Um uns einen ersten Überblick über die Zusammenhänge der Variablen in unserer DiD-Schätzung zu verschaffen, sind die Directed Acyclic Graphs (DAGs) von Vorteil.
Führen Sie hierfür den Code mittels check aus und sehen Sie sich den Graphen an.
(https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html)
(https://r-causal.github.io/ggdag/)

```{r}
dag <- dagify(
  ln_avwage ~ ctreat1 + treat1_NMW + NMW, 
  treat1_NMW ~ ctreat1 + NMW,
  labels = c(ctreat1 = "ctreat1", treat1_NMW = "treat1_NMW", NMW = "NMW", ln_avwage = "ln_avwage")
)

ggdag(dag, node_size = 18, text = FALSE, edge_type = "link", use_labels = "label")+
  theme_dag_blank()
```
Hier sieht man, warum der Effekt von treat1_NMW in Regression III so stark von dem in Regression IV abweicht. , nicht nur eine Regression mit der Interaktionsvariablen durchzuführen, sondern auch mit den beiden einzelnen Dummy-Variablen.

**Aufgabe**: Lesen Sie einen Auszug des bekannten Datensatzes dat_main ein, indem Sie den Code mit "check" ausführen.
```{r}
#< task
dat_raw = read_dta('main_fame.dta')
dat = filter(dat_raw, pp == 1) 
#>
```
Zu Beginn unserer Analyse wollen wir mehrere Regressionen mit den oben dargestellten Variablen laufen lassen. 
Dazu sollen die einzelnen Variablen die "ln_avwage" beeinflussen beobachtet werden.

Führen Sie die Regression aus und stellen Sie das Ergebnis mittels der stargazer-Funktion dar.
```{r}
#< fill_in
regi = lm(ln_avwage ~ treat1_NMW, data = dat)

stargazer(___, type = "text")
#>
regi = lm(ln_avwage ~ treat1_NMW, data = dat)

stargazer(regi, type = "text")
```
#< quiz "3.3.1"
question: Wieso ist der Einfluss der Treatmentvariablen im Gegensatz zur händischen Berechnung negativ?
sc:
    - Die Regression ist genauer als die händische Berechnung.
    - Die Regression ist fehlerhaft.*

success: Korrekt. Mit Blick auf den DAG können Sie erkennen, dass der Effekt von treat1_NMW in der Regression verschätzt wird.
failure: Das ist in diesem Fall nicht der Grund für die Unterschiede. Sehen Sie sich den DAG an.
#>


Wir müssen in unserer Regression also auch die sowohl die Interaktionsvariable als auch die abhängige Variable beeinflussenden Dummys berücksichtigen.


$ln(avwage) = \beta_0 + \beta_1 ctreat + \beta_2 treat1*NMW + \beta_3 NMW + \epsilon$

Berechnen Sie auf Basis dieser Formel die Einflüsse der Variablen und das damit zusammenhängende DiD-Ergebnis. Stellen Sie das Ergebnis wieder in "stargazer" dar.

```{r}
#< fill_in
reg1 = lm(ln_avwage ~ ___ + ___ + ___, data = dat)
stargazer(reg1, type = "text")
#>

reg1 = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW, data = dat)
stargazer(reg1, type = "text")
```
Der Wert der Interaktionsvariablen hat sich im Vergleich zur unvollständigen Regression stark verändert und erinnert an die händische Berechnung.

Um diese starke Veränderung besser zu verstehen können wir die gemeinsame Betrachtung der erklärenden Variablen mit der einzelnen Betrachtung vergleichen.


```{r}
regii = lm(ln_avwage ~ ctreat1, data = dat)

regiii = lm(ln_avwage ~ NMW, data = dat)

stargazer(regi, regii, regiii, reg1, type = "text")

```
Im Gegensatz zur händischen Berechnung bekommen wir durch die Regression die Signifikanz unserer Schätzung beurteilen.

#< quiz "3.3.1"
question: Wie beurteilen Sie die Signifikanz unseres DiD-Schätzers in der dargestellten Regression?
sc:
    - hoch*
    - niedrig

success: Korrekt, *** bestätigt ein hohes Signifikanzniveau. 
failure: Das ist nicht richtig. Achten Sie auf die p-Werte und die dazugehörige Veranschaulichung durch Sterne.
#>


**Genestete Daten**
(Bryk, Raudenbush: Hierarchical Linear Models: Applications and Data Analysis Methods)
Die Werte der Variablen sind im obigen Fall also hoch signifikant gekennzeichnet. 
Allerdings können die p-Werte fehlerhaft sein, da es sich bei den Daten teilweise um genestete Daten handelt. 
Genestete Daten liegen vor, wenn mehrere Daten zu einer übergeordneten Einheit zählen.
In unserem Fall haben wir Daten zum logarithmierten Durchschnittslohn (ln_avwage) über mehrere Jahre. Diese haben ein Unternehmen (regno) als übergeordnete Einheit.
Um Fehler bezüglich genesteter Daten zu verhindern, fügen wir Clusterrobuste Standardfehler ein.

#< quiz "3.3.1"
question: Nach welcher Variable soll geclustert werden?
sc:
    - ln_avwage
    - regno*

success: Korrekt, hierbei handelt es sich um die übergeordnete Einheit, nach der geclustert werden muss.   
failure: Das ist so nicht richtig. Bei genesteten Daten muss nach der übergeordneten Einheit geclustert werden.
#>

Nun fügen wir die Clusterrobusten Standardfehler ein und schauen, was sich dadurch verändert.

Führen Sie hierzu die Regression durch und vergleichen die Regression ohne Clustering (regiv) mit der Regression mit Clustering.
```{r}
#< fill_in
reg2 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW|0|0|regno, data=dat)
stargazer(___, ___, type ="text")
#>
reg2 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW|0|0|regno, data=dat)
stargazer(reg1, reg2, type ="text")
```

```{r}
#reg1 = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW, data = dat)
#cluster = vcovCL(reg1, cluster = ~regno)

#stargazer(reg1, type = "text",
#          se = list(sqrt(diag(cluster))))
#Quelle?
```


An den Werten der Variablen ist keine Veränderung zu erkennen. Allerdings haben sich die Werte der Standardfehler verändert.
Während man für ctreat1 und die Interaktionsvariable eine Erhöhung des p-Wertes vorfindet, ist eine Verringerung bei der Variablen NMW zu verzeichnen.

Um diese Veränderungen zu verstehen sehen wir uns an, was es generell mit clusterrobusten Standardfehlern auf sich hat:
(Angrist, 231ff) / 
(Abadie, A., Athey, S., Imbens, G. W., & Wooldridge, J. M. (2023). When should you adjust standard errors for clustering?. The Quarterly Journal of Economics, 138(1), 1-35.)
Variiert der Regressor nur innerhalb einer Clustergruppe, so kann der Standardfehler steigen (231)

---------------

**Ergebnisanalyse**

Die Variablen beschreiben die Veränderungen im Vergleich zum Pre-Policy Jahr, welche mit Constant beschrieben wird.
- Wie wirken die unterschiedlichen Variablen?
- Werte zuordnen
#< quiz "3.3.2"
question: Wenn Sie an die Werte aus der händischen Berechnung zurückdenken, sollte Ihnen der Wert einer Variablen bekannt vorkommen. Von welcher Variablen ist die Rede?
sc:
    - ctreat1
    - treat1_NMW*
    - NMW

success: Richtige Antwort, auf dieser Variablen liegt das Hauptaugenmerk.  
failure: Das ist leider falsch. 
#>

Bei treat1_NMW handelt es sich um den Interaktionsterm der beiden Dummyvariablen. Dieser beschreibt die einfache DiD-Schätzung unter der Berücksichtigung Cluster-Robuster Standardfehler je Unternehmen. Der Wert ist hoch signifikant.

#< quiz "3.3.3"
question: In welcher Einheit wird der DiD-Wert beschrieben?
sc:
    - Pfund
    - Prozent
    - Prozentpunkte*

success: Richtige Antwort. Der Anstieg des Gehalts in der Treatmentgruppe ist um ca. 11 Prozentpunkte höher als in der Kontrollgruppe.
failure: Das ist leider falsch. Es werden zwei log-Variablen miteinander verglichen.
#>


----------------

     | 

**NET_PCM**

Zur Betrachtung der Veränderung der Unternehmensgewinne gehen wir nach demselben Schema vor.

```{r}
reg2 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW | 0 | 0 | regno, data = dat)

stargazer(reg2, type = "text")
```
-------------

Sehen wir uns weiter an ob es zu Veränderungen kommt, wenn wir auf bestimmte Effekte der Unternehmenswelt kontrollieren.
Dafür können wir uns die Funktion der Faktorvariablen zunutze machen.

**Faktorvariablen**



**Table 2, Panel A**
```{r}
reg3 = felm(ln_avwage ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg3, type = "text")
```

```{r}
reg4 = felm(net_pcm ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg4, type = "text")
```

**Table 2, Panel B**

**Kontinuierliche Messung**

Bisher haben wir uns auf die Unterscheidung zwischen Treatment und keinem Treeatment konzentriert. Dabei wurde deutlich, dass sowohl einen signifikante positive Änderung des Lohns, als auch eine negative signifikante Veränderung der Gewinnmarge vorhanden sind. Da diese sich diese Unterscheidung allerdings auf die vorangegangene eigene Definition der beiden Gruppen stützt, kann die Betrachtung durch eine weitere Methode hilfreich sein. Zudem wollen wir einen genaueren Effekt je nach Einkommen erhalten.

Im Vergleich zur diskreten Messung wird bei der kontinuierlichen Messung kein Dummy für die Treatments verwendet, sondern ein bestimmter Wert.


Um diese kontinuierliche Analyse zu ermöglichen, wird anstatt der Treatmentvariablen *ctreat1* eine andere Variable gewählt.
In unserem Fall ist das *c_avwage99* und beschreibt den logarithmierten Durchschnittslohn zum Jahr 1999 nach Unternehmen gruppiert.

**Diskrete Daten vs. Kontinuierliche Daten**

| Merkmal             |     Diskrete Daten      |     Kontinuierliche Daten     |
|---------------------|-----------------------  |-------------------------------|
| Generell            |                         |                               |
| Vorteil             |                         |                               |   
| DiD-Schätzung       | Verwendung von Dummys   | Verwendung konkreter Werte    |
| Treatmentvariable   | ctreat                  | c_avwage99                    |
| Werte               | 0 oder 1                | logarithmierter Durchschnittslohn im Jahr 1999 |


```{r}
reg5 = felm(ln_avwage ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg6 = felm(net_pcm ~ c_avwage99 + avwage99_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg5, reg6, type = "text")
```
WAS HAT SICH GEÄNDERT?
WIE KANN DAS ERGEBNIS INTERPRETIERT WERDEN?
WIESO BRAUCHT MAN DAS?
  - Vergleich zur imaginären Einführung



## Exercise 3.4 -- Imaginäre Mindestlohneinführung

- Sind die Veränderungen auf das Treatment zurückzuführen?
  - Vergleich zu Parallel-Trend
- Imaginäre Einführung am 1. April 1996
- Vergleich Datensätze: ff=0 vs. ff=1
- Table 3
- Figure 3

Um zu überprüfen, ob die Mindestlohneinführung der Grund für die Ergebnisse der DiD-Schätzung ist, kann ein **Placebo Experiment** eingeführt werden.(142ff.)
Hierfür wird die Mindestlohneinführung imaginär um drei Jahre vorverlegt, auf den 01. April 1996.
Dabei können wir auf Vorarbeit im Datensatz zurückgreifen. Ähnlich wie bei der vorangegangenen Schätzung zur realen Mindestlohneinführung wird der Datensatz anhand eines Dummys gefiltert.

Lesen Sie den Datensatz ein und teilen ihn nach den Dummywerten von ff auf.
```{r}
dat = read_dta('main_fame.dta')
dat_ff1 = filter(dat, ff == 1)
dat_ff0 = filter(dat, ff == 0)
```
Um zu verstehen, warum manche Einträge von Firmen ausgelassen werden, hilft ein Vergleich der oben erstellten Variablen.

Gruppieren Sie dazu die Datensätze nach den Jahren und geben sie die Anzahl der Einträge pro Jahr aus. Hinweis: Die Funktion length(*Variable*) gibt die Anzahl der Einträge wieder.
```{r}
dat_ff1 %>%
  group_by(year)%>%
  summarise(length(year))

dat_ff0 %>%
  group_by(year)%>%
  summarise(length(year))
```
Es fällt auf, dass sich im untersuchten Datensatz nur Einträge befinden, die sich auf den Zeitraum **vor** der reellen Mindestlohneinführung beziehen.

Allerdings werden auch Daten aus den Jahren 1994 - 1999 herausgefiltert. Sehen wir uns an, wie das mit dem von den Autoren gefundene Unterbeispiel (pp) zusammenhängt.

```{r}
dat_ff0 %>%
  group_by(pp)%>%
  summarise(length(pp))

dat_ff1 %>%
  group_by(pp)%>%
  summarise(length(pp))
```
Der Anteil an pp==0 ist im unberücksichtigten Datensatz deutlich höher als im am Ende betrachteten Datensatz dat_ff1. Allerdings werden nun auch Unternehmen berücksichtigt, die bei den Analysen zur reellen Mindestlohneinführung nicht berücksichtigt wurden.
Der Grund dafür könnte sein, dass sich die Zahlen in den Unternehmen verändert haben.???

```{r}
dat_ff0 = filter(dat_ff0, year==1996)
dat_ff1 = filter(dat_ff1, year==1996)
boxplot(dat_ff0$ln_avwage,dat_ff1$ln_avwage)
mean(dat_ff0$avwage, na.rm = TRUE)
mean(dat_ff1$avwage)
max(dat_ff1$avwage)
```

Wie in den vorherigen Analysen sind nicht alle Ursachen für die Aussortierung einiger Daten erkennbar. 
Weiter werden wir die Analysen mit dem von den Autoren gegebenen Unterbeispiel durchführen.

Dafür können wir dieselbe Regression wie im Kapitel 3.3 verwenden mit dem Unterschied, dass der Datensatz nun nach ff gefiltert wird.
```{r}
dat = filter(dat, ff == 1)
```
**Diskret**
```{r}
reg7 = felm(ln_avwage ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg8 = felm(net_pcm ~ ptreat + ptreat_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg7, reg8, type = "text")
```


**Kontinuierlich**
```{r}
reg9 = felm(ln_avwage ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

reg10 = felm(net_pcm ~ c_avwage96 + avwage96_placebo + placebo + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dat)

stargazer(reg9, reg10, type = "text")
```
----------------

**Vergleich Fig 3**
- Treatmenteffekt net_pcm

Intervalle erstellen
```{r}
pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))
```
```{r}
dat_fig3 = dat %>%
  mutate("threshold" = round(exp(c_avwage99)*1000,-2)) %>%
  filter(threshold <= 16000) %>%
  filter(threshold >= 10000) %>%
  
  group_by(threshold) %>%
  summarise(length(threshold), mean(avwage99_NMW))
```

Regression in 100er Schritten durchführen und wiederholen. Die grenze wird nach oben verschioben und es werden immer mehr Einträge berücksichtigt.
Ergebnisse je 100 in Liste speichern

```{r}
#Neuen Datensatz erstellen
dati = read_dta('main_fame.dta')
dati = filter(dati, pp==1)

```

```{r}

# Schleife initiieren
#i = 10000
#while(i<=16000){
#dati = mutate(dati, "treat1" = NULL)
#dati$ctreat1 = NULL
#dati$avwage = dati$avwage * 1000

#dati$treat1 = ifelse(dati$year == 1999 | dati$avwage <= i, 1, 0)
#dati$ctreat1 = ifelse(dati$treat1 == 1, 1, 0)
#dati = mutate(dati, treat1)


#dati$paste("treat1", i, "_NMW") = dati$ctreat1*dati$NMW
  
# Regression innerhalb der Schleife
#reg = felm(net_pcm ~ ctreat1 + paste("treat1", i, "_NMW") + grad2 + unionmem + ptwk + female + 
#                factor(sic2) + factor(year) + factor(gorwk)| 0 | 0 | regno, data = dati)

#i + 100
#}
```



```{r}
library(ggplot2)
ggplot(dat_fig3, aes(x = threshold))+
  geom_line(aes(y = avwage99_NMW))

```




## Exercise 4 -- Einordnung des Artikels (weiterführende Überlegungen)

- EU-weiter Mindestlohn (Möglichkeiten, Chancen, Probleme)
- Unterschiede zu 1999 (Andere Rahmenbedingungen?, Brexit?)
- unberücksichtigte Variablen
- Auswirkung auf Beschäftigung
- weitere Artikel (andere Auswirkungen untersucht)
- Strukturen in Unternehmen

## Exercise Anregungen

- "Aber was sind die Produktionskosten - des Arbeiters, d.h. die Kosten, um den Arbeiter selbst zu produzieren?" / "Wert der Arbeit" (Kapital, 497)


## Exercise Probleme beim Code

- i. Dummyvariablen in Stata
- Intervallregression


## Exercise Aufgabentypen 

a) We often want to compute some summary statistic of a vector. For example:

```{r}
#< task
x = 10:23
# Computing the sum of x
sum(x)
#>
```

Now compute the mean of x.
```{r optional=TRUE}
# Note the chunk option optional = TRUE means
# the user can continue with the next exercise
# without having solved this one

mean(x)
#< hint
cat("There already exist R functions for many things. To find them use Google, e.g. search for 'R compute mean'.")
#>
```


#< info "useful functions for numeric vectors"
Here are examples for useful R functions
```{r}
max(c(1,5,2)) # returns maximum
min(c(1,5,2)) # returns minimum

sum(c(1,5,2,NA), na.rm=TRUE) # returns sum of all numbers, ignore NA
cumsum(c(1,5,2)) # returns cummulated sum
diff(c(1,5,2)) # returns the vector of differences
```
#>


#< award "mean means mean"
Well, in some occasions one can just guess the name of an R function. The function to compute the mean of a vector, or matrix is called 'mean'. Usually, it is much quicker to goggle than to guess function names, however.
#>

b) Let `y` be a vector that contains the squared elements of `x`, i.e. for each element $i$ we want $$y_i = x_i^2.$$ Then show `y`.
```{r}
# We should not set this chunk optional
# since we need y in the next chunk
y = x^2
y
```

c) Now use the function `qplot` from the package `ggplot2` to create a scatter plot of `x` against `y`. You can google `r qplot` to get the help for the function `qplot`.

```{r optional=TRUE, dev="svg", fig.width=4}
#< task
library(ggplot2) # load ggplot2 package

# Enter your call to qplot here...
#>
qplot(x,y)
#< test_arg
allow.extra.arg = TRUE 
#>
# The block above allows the user to add extra arguments to the call to qplot, i.e. qplot(x,y,xlab="The variable x"), would also pass the test.
```


#< quiz "prime"
question: What is the 'oddest' prime?
sc:
    - 2*
    - 3
    - 5
    - 7
success: Well, of course the answer is debatable...
failure: Try again.
#>

Note: A quiz as specified below only works in the shiny environment. If you want to design a quiz in an RMarkdown based RTutor problem set, you should use a chunk. E.g. as follows:

Which of the following numbers is the oddest prime? 2,3,5 or 7? Enter you solution in the code below and press "check".

```{r}
2
```
#< award "The oddest prime"
Wouldn't you agree that the only even prime is the odd man out?
#>

## Exercise Submitting your solution

To submit your solution please proceed as follows:

1. Scroll to the top and click on the icon with the bars <i class="fa fa-tasks fa-fw"></i> to see how many points you got so far. If you want to have more points you can try to solve the missing tasks.

2. If you want to submit click on the download button <i class="fa  fa-download fa-fw"></i> at the very right.

3. In the opened tab click the button "Download Submission File". Your browser should then download a file with the extension `.sub`.

4. Upload that downloaded file to your course management system like Moodle, as specified by your instructor.




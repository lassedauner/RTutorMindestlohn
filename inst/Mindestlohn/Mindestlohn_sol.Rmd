## Mindestlohn und Firmenprofitabilität: Eine interaktive Analyse

- Einführung .


#< ignore
```{r "setup"}
library(RTutor)
# Adapt working directory
setwd("C:/Users/lasse/Documents/GitHub/RTutorMindestlohn/inst/Mindestlohn")
ps.name = "Mindestlohn"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all packages you load in the problem set
libs = c("ggplot2","haven","stargazer","sandwich") 
create.ps(sol.file=sol.file, ps.name=ps.name,libs=libs, rps.has.sol=TRUE, addons="quiz")
# Show the problem set in the webbrowser
show.ps(ps.name,sample.solution=FALSE,auto.save.code = TRUE)
```
#>

## Exercise Inhaltsübersicht

1. Einführung in den Mindestlohn

2. Datenüberblick

3. Difference in Differences

4. Einordnung des Artikels

**Ideen**
Diagramm Variablenbeeinflussung


## Exercise 1 -- Einführung in den Mindestlohn

- Relevanz der Forschungsfrage
- Hintergrund der Mindestlohneinführung
- sic
- Vergleich zu anderen Staaten
- Wie werden Unternhemensgewinne definiert?
- Theoretisch mathematischer Hintergrund / Ausgangspunkt
  - Messung Unternehmensgewinne
  - Messung Mindestlohn

**Hintergrund der Einführung**
Quellen: FES 09/2007
Wie in Deutschland, wurden und werden Löhne teilweise durch Tarifverhandlungen festgelegt. Die Notwendigkeit der Einführung eines nationalen Mindestlohns wurde in Großbritannien durch den sinkenden Einfluss von Gewerkschaften gesehen. Haben im Jahr 1970 noch 80% der Arbeitnehmer von Tarifverträgen profitiert, sank dieser Anteil bis 2000 um 50 Prozentpunkte.
Mit einem Machtwechsel im britischen Unterhaus, hin zur sozialdemokratischen Labour-Partei, kommt es zur Veränderung in der Arbeitspolitik. Zum 1. April 1999 wird der nationale Mindestlohn eingeführt.
#< quiz "1.1"
question: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien zur Einführung 1999 (in Pfund)?
sc:
    - 3.6*
    - 5.7 
    - 7.8 

success: Korrekt. Der Artikel befasst sich mit der Einführung des Mindestlohns in Höhe von 3.60 Pfund.
failure: Diese Schätzung ist zu hoch.
#>


Weiter gilt zu erwähnen, dass der nationale Mindestlohn (NMW) nicht die erste Art des Mindestlohns in Großbritannien war. Von 1909 bis zum Jahr 1993 an wurden gesetzliche Mindestlöhne durch *Wage Councils* innerhalb von Branchen bestimmt. 
Das Novum des NMW liegt in der Reichweite über alle Branchen hinweg. Ähnlich wie die *Wage Councils*, gibt die unabhängige Niedriglohnkommission (LPC) eine Empfehlung zur Mindestlohnhöhe. Von 1999 an wird die Lohnhöhe fortlaufend von der Niedriglohnkomission angepasst.

#< quiz "1.2"
question: Auf welche Höhe schätzen Sie den gesetzlichen Mindestlohn in Großbritannien im Jahr 2024 (in Pfund)?
sc:
    - 9.11
    - 11.22*
    - 14.44
    

success: Korrekt. Für Personen über 21 gilt dieser Mindestlohn von April 2024 an.
failure: Diese Schätzung ist falsch.
#>
https://www.gov.uk/national-minimum-wage-rates


#< quiz "2"
question: Wie werden Lohnerhöhungen hauptsächlich gedeckt?
sc:
    - Verkleinerung der Gewinnmarge*
    - Weitergabe an Verbraucher
    - Effizienzsteigerung

success: Auf dieser Vermutung beruht der wissenschaftliche Artikel.
failure: Eine mögliche Antwort
#>

## Exercise 2 -- Datenüberblick

- Herkunft der Daten
- Ausgewogenheit der Daten
- Datensatz WERS
- Datensatz main (FAME (Financial Analysis Made Easy(135)))
  - Gesetzliche Verpflichtung
  - Auch Analyse kleinerer Unternehmen möglich (135)
  - Betrachtung von Firmen mit Geschäftsjahr April-März (Filter-Sample) (135)
- Labor Force Survey (136f.)
  - Arbeitsumfeld
  
- Relevante Variablen

**Aufgabe**: Lesen Sie den Datensatz 'main_fame.dta' mit der Funktion 'read_dta' ein und speichern Sie den Datensatz unter 'dat_main'. Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
#Datensatz einlesen
#>
dat_main = read_dta('main_fame.dta')
```


## Exercise 2.1 -- Schaubild / Wahl der Gruppen

Es soll überprüft werden, wie sich die Einführung des Mindestlohns auf die unterschiedlichen Einkommen ausgewirkt hat. 
Um die Veränderung des Lohns zum Vorjahr zu messen, muss der Datensatz zunächst für jedes einzelne Jahr aufgeteilt werden.

Zu Beginn wird erneut der Datensatz aus Aufgabe 2 eingelesen.

**Aufgabe**: Führen Sie den Code aus, indem Sie "check" drücken.
```{r}
#< task
dat_main = read_dta('main_fame.dta')
#>

```

Um die Veränderung der Löhne von Geschäftsjahr zu Geschäftsjahr herauszufinden, muss der Datensatz nach Jahren aufgeteilt werden. Das gelingt, indem für jedes Jahr ein eigener Datensatz erstellt wird. Dafür muss der bereits eingelesene Datensatz dat_main zunächst gefiltert werden.

**Aufgabe**: Wählen Sie die passende Variable für das leere Feld und überprüfen Sie Ihre Eingabe durch "check".
```{r}
#< fill_in
pcw95 = dat_main %>%
  filter(___ == 1995) %>%
  filter(avwage >= 3)
#>
#
pcw95 = dat_main %>%
  filter(year == 1995)%>%
  filter(avwage >= 3)
```

-#Wieso werden nur Werte für avwage >= 3 gewählt? Verfälschung der Ergebnisse? Was für Unternehmen sind betroffen(sic überprüfen)?

```{r}
dat_probe = dat_main %>% 
  filter(avwage < 3)
```


Nun befinden sich in pcw95 alle Daten aus dat_main, die aus dem Jahr 1995 stammen. 
Neben der Unterscheidung in den Jahren sollen zudem die Unterschiede der Ausgangslöhne herauskristallisiert werden.
Dazu werden die Löhne in Perzentile aufgeteilt.

**Aufgabe**: Erstellen Sie einen Vektor "percent95", der die logarithmierten Durchschnittslöhne in 100 Perzentile aufteilt. Nutzen Sie dafür die Funktion `quantile(dat,seq())`. Setzen Sie den fehlenden Wert in "seq()" ein, um einen Vektor der Länge 100 zu erhalten.

```{r}
#< fill_in
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, ___))
#>
percent95 = quantile(pcw95$ln_avwage, seq(0, 1, 0.01))
```

Diese Aufteilung muss nun für jedes Jahr des Datensatzes wiederholt werden.

**Aufgabe**: Führen sie den Chunk durch *check* aus.

```{r}
#< task

pcw96 = dat_main %>%
  filter(year == 1996)%>%
  filter(avwage >= 3)
percent96 = quantile(pcw96$ln_avwage, seq(0, 1, 0.01))

pcw97 = dat_main %>%
  filter(year == 1997)%>%
  filter(avwage >= 3)
percent97 = quantile(pcw97$ln_avwage, seq(0, 1, 0.01))

pcw98 = dat_main %>%
  filter(year == 1998)%>%
  filter(avwage >= 3)
percent98 = quantile(pcw98$ln_avwage, seq(0, 1, 0.01))

pcw99 = dat_main %>%
  filter(year == 1999)%>%
  filter(avwage >= 3)
percent99 = quantile(pcw99$ln_avwage, seq(0, 1, 0.01))

pcw00 = dat_main %>%
  filter(year == 2000)%>%
  filter(avwage >= 3)
percent00 = quantile(pcw00$ln_avwage, seq(0, 1, 0.01))

pcw01 = dat_main %>%
  filter(year == 2001)%>%
  filter(avwage >= 3)
percent01 = quantile(pcw01$ln_avwage, seq(0, 1, 0.01))

pcw02 = dat_main %>%
  filter(year == 2002)%>%
  filter(avwage >= 3)
percent02 = quantile(pcw02$ln_avwage, seq(0, 1, 0.01))

#>

```


Nun können die Unterschiede in jedem einzelnen Perzentil von Jahr zu Jahr ermittelt werden. Die Differenzen sollen in einem Datnsatz gespeichert werden. 

Dafür wird zunächst ein Datensatz erstellt, der sich an den Werten der Perzentile aus dem ersten Beobachtungsjahr 1995 richtet.

**Aufgabe**: Erstellen Sie einen Datensatz `diffperc` mittels der Funktion `data.frame`. Dieser soll zunächst die Werte aus `percent95` enthalten, welche durch `sort()` geordnet sind.

```{r}
#< task

#>
diffperc = data.frame(sort(percent95))
```


Der Datensatz diffperc kann jetzt um die Differenzen innerhalb der Perzentile erweitert werden.

**Aufgabe**: Führen Sie den Code mit "check" aus.

```{r}
#< task
diffperc = diffperc %>%
  mutate("percentile" = c(0:100),
         "diff96" = percent96-percent95,
         "diff97" = percent97-percent96,
         "diff98" = percent98-percent97,
         "diff99" = percent99-percent98,
         "diff00" = percent00-percent99,
         "diff01" = percent01-percent00,
         "diff02" = percent02-percent01)

#>
```


Für die Betrachtungsweise der Auswirkungen durch die Einführung des Mindestlohns sind zwei Differenzen von besonderer Bedeutung. Daher sollen die Änderung des Lohns im Jahr vor der Einführung (diff99) mit der Änderung im Jahr nach der Einführung (diff00) in einem Liniendiagramm gegenübergestellt werden.

```{r}
#< task

#Graphik
library(ggplot2)

diffperc = filter(diffperc, percentile < 76 & percentile > 0)
ggplot(diffperc)+
  geom_line(aes(x = percentile, y = diff99), colour = "blue", linetype = 2, linewidth = 0.8)+
  geom_line(aes(x = percentile, y = diff00), colour = "red", linewidth = 0.8)+
  geom_vline(xintercept = 13)+
  geom_vline(xintercept = 50)+
  xlab("Perzentile der Ausgangsdurchschnittslöhne")+
  ylab("Änderung des logarithmierten Durchschnittslohns")

#>
```

#-Mögliche Fragen zum Schaubild

-Wieso logarithmierte Werte?
-Woher kommt der Piek nach unten?




## Exercise 3 DiD -- Difference in Differences

**Möglicher Inhalt**
- Wieso braucht man DiD
- Voraussetzungen gegeben? (parallel-Trend)
- Was sagt er aus
- Vorteil ggü. anderer Methoden
- Wie werden die jeweiligen Gruppen gewählt? (136f.)
  - Treatment Group Indikatoren = FAME + LFS + WERS (136)
  - T = 1 für avwage < 12.000 im Geschäftsjahr vor NMW Einführung 
  - Durchschnitt in T = 1 = 8400 => 3,90 pro Stunde (nah bei NMW = 3,60)  
  - Plausible Treatment-Wahl? (137D.), Fig. 1
- Was gibt es für andere Schätzmethoden?
- Diagramm Variablenbeeinflussung
- Placebo-Effekt (142f.)
  - Imaginäre Einführung NMW im April 1996

**Vorgehen**
- Kernergebnisse erkennen
- Ausgangspunkt: Mindestlohn + Unternehmensgewinne
- Regression aufbauen

**Stichwörter**
- Quasi-experimenteller Rahmen NMW (133)
- Händische DiD-Schätzungsformel (133)
- Parallel-Trend: Unterschiede wären gleich geblieben, wenn es kein Treatment gegeben hätte

**Mögliche Aufgaben**
- Treatmentgruppenwahl entwickeln: 3,60 pro Stunde -> Schnitt 8400 im Jahr bei Vollzeit (Arbeitszeiten GB aufdröseln)


Die Auswirkungen des Mindestlohns auf die Unternehmensgewinne können mit Hilfe der Difference-in-Differences-Methode - kurz **DiD** - beobachtet werden.

**DiD-Methode**
Die DiD-Schätzung ist häufig geeignet, um politische Maßnahmen empirisch zu beurteilen. Gerade mit Hinblick auf Lohnentwicklungen stellte die Methode bereits in der Vergangenheit eine wichtige Grundlage. So können beispielsweise die Einflüsse von Schocks und fixer Effekte abgefedert werden und so die Auswirkungen einzelner Maßnahmen besser beurteilbar machen. (Quelle???) (Angrist, J. D., & Pischke, J. S. (2009). Mostly harmless econometrics: An empiricist's companion. Princeton university press.)

**Sind die Voraussetzungen gegeben? (Quiz)**
- Parallele Trends


**Parallele Trends**
Eine relevante Voraussetzung für das Anwenden der DiD-Methode ist die Parallel-Trends-Assumption (PTA). Diese besagt, dass ohne die Einführung eines Treatments, in unserem Fall der Mindestlohn, die Linien der Kontroll- und Treatmentgruppe weitestgehend parallel liefen. 
Annähernd kann das überprüft werden, indem man sich die Trendlinien der beiden Gruppen vor Einführung des Treatments ansieht. (Quelle???)

**Code**
```{r}
  dat = read_dta('main_fame.dta')
```

```{r}
dat_trend_treat = dat %>% 
  filter(ctreat1 == 1) %>%
  group_by(year)%>%
  summarise("Treatment"=mean(ln_avwage, na.rm = TRUE))
```
```{r}
dat_trend_control = dat %>%
  filter(ctreat1 == 0) %>%
  group_by(year) %>%
  summarise("Control"=mean(ln_avwage, na.rm = TRUE))
```
```{r}
dat_trend = left_join(dat_trend_treat, dat_trend_control)
```
```{r}
ggplot(dat_trend)+
   geom_line(aes(x = year, y = Treatment), colour= "blue", linetype = 1, linewidth = 0.8)+
   geom_line(aes(x = year, y = Control), colour = "red", linetype = 1, linewidth = 0.8)+
   geom_vline(xintercept = 1999)
```
#< quiz "3"
question: Erkennen Sie einen parallelen Trend?
sc:
    - Ja
    - Nein*

success: Während die Löhne in der Kontrollgruppe konstant zu steigen scheinen, läuft der Trend der Treatmentgruppe nicht konstant und auf einem gleichbleibenden Niveau.
failure: Auch wenn es hier meist um eine subjektive Einschätzung geht, sollten Sie sich die unterschiedlichen Steigungen der Trends ansehen.
#>

In unserer Betrachtungsweise ist kein eindeutig paralleler Trend zu erkennen. Aufgrund des kurzen Betrachtungszeitraums des Trends sollte diese Einschätzung aber auch mit Vorsicht genossen werden: Es wird sich auf Trends bezogen, die sich auf sechs Datenpunkte (1994-1999) stützen. Die Betrachtung eines größeren Zeitraums könnte hier eine genauere Betrachtung zulassen.
Bezüglich der PTA gibt es seitens der Autoren keine weiterführenden Analysen, eine Erwähnung wird innerhalb des Artikels vergeblich gesucht.


Bei der Difference in Difference (DiD) Methode werden die Daten anhand von zwei Kriterien unterteilt.
Zum einen wird entschieden, ob es sich um eine Pre-Treatment oder eine Post-Treatment Gruppe handelt.

#< quiz "4"
question: Ab welchem Zeitpunkt werden Daten der Post-Treatment Gruppe zugewiesen?
sc:
    - 1999
    - 2000*

success: Richtige Antwort. Die Einführung war zwar im Jahr 1999, die Daten jedes Jahres beziehen sich allerdings auf das vergangene Geschäftsjahr (April bis März).
failure: Das ist nicht korrekt. 
#>

Für eine DiD-Schätuung muss weiter eine Kontroll- und eine Treatmentgruppe definiert werden. In der Treatmentgruppe werden jene Unternehmen zusammengefasst, bei denen der Durchschnittslohn (avwage) im Jahr unter 12000 Pfund lag.
Die Kontrollgruppe umfasst Unternehmensdaten mit einem Durchschnittslohn zwischen 12000 und 20000 Pfund.


## Exercise 3.1 -- Wahl der Gruppen
Im Mittelpunkt der Mindestlohneinführung steht der Wert von 3,60 Pfund pro Stunde. Da unser Datensatz allerdings keine Daten zu jedem Arbeitnehmer enthält, müssen wir uns an die Wahl der Treatmentgruppe nähern.

```{r}
#< task
  dat = read_dta('main_fame.dta')
#>

```
Die Variable, die den Lohn innerhalb eines Unternehmens am Besten widerspiegelt ist hierbei "avwage". Hierüber wird sich auch im Artikel genähert. Dabei werden alle Unternehmen mit einem avwage =< 12000 in die Treatmentgruppe einsortiert. 
Um zu verstehen, warum sich für diesen Wert als Obergrenze entschieden wird ist es hilfreich, den Wert in Zusammenhang mit dem Stundenlohn zu bringen.
Dazu soll zunächst der durchschnittliche Lohn aller Unternehmen aus der Treatmentgruppe in der Pre-Policy Periode ermittelt werden.

**Aufgabe**: Setzen Sie die passenden Werte in die Lücken ein. (Hinweis: Avwage wird im Datensatz in 1000 Pfund angegeben)
```{r}
#< fill_in
mean_treat = dat %>%
  filter(avwage <= ___) %>%
  filter(year == ___) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
#>
mean_treat = dat %>%
  filter(avwage <= 12) %>%
  filter(year == 1999) %>%
  summarise(round(mean(avwage)*1000,2))
mean_treat
```
```{r}
#< task
mean_treat / 2000
#>
```
Mit dieser Näherung kommt man in die Nähe des Mindestlohns. Dennoch ist dies auch mit Vorsicht zu genießen. Da die Wahl der Treatmentgruppe auf Durchschnittslöhne eines gesamten Unternehmens beruht, können große Ausreißer das Ergebnis beeinflussen. Es wird eine Vollzeitbeschäftigung vorausgesetzt, wobei der Anteil an Teilzeitarbeitarbeit bei knapp einem Viertel lag. (Quelle???)

Die Wahl der Treatmentgruppe kann allerdings weiter durch die Verwendung des WERS-Datensatzes untermauert werden. 
So kann die Lohnverteilung innerhalb eines Unternehmens mit dem Durchschnittslohn in Zusammenhang gebracht werden. Die Autoren kommen zu dem Schluss, dass 87% aller vom Mindestlohn profitierenden Arbeiter in Unternehmen arbeiten, in denen der jährliche Durchschnittslohn bei 12000 Pfund oder niedriger liegt. 
Wir wollen überprüfen, inwiwefern der Anteil an Lohnzahlungen unter 3,60 mit dem Durchschnittslohn zusammmenhängt.

**Figure 1**
```{r}
#< task
dat_seq = read_dta('seq98.dta')
#>
```

## Exercise 3.2 -- händische DiD-Berechnung

Mit einem Blick auf den Datensatz erkennt man, dass hierfür bereits Dummy-Variablen ertellt worden sind.

**Aufgabe**: Laden Sie erneut den bereits bekannten Datensatz, indem Sie lediglich "check" drücken.
```{r}
#< task
dat = read_dta('main_fame.dta')
#>

```

```{r}
#< task
dat_table_DiD = dat %>%
  group_by(ctreat1, NMW)%>%
  filter(pp == 1) %>%
  summarise(mean_avwage = mean(avwage), mean_ln_avwage = mean(ln_avwage), mean_net_pcm = mean(net_pcm))
#>
```

**Wieso wird der Dummy "pp" angewandt?**
In diesem Code fällt auf, dass der Datensatz um mehrere Einträge mit Hilfe des Dummys pp verkleinert wird.
Diese Vorauswahl wird von Seiten der Autoren getroffen (S. 135, (Verw. 14)): Dabei wird sich auf Unternehmen bezogen, deren Geschäftsjahr im Zeitraum April bis März läuft. Untersuchungen wurden ebenfalls für den gesamten Datensatz durchgeführt, die grundlegenden Ergebnisse ähneln sich dabei. Aufgrund diverser Regelungen in der britischen Berichterstattung sind kleinere Unternehmen von der Angabe bestimmter Daten befreit. Daher gibt es ein subsample. 

Werfen wir einen Blick auf die aussortierten Daten und überprüfen anhand der Beschäftigungszahlen, ob es Aufffälligkeiten gibt:

```{r}
dat_no_pp = dat %>%
  filter(pp == 0)

dat_pp = dat %>%
  filter(pp == 1)

boxplot(log(dat_no_pp$emp),log(dat_pp$emp))
boxplot(log(dat_no_pp$net_pcm),log(dat_pp$net_pcm))
boxplot(log(dat_no_pp$avwage),log(dat_pp$avwage))

```
Im Gesamten ist zu erkennen, dass die Daten, die sich nicht in der Auswahl befinden, breiter gestreut sind.
Wir erkennen einen Unterschied in den Beschäftigungszahlen der beiden Gruppen.
In Großbritannien sind **kleinere Unternehmen** von der Veröffentlichung bestimmter Daten befreit. Um eine vollumfängliche Analyse zu gewährleisten entscheiden sich die Autoren daher ein Unterbeispiel zu erstellen, in denen Daten vollumfänglich erfasst werden (S. 135).
Das schränkt allerdings auch die Bewertung ein, lenkt den Blick weg von kleineren Unternehmen und muss bei der Betrachtung der Ergebnisse bedacht werden. 



Nachdem die relevanten Daten des DiD zusammengefasst in der Tabelle "dat_table_DiD" vorhanden sind, können die Differenzen nun händisch berechnet werden.

Die Formel hierfür lautet 
***(y.post.treat - y.post.control) - (y.pre.treat - y.pre.control)***

**Aufgabe**: Werfen Sie zunächst einen Blick auf die erzeugte Tabelle und überlegen Sie, welcher Gruppe die jeweiligen Werte angehören. Lassen Sie sich dafür die oben erstellte Tabelle anzeigen und überprüfen Sie Ihre Eingabe mittels "check".
```{r}
#< task

#>
dat_table_DiD
```

#< quiz "5"
question: Welche Spalte beschreibt die Kontroll- bzw. Treatmentgruppe?
sc:
    - ctreat1*
    - NMW

success: Richtige Antwort. Ist ctreat1 = 1, so handelt es sich um die Treatmentgruppe, andernfalls ist es die Kontrollgruppe.
failure: Falsch. NMW bezieht sich auf den Zeitpunkt. 
#>

#< quiz "6"
question: Von welcher Gruppe ist die Rede, wenn NMW = 1 ?
sc:
    - Pre-Treatment
    - Post-Treatment*
    
success: Korrekt. In diesem Fall befinden wir uns im Jahr 2000 oder später.
failure: Das ist nicht richtig. In diesem Fall wäre NMW = 0.

#>

**Aufgabe**: Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
```{r}
#< fill_in
# Weisen Sie den für die DiD Schätzung relevanten Variablen die passenden Tabelleneinträge aus "dat_table_DiD" zu.
y1.post.treat = dat_table_DiD$mean_ln_avwage[___]
y1.post.control = dat_table_DiD$mean_ln_avwage[___]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[___]
y1.pre.control = dat_table_DiD$mean_ln_avwage[___]

#>
y1.post.treat = dat_table_DiD$mean_ln_avwage[4]
y1.post.control = dat_table_DiD$mean_ln_avwage[2]
y1.pre.treat = dat_table_DiD$mean_ln_avwage[3]
y1.pre.control = dat_table_DiD$mean_ln_avwage[1]

```

#< quiz "7"
question: Wieso werden für den Durchschnittslohn logarithmierte Werte verwendet?
sc:
    - a*
    - b
    - c

success: Korrekt. 
failure: Das ist nicht die richtige Lösung.
#>

#< quiz "8"
question: Wieso gibt es in der Kontrollgruppe eine Obergrenze (20000 = Median)?
sc:
    - a
    - b*
    - c

success: Korrekt. 
failure: Das ist nicht die richtige Lösung.
#>
Neben des logarithmierten Durchschnittslohns wird auch der DiD-Schätzer der Nettorendite eines Unternehmens je Geschäftsjahr (net_pcm) berechnet.
Das geschieht analog zur obigen Schätzung.

**Aufgabe**: Werfen Sie erneut einen Blick auf die erstellte Tabelle und geben Sie nun die Zeilen ein, in denen der passende Wert steht.
```{r}
#< fill_in
y2.post.treat = dat_table_DiD$mean_net_pcm[___]
y2.post.control = dat_table_DiD$mean_net_pcm[___]
y2.pre.treat = dat_table_DiD$mean_net_pcm[___]
y2.pre.control = dat_table_DiD$mean_net_pcm[___]
#>
y2.post.treat = dat_table_DiD$mean_net_pcm[4]
y2.post.control = dat_table_DiD$mean_net_pcm[2]
y2.pre.treat = dat_table_DiD$mean_net_pcm[3]
y2.pre.control = dat_table_DiD$mean_net_pcm[1]
```

Die Werte sind nun gespeichert und die DiDs können berechnet werden.

**Aufgabe**: Fügen Sie dem Code das Anzeigen der Ergebnisse hinzu und führen Sie den Code mittels "Check" aus.
```{r}
#< fill_in
DiD_ln_avwage = (y1.post.treat - y1.post.control) - (y1.pre.treat - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.post.control) - (y2.pre.treat - y2.pre.control)
  
#Ergebnisse anzeigen
#>
DiD_ln_avwage = (y1.post.treat - y1.post.control) - (y1.pre.treat - y1.pre.control)
DiD_net_pcm = (y2.post.treat - y2.post.control) - (y2.pre.treat - y2.pre.control)
  
#Ergebnisse anzeigen
DiD_ln_avwage
DiD_net_pcm
```

Durch die Einführung des Mindestlohns können wir sagen, dass dadurch in den beobachteten Unternehmen der Durchschnittslohn gestiegen ist. Zugleich ist zu erkennen, dass in jenen Unternehmen der Nettogewinn zurück gegangen ist.

Um diese Veränderung genauer bewerten zu können und tiefergehende Analysen zu ermöglichen, machen wir uns die Methode der Regression zu eigen.


## Exercise 3.3 -- DiD-Schätzung mittels Regression

**Theorie**
- Cluster-Robuste Standardfehler
  - Geclustert nach Regno (unternehmen)
- Genestete Daten

**Aufgabe**: Lesen Sie einen Auszug des bekannten Datensatzes dat_main ein, indem Sie den Code mit "check" ausführen.
```{r}
#< task
dat_raw = read_dta('main_fame.dta')
dat = filter(dat_raw, pp == 1) 
#>
```

```{r}
regi = lm(ln_avwage ~ ctreat1, data = dat)
```

```{r}
regii = lm(ln_avwage ~ NMW, data = dat)
```

```{r}
regiii = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW, data = dat)
```

```{r}
stargazer(regi, regii, regiii, type = "text")
```

**Genestete Daten**
(Bryk, Raudenbush: Hierarchical Linear Models: Applications and Data Analysis Methods)
Die Werte der Variablen sind im obigen Fall als hoch signifikant gekennzeichnet. Allerdings sind die p-Werte fehlerhaft, da es sich bei den Daten teilweise um genestete Daten handelt. Genestete Daten liegen vor, wenn mehrere Daten zu einer übergeordneten Einheit zählen.
In unserem Fall haben wir Daten zum logarithmierten Durchschnittslohn (ln_avwage) über mehrere Jahre. Diese haben ein Unternehmen (regno) als übergeordnete Einheit.
Um Fehler bezüglich genesteter Daten zu verhindern, fügen wir Clusterrobuste Standardfehler ein.

#< quiz "3.3.1"
question: Nach welcher Variable soll geclustert werden?
sc:
    - ln_avwage
    - regno*

success: Korrekt, hierbei handelt es sich um die übergeordnete Einheit.   
failure: Das ist so nicht richtig. Bei genesteten Daten muss nach der übergeordneten Einheit geclustert werden.
#>

Nun fügen wir die Clusterrobusten Standardfehler ein und schauen, was sich dadurch verändert.
```{r}
reg1 = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW, data = dat)
cluster = vcovCL(reg1, cluster = ~regno)

stargazer(reg1, type = "text",
          se = list(sqrt(diag(cluster))))
#Quelle?
```

**Clusterrobuste Standardfehler**

An den Werten der ist Variablen ist keine Veränderung zu erkennen. Allerdings haben sich die Werte der Standardfehler verändert.
Während man für ctreat1 und die Interaktionsvariable eine Erhöhung des P-Wertes vorfindet, ist eine Verringerung bei der Variablen NMW zu verzeichnen.

Um diese Veränderungen zu verstehen sehen wir uns an, was es generell mit clusterrobusten Standardfehlern auf sich hat:
(Angrist, 231ff)...
Variiert der Regressor nur innerhalb einer Clustergruppe, so kann der Standardfehler steigen (231)

---------------

**Ergebnisanalyse**

Die Variablen beschreiben die Veränderungen im Vergleich zum Pre-Policy Jahr, welche mit Constant beschrieben wird.
- Wie wirken die unterschiedlichen Variablen?
- Werte zuordnen
#< quiz "3.3.2"
question: Wenn Sie an die Werte aus der händischen Berechnung zurückdenken, sollte Ihnen der Wert einer Variablen bekannt vorkommen. Von welcher Variablen ist die Rede?
sc:
    - ctreat1
    - treat1_NMW*
    - NMW

success: Richtige Antwort, auf dieser Variablen liegt das Hauptaugenmerk.  
failure: Das ist leider falsch. 
#>

Bei treat1_NMW handelt es sich um den Interaktionsterm der beiden Dummyvariablen. Dieser beschreibt die einfache DiD-Schätzung unter der Berücksichtigung Cluster-Robuster Standardfehler je Unternehmen. Der Wert ist hoch signifikant.

#< quiz "3.3.3"
question: In welcher Einheit wird der DiD-Wert beschrieben?
sc:
    - Pfund
    - Prozent
    - Prozentpunkte*

success: Richtige Antwort. Der Anstieg des Gehalts in der Treatmentgruppe ist um ca. 11 Prozentpunkte höher als in der Kontrollgruppe.
failure: Das ist leider falsch. Es werden zwei log-Variablen miteinander verglichen.
#>

----------------

**NET_PCM**

Zur Betrachtung der Veränderung der Unternehmensgewinne gehen wir nach demselben Schema vor.

```{r}
reg2 = lm(net_pcm ~ ctreat1 + treat1_NMW + NMW, data = dat)
cluster2 = vcovCL(reg2, cluster = ~regno)

stargazer(reg2, type = "text",
          se = list(sqrt(diag(cluster2))))
```
-------------

Sehen wir uns weiter an ob es zu Veränderungen kommt, wenn wir auf bestimmte Effekte der Unternehmenswelt kontrollieren.

**Table 2, Panel A**
```{r}
reg3 = lm(ln_avwage ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk), data = dat)
cluster3 = vcovCL(reg3, cluster = ~regno)

stargazer(reg3, type = "text",
          se = list(sqrt(diag(cluster3))))
```

```{r}
reg4 = lm(net_pcm ~ ctreat1 + treat1_NMW + NMW + grad2 + unionmem + ptwk + female + 
                factor(sic2) + factor(year) + factor(gorwk), data = dat)
cluster4 = vcovCL(reg4, cluster = ~regno)

stargazer(reg4, type = "text",
          se = list(sqrt(diag(cluster4))))
```

**Table 2, Panel B**


## Exercise 3.4 -- Imaginäre Mindestlohneinführung

- Sind die Veränderungen auf das Treatment zurückzuführen?
  - Vergleich zu Parallel-Trend
- Imaginäre Einführung am 1. April 1996
- Vergleich Datensätze: ff=0 vs. ff=1
- Table 3
- Figure 3


```{r}
dat = read_dta('main_fame.dta')
dat_ff1 = filter(dat, ff == 1)
dat_ff0 = filter(dat, ff == 0)
```

```{r}
dat_ff1 %>%
  group_by(year)%>%
  summarise(length(year))

dat_ff0 %>%
  group_by(year)%>%
  summarise(length(year))
```
-> Nur Einträge bis 99 in ff1
ABER: 1994-1999 auch in ff0 vorhanden

```{r}
dat_ff0 %>%
  group_by(pp)%>%
  summarise(length(pp))

dat_ff1 %>%
  group_by(pp)%>%
  summarise(length(pp))
```
-> Anteil an pp==0 in ff0 deutlich höher als in ff1

```{r}
dat_ff0 = filter(dat_ff0, year==1996)
dat_ff1 = filter(dat_ff1, year==1996)
boxplot(dat_ff0$ln_avwage,dat_ff1$ln_avwage)
mean(dat_ff0$avwage, na.rm = TRUE)
mean(dat_ff1$avwage)
max(dat_ff1$avwage)
```


## Exercise 4 -- Einordnung des Artikels (weiterführende Überlegungen)

- EU-weiter Mindestlohn (Möglichkeiten, Chancen, Probleme)
- Unterschiede zu 1999 (Andere Rahmenbedingungen?, Brexit?)
- unberücksichtigte Variablen
- Auswirkung auf Beschäftigung
- weitere Artikel (andere Auswirkungen untersucht)
- Strukturen in Unternehmen

## Exercise Anregungen

- "Aber was sind die Produktionskosten - des Arbeiters, d.h. die Kosten, um den Arbeiter selbst zu produzieren?" / "Wert der Arbeit" (Kapital, 497)


## Exercise Probleme beim Code

- i. Dummyvariablen in Stata
- Intervallregression


## Exercise Aufgabentypen 

a) We often want to compute some summary statistic of a vector. For example:

```{r}
#< task
x = 10:23
# Computing the sum of x
sum(x)
#>
```

Now compute the mean of x.
```{r optional=TRUE}
# Note the chunk option optional = TRUE means
# the user can continue with the next exercise
# without having solved this one

mean(x)
#< hint
cat("There already exist R functions for many things. To find them use Google, e.g. search for 'R compute mean'.")
#>
```


#< info "useful functions for numeric vectors"
Here are examples for useful R functions
```{r}
max(c(1,5,2)) # returns maximum
min(c(1,5,2)) # returns minimum

sum(c(1,5,2,NA), na.rm=TRUE) # returns sum of all numbers, ignore NA
cumsum(c(1,5,2)) # returns cummulated sum
diff(c(1,5,2)) # returns the vector of differences
```
#>


#< award "mean means mean"
Well, in some occasions one can just guess the name of an R function. The function to compute the mean of a vector, or matrix is called 'mean'. Usually, it is much quicker to goggle than to guess function names, however.
#>

b) Let `y` be a vector that contains the squared elements of `x`, i.e. for each element $i$ we want $$y_i = x_i^2.$$ Then show `y`.
```{r}
# We should not set this chunk optional
# since we need y in the next chunk
y = x^2
y
```

c) Now use the function `qplot` from the package `ggplot2` to create a scatter plot of `x` against `y`. You can google `r qplot` to get the help for the function `qplot`.

```{r optional=TRUE, dev="svg", fig.width=4}
#< task
library(ggplot2) # load ggplot2 package

# Enter your call to qplot here...
#>
qplot(x,y)
#< test_arg
allow.extra.arg = TRUE 
#>
# The block above allows the user to add extra arguments to the call to qplot, i.e. qplot(x,y,xlab="The variable x"), would also pass the test.
```


#< quiz "prime"
question: What is the 'oddest' prime?
sc:
    - 2*
    - 3
    - 5
    - 7
success: Well, of course the answer is debatable...
failure: Try again.
#>

Note: A quiz as specified below only works in the shiny environment. If you want to design a quiz in an RMarkdown based RTutor problem set, you should use a chunk. E.g. as follows:

Which of the following numbers is the oddest prime? 2,3,5 or 7? Enter you solution in the code below and press "check".

```{r}
2
```
#< award "The oddest prime"
Wouldn't you agree that the only even prime is the odd man out?
#>

## Exercise Submitting your solution

To submit your solution please proceed as follows:

1. Scroll to the top and click on the icon with the bars <i class="fa fa-tasks fa-fw"></i> to see how many points you got so far. If you want to have more points you can try to solve the missing tasks.

2. If you want to submit click on the download button <i class="fa  fa-download fa-fw"></i> at the very right.

3. In the opened tab click the button "Download Submission File". Your browser should then download a file with the extension `.sub`.

4. Upload that downloaded file to your course management system like Moodle, as specified by your instructor.



